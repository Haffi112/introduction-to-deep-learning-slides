\section{Related works}

\label{sec:related}

\textbf{Large-scale pre-training.} Benefited from the development of Transformer in both vision~\cite{acmix,dat,pointformer} and language~\cite{transformer} tasks, large-scale pre-training framework has received wide concerns in recent years and shown promising results in the field of computer vision and natural language processing. GPT~\cite{gpt} is one of the pioneer works for language pre-training which optimizes the probability of output based on previous words in the sequence. BERT~\cite{bert} adopts the masked language modeling technique and predicts the masked tokens conditioned on the unmasked ones. 
% XLNet~\cite{xlnet} takes the advantages of BERT and GPT, and combines the ability to model bidirectional contexts in BERT, and the auto-regressive formulation in GPT which additionally improves the generalization performance.

Similarly, computer vision society also witnesses the development of pre-training models thanks to the emergence of large-scale image datasets. IGPT~\cite{igpt} proposes a generative pre-training technique and shows promising results on classification task. MAE~\cite{mae} adopts a similar pre-training scheme as BERT and predicts the masked regions of an image with unmasked ones. 
% Another line of researches is based on contrastive learning and uses siamese architectures for self supervision~\cite{swav,simclr,moco}. With the advent of Transformer-based models in computer vision, large-scale datasets have gradually become a common practice in the training process~\cite{vit,deit}.

Multi-modal pre-training bears differences from the aforementioned frameworks and requires the alignment between various data modalities. Using enormous image-text pairs collected from Internet, vision-language models show significant improvements on various downstream tasks. Among these approaches, various pre-training scheme is adopted, including contrastive learning~\cite{cont1,cont2,cont3}, masked language modeling~\cite{mlm1,mlm2}, and masked region modeling~\cite{uniter}. 
% Several approaches also use a pre-trained object detector to align the object with text concepts~\cite{uniter,oscar,lxmert}.

The problem of semantic misunderstanding has also been investigated by previous works. EI-CLIP~\cite{eiclip} considers the problem of cross-modal retrieval in the field of E-commerce. Sharing similar insight with our work, the authors notice the model bias towards some specific word tokens in CLIP, and introduce causal inference to align the text encoder with e-commerce domain knowledge. K3M~\cite{k3m} focuses on the modality-missing and modality-noise problem and introduces knowledge modality into E-commerce tasks. DeVLBert~\cite{devlbert} studies the spurious correlations between different modalities and adjusts the conditional probability of image tokens and word tokens. Kaleido-BERT~\cite{zhuge2021kaleido} focuses on image-text coherence by introducing several novel self-supervised tasks.

Compared to previous approaches, we are the first to incorporate multi-modal knowledge graphs into the pre-training process, and effectively enhance the model perception on semantic relations between visual and language concepts.

\textbf{Knowledge Graph.} Knowledge graph is first introduced in the field of natural language processing, and the knowledge graph embedding approaches have been successful on capturing the semantics of symbols (entities and relations) and achieving impressive results on a wide range of real-world applications including text understanding~\cite{textunder2,textunder1}, recommendation system~\cite{recommand2,recommand1} and natural language question answering~\cite{kgqa, kgqa2}. On the other hand, scene graphs represent a type of graph-structured data in computer vision, where the visual concepts in the image are connected with semantic relations. Scene graphs emphasize the fine-grained semantic features for images and are widely adopted in various downstream tasks, including scene graph generation~\cite{sggen}, and Scene Graph Parsing~\cite{sgparse}. Besides scene graph, knowledge graph is also adopted in other computer vision tasks, including image classification~\cite{graphcls}, panoptic segmentation~\cite{graphseg}, and image captioning~\cite{graphcap}.
On this basis, multi-modal knowledge graph earns wide concerns in recent years. Considering the natural alignment between different data modalities, multi-modal knowledge graphs have been widely adopted in various graph-based tasks including link prediction~\cite{link1, link2}, entity classification~\cite{entity1}, while also showing great potential on out of graph applications like visual question answering~\cite{gvqa1,gvqa2} and recommendation systems~\cite{grecommand1,grecommand2}.