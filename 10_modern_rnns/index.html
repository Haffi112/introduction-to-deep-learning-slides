<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Modern Recurrent Neural Networks - Introduction to Deep Learning</title>

    <!-- Reveal.js CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/reveal.css">
    <link rel="stylesheet" href="../shared/css/reveal-theme.css">
    <link rel="stylesheet" href="../shared/css/common.css">
    <link rel="stylesheet" href="../shared/css/quiz.css">
    <link rel="stylesheet" href="css/modern-rnn-custom.css">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/highlight/monokai.css">
</head>
<body>
    <div class="reveal">
        <div class="slides">

            <!-- Title Slide -->
            <section class="title-slide">
                <img src="../shared/images/uoi_logo_blue.png" alt="University of Iceland Logo" class="ui-logo">
                <h1 class="truncate-title">Modern Recurrent Neural Networks</h1>
                <p>Chapter 10: Advanced RNN Architectures</p>
                <p>Based on "Dive into Deep Learning" by Zhang et al.</p>
                <p class="mt-lg">
                    <small>Instructor: Hafsteinn Einarsson</small><br>
                    <small>University of Iceland</small>
                </p>
            </section>

            <!-- Single Vertical Section: Chapter Overview -->
            <section>
                <!-- Slide 1: The Problem with Basic RNNs -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10", "url": "https://d2l.ai/chapter_recurrent-modern/index.html"}]'>
                    <h2 class="truncate-title">The Challenge: Training RNNs is Hard</h2>
                    <div style="font-size: 0.85em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Vanishing and Exploding Gradient Problem</h4>
                            <p>Shortly after the first RNNs were trained using backpropagation, a critical issue emerged:</p>
                        </div>
                        <div class="fragment" style="margin-top: 30px;">
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; font-size: 0.7em;">
                                <div class="emphasis-box" style="background: #FFF5F5; border-left: 4px solid #FC8484;">
                                    <h5 style="color: #FC8484; margin-top: 0;">üí• Exploding Gradients</h5>
                                    <p style="font-size: 0.85em;">Gradients grow exponentially during backpropagation</p>
                                    <p style="font-size: 0.85em;"><strong>Solution:</strong> <span class="tooltip">Gradient clipping<span class="tooltiptext">A technique that limits gradient values to a maximum threshold to prevent numerical instability</span></span> (a blunt but effective hack)</p>
                                </div>
                                <div class="emphasis-box" style="background: #F5F5FF; border-left: 4px solid #10099F;">
                                    <h5 style="color: #10099F; margin-top: 0;">üå´Ô∏è Vanishing Gradients</h5>
                                    <p style="font-size: 0.85em;">Gradients shrink to near zero, preventing learning</p>
                                    <p style="font-size: 0.85em;"><strong>Problem:</strong> Can't learn <span class="tooltip">long-term dependencies<span class="tooltiptext">Relationships between events that are many time steps apart in a sequence</span></span></p>
                                </div>
                            </div>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 30px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0;"><strong>The Real Challenge:</strong> Vanishing gradients require a more elaborate architectural solution</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 2: Two Groundbreaking Papers -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - Long Short-Term Memory", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}, {"text": "Schuster & Paliwal (1997) - Bidirectional RNNs", "url": "https://ieeexplore.ieee.org/document/650093"}]'>
                    <h2 class="truncate-title">Two Groundbreaking Papers That Changed Everything</h2>
                    <div style="font-size: 0.7em;">
                        <div class="fragment" style="margin-bottom: 40px;">
                            <div style="background: linear-gradient(135deg, #10099F 0%, #2DD2C0 100%); color: white; padding: 25px; border-radius: 10px;">
                                <h4 style="margin-top: 0; color: white;">üìö Paper #1: Long Short-Term Memory (1997)</h4>
                                <p style="font-size: 0.95em;"><strong>Authors:</strong> Sepp Hochreiter & J√ºrgen Schmidhuber</p>
                                <p style="font-size: 0.9em; margin-bottom: 0;"><strong>Key Innovation:</strong> Introduced the <span class="tooltip" style="border-bottom-color: white;">memory cell<span class="tooltiptext">A unit of computation that replaces traditional RNN nodes with an internal state and multiplicative gates</span></span> - a composite unit with internal state that can maintain information across many time steps</p>
                            </div>
                        </div>
                        <div class="fragment">
                            <div style="background: linear-gradient(135deg, #2DD2C0 0%, #00FFBA 100%); color: #262626; padding: 25px; border-radius: 10px;">
                                <h4 style="margin-top: 0;">üìö Paper #2: Bidirectional RNNs (1997)</h4>
                                <p style="font-size: 0.95em;"><strong>Authors:</strong> Mike Schuster & Kuldip K. Paliwal</p>
                                <p style="font-size: 0.9em; margin-bottom: 0;"><strong>Key Innovation:</strong> Use information from both <em>past</em> and <em>future</em> time steps to determine output at any point in the sequence</p>
                            </div>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 30px;">
                            <p style="margin: 0; font-size: 0.95em;">üí° These innovations are not mutually exclusive! They can be combined for even better performance.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 3: Understanding LSTM Memory -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - LSTM", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}]'>
                    <h2 class="truncate-title">Understanding LSTM Memory</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Three Types of Memory</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 15px; margin: 20px 0; font-size: 0.85em;">
                                <div class="emphasis-box" style="background: #F5F5F5; border: 2px solid #EEEEEE;">
                                    <h5 style="color: #10099F; margin-top: 0;">Long-Term</h5>
                                    <p style="font-size: 0.9em;">Network <strong>weights</strong></p>
                                    <p style="font-size: 0.85em; margin: 0;">Change slowly during training</p>
                                </div>
                                <div class="emphasis-box" style="background: #FFFBF0; border: 2px solid #FAC55B;">
                                    <h5 style="color: #FFA05F; margin-top: 0;">Short-Term</h5>
                                    <p style="font-size: 0.9em;">Ephemeral <strong>activations</strong></p>
                                    <p style="font-size: 0.85em; margin: 0;">Pass from node to node</p>
                                </div>
                                <div class="emphasis-box" style="background: #F0FFF9; border: 2px solid #2DD2C0;">
                                    <h5 style="color: #2DD2C0; margin-top: 0;">LSTM Cell</h5>
                                    <p style="font-size: 0.9em;"><strong>Intermediate storage</strong></p>
                                    <p style="font-size: 0.85em; margin: 0;">Controlled by gates</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">The Key Innovation</h4>
                            <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                                <p style="font-size: 0.95em; margin: 0;">Memory cell with <strong>internal state</strong> maintained by a self-connected <span class="tooltip">recurrent edge of weight 1<span class="tooltiptext">A connection with exactly weight 1.0 means gradients can flow unchanged through time, avoiding vanishing or exploding</span></span></p>
                            </div>
                            <p style="font-size: 0.9em; margin-top: 15px;">‚Üí Gradients can pass across <strong>many time steps</strong> without vanishing or exploding!</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 4: LSTM Gates -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - LSTM", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}]'>
                    <h2 class="truncate-title">LSTM Gates: Controlling Information Flow</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Three Multiplicative Gates</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 12px; margin: 20px 0; font-size: 0.8em;">
                                <div style="text-align: center; padding: 15px; background: #FFF5F5; border-radius: 8px;">
                                    <div style="font-size: 2.2em; margin-bottom: 8px;">üö™</div>
                                    <strong style="color: #FC8484;">Input Gate</strong>
                                    <p style="margin: 8px 0 0 0; font-size: 0.9em;">Controls what new information enters memory</p>
                                </div>
                                <div style="text-align: center; padding: 15px; background: #FFFBF0; border-radius: 8px;">
                                    <div style="font-size: 2.2em; margin-bottom: 8px;">üóëÔ∏è</div>
                                    <strong style="color: #FFA05F;">Forget Gate</strong>
                                    <p style="margin: 8px 0 0 0; font-size: 0.9em;">Decides what to remove from memory</p>
                                </div>
                                <div style="text-align: center; padding: 15px; background: #F0FFF9; border-radius: 8px;">
                                    <div style="font-size: 2.2em; margin-bottom: 8px;">üì§</div>
                                    <strong style="color: #2DD2C0;">Output Gate</strong>
                                    <p style="margin: 8px 0 0 0; font-size: 0.9em;">Controls what information is output</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 25px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0; font-size: 0.95em;">üí° <strong>Why "gates"?</strong> Each gate uses a sigmoid activation (output 0-1) to act like a valve, controlling how much information flows through</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 5: Bidirectional RNNs Concept -->
                <section data-sources='[{"text": "Schuster & Paliwal (1997) - Bidirectional RNNs", "url": "https://ieeexplore.ieee.org/document/650093"}]'>
                    <h2 class="truncate-title">Bidirectional RNNs: The Concept</h2>
                    <div style="font-size: 0.6em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Limitation</h4>
                            <div class="emphasis-box" style="background: #FFF5F5; border-left: 4px solid #FC8484;">
                                <p style="margin: 0; font-size: 0.95em;">Traditional RNNs only use <strong>past context</strong> (previous time steps)</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Example: Part-of-Speech Tagging</h4>
                            <div style="background: #F0FFF9; padding: 18px; border-radius: 8px; margin: 12px 0;">
                                <p style="font-family: 'Source Code Pro', monospace; font-size: 0.9em; margin: 0; line-height: 1.8;">
                                    "We saw her <span style="background: #FAC55B; padding: 2px 6px; border-radius: 3px;">duck</span> into the room" ‚Üí <strong>verb</strong><br>
                                    "We saw her <span style="background: #FAC55B; padding: 2px 6px; border-radius: 3px;">duck</span> in the pond" ‚Üí <strong>noun</strong>
                                </p>
                                <p style="font-size: 0.9em; margin-top: 12px; font-style: italic;">Same prefix "We saw her", but words <em>after</em> "duck" determine its role!</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">The Solution</h4>
                            <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                                <p style="font-size: 0.95em; margin-bottom: 8px;">Process in <strong>both directions</strong>:</p>
                                <ul style="font-size: 0.9em; margin: 0; line-height: 1.6;">
                                    <li><strong>Forward RNN:</strong> beginning ‚Üí end (past context)</li>
                                    <li><strong>Backward RNN:</strong> end ‚Üí beginning (future context)</li>
                                    <li><strong>Output:</strong> concatenate both directions</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 6: Bidirectional RNNs Applications -->
                <section data-sources='[{"text": "Graves & Schmidhuber (2005) - Phoneme Classification", "url": "https://ieeexplore.ieee.org/document/1532202"}, {"text": "Graves et al. (2008) - Handwriting Recognition", "url": "https://ieeexplore.ieee.org/document/4531750"}]'>
                    <h2 class="truncate-title">Bidirectional RNNs: Success Stories</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Successful Applications</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 20px 0; font-size: 0.9em;">
                                <div class="emphasis-box" style="text-align: center; background: #FFFBF0; padding: 20px;">
                                    <div style="font-size: 2em; margin-bottom: 10px;">üé§</div>
                                    <p style="margin: 0;"><strong>Phoneme Classification</strong></p>
                                    <p style="font-size: 0.85em; margin: 8px 0 0 0;"><small>(Graves & Schmidhuber, 2005)</small></p>
                                </div>
                                <div class="emphasis-box" style="text-align: center; background: #FFFBF0; padding: 20px;">
                                    <div style="font-size: 2em; margin-bottom: 10px;">‚úçÔ∏è</div>
                                    <p style="margin: 0;"><strong>Handwriting Recognition</strong></p>
                                    <p style="font-size: 0.85em; margin: 8px 0 0 0;"><small>(Graves et al., 2008)</small></p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 30px; background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                            <p style="margin: 0; font-size: 1em;">üí° <strong>The Best of Both Worlds:</strong> Bidirectional LSTMs combine both innovations for state-of-the-art sequence labeling!</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 7: What This Chapter Covers -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10", "url": "https://d2l.ai/chapter_recurrent-modern/index.html"}]'>
                    <h2 class="truncate-title">What This Chapter Covers</h2>
                    <div style="font-size: 0.65em;">
                        <div class="fragment">
                            <div style="background: linear-gradient(135deg, #10099F 0%, #2DD2C0 100%); color: white; padding: 15px; border-radius: 8px; margin-bottom: 15px;">
                                <h4 style="margin-top: 0; color: white; font-size: 1.1em;">üèóÔ∏è Architecture Innovations</h4>
                                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 12px; font-size: 1em;">
                                    <div>
                                        <p style="margin: 4px 0;"><strong>‚Ä¢ LSTM Architecture</strong></p>
                                        <p style="margin: 4px 0 4px 18px; font-size: 0.9em;">Memory cells and gates</p>
                                    </div>
                                    <div>
                                        <p style="margin: 4px 0;"><strong>‚Ä¢ GRU</strong></p>
                                        <p style="margin: 4px 0 4px 18px; font-size: 0.9em;">Lighter alternative to LSTM</p>
                                    </div>
                                    <div>
                                        <p style="margin: 4px 0;"><strong>‚Ä¢ Bidirectional RNNs</strong></p>
                                        <p style="margin: 4px 0 4px 18px; font-size: 0.9em;">Past and future context</p>
                                    </div>
                                    <div>
                                        <p style="margin: 4px 0;"><strong>‚Ä¢ Deep RNNs</strong></p>
                                        <p style="margin: 4px 0 4px 18px; font-size: 0.9em;">Stacking RNN layers</p>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="fragment">
                            <div style="background: linear-gradient(135deg, #2DD2C0 0%, #00FFBA 100%); color: #262626; padding: 15px; border-radius: 8px;">
                                <h4 style="margin-top: 0; font-size: 1.1em;">üîÑ Sequence-to-Sequence Learning</h4>
                                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 12px; font-size: 1em;">
                                    <div>
                                        <p style="margin: 4px 0;"><strong>‚Ä¢ Machine Translation</strong></p>
                                        <p style="margin: 4px 0 4px 18px; font-size: 0.9em;">Between languages</p>
                                    </div>
                                    <div>
                                        <p style="margin: 4px 0;"><strong>‚Ä¢ Encoder-Decoder</strong></p>
                                        <p style="margin: 4px 0 4px 18px; font-size: 0.9em;">Framework for seq2seq</p>
                                    </div>
                                    <div>
                                        <p style="margin: 4px 0;"><strong>‚Ä¢ Teacher Forcing</strong></p>
                                        <p style="margin: 4px 0 4px 18px; font-size: 0.9em;">Training technique</p>
                                    </div>
                                    <div>
                                        <p style="margin: 4px 0;"><strong>‚Ä¢ Beam Search</strong></p>
                                        <p style="margin: 4px 0 4px 18px; font-size: 0.9em;">Decoding strategy</p>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 18px; background: #FFFBF0; border-left: 4px solid #FAC55B; padding: 12px;">
                            <p style="margin: 0; font-size: 1.15em;"><strong>üéØ Goal:</strong> Understand successful RNN architectures and apply them to sequence learning</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 6: MCQ -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "What is the key innovation of LSTM that helps solve the vanishing gradient problem?",
                        "type": "single",
                        "options": [
                            {
                                "text": "Using gradient clipping to prevent gradients from becoming too small",
                                "correct": false,
                                "explanation": "Gradient clipping helps with exploding gradients, not vanishing gradients. LSTMs solve vanishing gradients through their architecture."
                            },
                            {
                                "text": "A memory cell with an internal state maintained by a recurrent edge with weight 1",
                                "correct": true,
                                "explanation": "Correct! The memory cell with a weight-1 recurrent edge allows gradients to flow unchanged across many time steps, preventing vanishing."
                            },
                            {
                                "text": "Processing the sequence in both forward and backward directions",
                                "correct": false,
                                "explanation": "This describes bidirectional RNNs, not the LSTM solution to vanishing gradients. While powerful, bidirectionality doesnt solve gradient vanishing."
                            },
                            {
                                "text": "Using deeper networks with more layers",
                                "correct": false,
                                "explanation": "Deep networks can actually make vanishing gradients worse. LSTMs solve this through their gated memory cell architecture."
                            }
                        ]
                    }'></div>
                </section>

            </section>

            <!-- Single Vertical Section: LSTM (Long Short-Term Memory) -->
            <section>
                <!-- Slide 1: LSTM Introduction -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - Long Short-Term Memory", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}, {"text": "Bengio et al. (1994) - Learning Long-Term Dependencies", "url": "https://ieeexplore.ieee.org/document/279181"}]'>
                    <h2 class="truncate-title">Long Short-Term Memory (LSTM)</h2>
                    <div style="font-size: 0.8em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Historical Context</h4>
                            <div style="background: #F5F5F5; padding: 15px; border-radius: 8px; margin: 15px 0;">
                                <ul style="font-size: 0.95em; line-height: 1.8; margin: 0;">
                                    <li><strong>1990:</strong> First <span class="tooltip">Elman-style RNNs<span class="tooltiptext">Simple recurrent neural networks where hidden state from previous time step feeds back as input</span></span> trained using backpropagation</li>
                                    <li><strong>1991:</strong> Hochreiter articulates the problem in his Master's thesis (in German)</li>
                                    <li><strong>1994:</strong> Bengio discusses learning long-term dependencies is difficult</li>
                                    <li><strong>1997:</strong> Hochreiter & Schmidhuber publish LSTM solution</li>
                                </ul>
                            </div>
                        </div>
                        <div class="fragment emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; margin-top: 20px;">
                            <p style="margin: 0; font-size: 0.95em;">üí° <strong>Key Insight:</strong> Replace ordinary recurrent nodes with <strong>memory cells</strong> that can maintain gradients across many time steps</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 2: The LSTM Solution -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - LSTM", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}]'>
                    <h2 class="truncate-title">The LSTM Solution to Vanishing Gradients</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Core Innovation</h4>
                            <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                                <p style="font-size: 0.95em; margin: 0;">Each memory cell contains an <strong>internal state</strong> with a <span class="tooltip">self-connected recurrent edge of fixed weight 1<span class="tooltiptext">A recurrent connection with weight exactly 1.0 ensures that gradients neither vanish (shrink) nor explode (grow) as they flow backward through time</span></span></p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Why This Works</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; font-size: 0.9em;">
                                <div style="background: #FFF5F5; padding: 15px; border-radius: 8px; border: 2px solid #FC8484;">
                                    <div style="text-align: center; font-size: 1.8em; margin-bottom: 8px;">‚ùå</div>
                                    <p style="margin: 0;"><strong>Standard RNN:</strong></p>
                                    <p style="font-size: 0.9em; margin: 8px 0 0 0;">Gradient ‚àù W<sup>t</sup> ‚Üí vanishes if |W| &lt; 1</p>
                                </div>
                                <div style="background: #F0FFF9; padding: 15px; border-radius: 8px; border: 2px solid #2DD2C0;">
                                    <div style="text-align: center; font-size: 1.8em; margin-bottom: 8px;">‚úì</div>
                                    <p style="margin: 0;"><strong>LSTM:</strong></p>
                                    <p style="font-size: 0.9em; margin: 8px 0 0 0;">Gradient ‚àù 1<sup>t</sup> = 1 ‚Üí stays constant!</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 25px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0; font-size: 0.95em;">üéØ <strong>Result:</strong> Gradients can pass across many time steps without vanishing or exploding</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 3: MCQ on LSTM Motivation -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "Why does an LSTM use a self-connected recurrent edge with weight exactly 1?",
                        "type": "single",
                        "options": [
                            {
                                "text": "To make the network easier to train by reducing the number of parameters",
                                "correct": false,
                                "explanation": "LSTMs actually have more parameters than basic RNNs. The weight-1 connection serves a different purpose."
                            },
                            {
                                "text": "To ensure gradients remain constant as they flow backward through time",
                                "correct": true,
                                "explanation": "Correct! A weight of exactly 1.0 means multiplying by 1^t = 1, keeping gradients from vanishing or exploding across time steps."
                            },
                            {
                                "text": "To speed up the forward pass computation",
                                "correct": false,
                                "explanation": "While multiplication by 1 is computationally simple, the main purpose is gradient flow, not speed."
                            },
                            {
                                "text": "To store only binary information in the memory cell",
                                "correct": false,
                                "explanation": "The memory cell stores continuous values, not binary. The weight-1 connection is about gradient flow."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 4: LSTM Gates Overview -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - LSTM", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}]'>
                    <h2 class="truncate-title">Gated Memory Cell: Three Gates</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Gate Inputs</h4>
                            <div class="emphasis-box" style="background: #F5F5F5;">
                                <p style="margin: 0; font-size: 0.95em;">All gates receive: <strong>X<sub>t</sub></strong> (current input) and <strong>H<sub>t-1</sub></strong> (previous hidden state)</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #10099F;">The Three Gates</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 12px; font-size: 0.85em;">
                                <div style="text-align: center; background: #FFF5F5; padding: 18px; border-radius: 8px; border: 2px solid #FC8484;">
                                    <div style="font-size: 2.5em; margin-bottom: 10px;">üö™</div>
                                    <strong style="color: #FC8484; font-size: 1.1em;">Input Gate (I<sub>t</sub>)</strong>
                                    <p style="margin: 12px 0 0 0; font-size: 0.9em; line-height: 1.5;">How much of the new input should be added to memory?</p>
                                </div>
                                <div style="text-align: center; background: #FFFBF0; padding: 18px; border-radius: 8px; border: 2px solid #FFA05F;">
                                    <div style="font-size: 2.5em; margin-bottom: 10px;">üóëÔ∏è</div>
                                    <strong style="color: #FFA05F; font-size: 1.1em;">Forget Gate (F<sub>t</sub>)</strong>
                                    <p style="margin: 12px 0 0 0; font-size: 0.9em; line-height: 1.5;">How much of the old memory should be kept?</p>
                                </div>
                                <div style="text-align: center; background: #F0FFF9; padding: 18px; border-radius: 8px; border: 2px solid #2DD2C0;">
                                    <div style="font-size: 2.5em; margin-bottom: 10px;">üì§</div>
                                    <strong style="color: #2DD2C0; font-size: 1.1em;">Output Gate (O<sub>t</sub>)</strong>
                                    <p style="margin: 12px 0 0 0; font-size: 0.9em; line-height: 1.5;">How much of the memory should influence output?</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0; font-size: 0.95em;">üí° All gates use <strong>sigmoid activation</strong> ‚Üí output range (0, 1) ‚Üí acts like a valve</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 5: Gate Equations -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - LSTM", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}]'>
                    <h2 class="truncate-title">LSTM Gate Equations</h2>
                    <div style="font-size: 0.7em;">
                        <div class="fragment">
                            <div style="background: #F5F5F5; padding: 12px; border-radius: 8px; margin: 10px 0;">
                                <p style="margin: 0; font-size: 0.9em;"><strong>Given:</strong> X<sub>t</sub> ‚àà ‚Ñù<sup>n√ód</sup> (input), H<sub>t-1</sub> ‚àà ‚Ñù<sup>n√óh</sup> (previous hidden state)</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 15px;">
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px;">
                                <div style="background: #FFF5F5; padding: 15px; border-radius: 8px; border-left: 4px solid #FC8484;">
                                    <p style="margin: 0 0 8px 0; color: #FC8484; font-size: 0.95em;"><strong>Input Gate:</strong></p>
                                    <p style="font-size: 1em; margin: 0;">$$\mathbf{I}_t = \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xi}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hi}} + \mathbf{b}_\textrm{i})$$</p>
                                </div>

                                <div style="background: #FFFBF0; padding: 15px; border-radius: 8px; border-left: 4px solid #FFA05F;">
                                    <p style="margin: 0 0 8px 0; color: #FFA05F; font-size: 0.95em;"><strong>Forget Gate:</strong></p>
                                    <p style="font-size: 1em; margin: 0;">$$\mathbf{F}_t = \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xf}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hf}} + \mathbf{b}_\textrm{f})$$</p>
                                </div>
                            </div>

                            <div style="margin-top: 15px;">
                                <div style="background: #F0FFF9; padding: 15px; border-radius: 8px; border-left: 4px solid #2DD2C0;">
                                    <p style="margin: 0 0 8px 0; color: #2DD2C0; font-size: 0.95em;"><strong>Output Gate:</strong></p>
                                    <p style="font-size: 1em; margin: 0;">$$\mathbf{O}_t = \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xo}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{ho}} + \mathbf{b}_\textrm{o})$$</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 15px;">
                            <p style="font-size: 0.85em; margin: 0;"><strong>Where:</strong> W<sub>xi</sub>, W<sub>xf</sub>, W<sub>xo</sub> ‚àà ‚Ñù<sup>d√óh</sup> and W<sub>hi</sub>, W<sub>hf</sub>, W<sub>ho</sub> ‚àà ‚Ñù<sup>h√óh</sup> are weight matrices; b<sub>i</sub>, b<sub>f</sub>, b<sub>o</sub> ‚àà ‚Ñù<sup>1√óh</sup> are bias vectors</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 6: LSTM Gates Diagram -->
                <section data-sources='[{"text": "Dive into Deep Learning - LSTM", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html"}]'>
                    <h2 class="truncate-title">LSTM Gates: Visual Representation</h2>
                    <div style="font-size: 0.8em;">
                        <img src="images/lstm-0.svg" alt="LSTM Gates Computation" style="max-width: 90%; height: auto; margin: 20px auto; display: block;">
                        <div class="fragment emphasis-box" style="background: #F5F5F5; margin-top: 20px;">
                            <p style="margin: 0; font-size: 0.95em;">üí° Each gate is a <strong>fully connected layer</strong> with sigmoid activation, processing the concatenation of X<sub>t</sub> and H<sub>t-1</sub></p>
                        </div>
                    </div>
                </section>

                <!-- Slide 7: Input Node -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - LSTM", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}]'>
                    <h2 class="truncate-title">Input Node: Candidate Memory Cell</h2>
                    <div style="font-size: 0.65em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Input Node (CÃÉ<sub>t</sub>)</h4>
                            <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                                <p style="font-size: 0.95em; margin: 0;">Also called the <strong>candidate memory cell</strong> - represents new information that <em>could</em> be stored in memory</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Equation</h4>
                            <div style="background: #F5F5F5; padding: 20px; border-radius: 8px; text-align: center;">
                                <p style="font-size: 1.2em; margin: 0;">$$\tilde{\mathbf{C}}_t = \textrm{tanh}(\mathbf{X}_t \mathbf{W}_{\textrm{xc}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hc}} + \mathbf{b}_\textrm{c})$$</p>
                            </div>
                            <p style="margin-top: 15px; font-size: 0.9em;"><strong>Where:</strong> W<sub>xc</sub> ‚àà ‚Ñù<sup>d√óh</sup>, W<sub>hc</sub> ‚àà ‚Ñù<sup>h√óh</sup>, b<sub>c</sub> ‚àà ‚Ñù<sup>1√óh</sup></p>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Key Difference from Gates</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; font-size: 0.9em;">
                                <div style="background: #FFFBF0; padding: 15px; border-radius: 8px; border: 2px solid #FAC55B;">
                                    <p style="margin: 0;"><strong>Gates:</strong> œÉ(¬∑) ‚Üí (0, 1)</p>
                                    <p style="font-size: 0.85em; margin: 8px 0 0 0;">Control <em>how much</em></p>
                                </div>
                                <div style="background: #F0FFF9; padding: 15px; border-radius: 8px; border: 2px solid #2DD2C0;">
                                    <p style="margin: 0;"><strong>Input Node:</strong> tanh(¬∑) ‚Üí (-1, 1)</p>
                                    <p style="font-size: 0.85em; margin: 8px 0 0 0;">Represents <em>what</em> content</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 8: Input Node Diagram -->
                <section data-sources='[{"text": "Dive into Deep Learning - LSTM", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html"}]'>
                    <h2 class="truncate-title">Input Node: Visual Representation</h2>
                    <div style="font-size: 0.8em;">
                        <img src="images/lstm-1.svg" alt="LSTM Input Node" style="max-width: 90%; height: auto; margin: 20px auto; display: block;">
                        <div class="fragment emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; margin-top: 20px;">
                            <p style="margin: 0; font-size: 0.95em;">üí° Similar structure to gates, but uses <span class="tooltip">tanh activation<span class="tooltiptext">Hyperbolic tangent function: maps inputs to range (-1, 1), allowing both positive and negative values to represent increases and decreases in memory</span></span> to generate candidate values</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 9: Memory Cell Internal State -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - LSTM", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}]'>
                    <h2 class="truncate-title">Memory Cell Internal State Update</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Update Equation</h4>
                            <div style="background: #F5F5F5; padding: 20px; border-radius: 8px; text-align: center; margin: 15px 0;">
                                <p style="font-size: 1.3em; margin: 0;">$$\mathbf{C}_t = \mathbf{F}_t \odot \mathbf{C}_{t-1} + \mathbf{I}_t \odot \tilde{\mathbf{C}}_t$$</p>
                            </div>
                            <p style="font-size: 0.9em; text-align: center; margin: 8px 0;">where ‚äô is the <span class="tooltip">Hadamard product<span class="tooltiptext">Element-wise multiplication of two vectors or matrices: (a‚äôb)<sub>i</sub> = a<sub>i</sub> √ó b<sub>i</sub></span></span> (element-wise multiplication)</p>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Breaking It Down</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; font-size: 0.85em;">
                                <div style="background: #FFFBF0; padding: 15px; border-radius: 8px; border-left: 4px solid #FFA05F;">
                                    <p style="margin: 0 0 8px 0; color: #FFA05F;"><strong>Forget: F<sub>t</sub> ‚äô C<sub>t-1</sub></strong></p>
                                    <p style="font-size: 0.9em; margin: 0;">Controls what to <strong>keep</strong> from old memory</p>
                                    <p style="font-size: 0.85em; margin: 8px 0 0 0; font-style: italic;">F<sub>t</sub> ‚âà 1: keep, F<sub>t</sub> ‚âà 0: forget</p>
                                </div>
                                <div style="background: #FFF5F5; padding: 15px; border-radius: 8px; border-left: 4px solid #FC8484;">
                                    <p style="margin: 0 0 8px 0; color: #FC8484;"><strong>Input: I<sub>t</sub> ‚äô CÃÉ<sub>t</sub></strong></p>
                                    <p style="font-size: 0.9em; margin: 0;">Controls what to <strong>add</strong> to memory</p>
                                    <p style="font-size: 0.85em; margin: 8px 0 0 0; font-style: italic;">I<sub>t</sub> ‚âà 1: use new info, I<sub>t</sub> ‚âà 0: ignore</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                            <p style="margin: 0; font-size: 0.95em;">üéØ <strong>Key Property:</strong> If F<sub>t</sub> = 1 and I<sub>t</sub> = 0, then C<sub>t</sub> = C<sub>t-1</sub> (memory preserved unchanged!)</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 10: Memory Cell Diagram -->
                <section data-sources='[{"text": "Dive into Deep Learning - LSTM", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html"}]'>
                    <h2 class="truncate-title">Memory Cell Internal State: Visual Flow</h2>
                    <div style="font-size: 0.8em;">
                        <img src="images/lstm-2.svg" alt="LSTM Memory Cell State" style="max-width: 95%; height: auto; margin: 15px auto; display: block;">
                        <div class="fragment emphasis-box" style="background: #FFFBF0; border-left: 4px solid #FAC55B; margin-top: 15px;">
                            <p style="margin: 0; font-size: 0.95em;">üí° <strong>The Magic:</strong> The memory cell state C<sub>t</sub> flows horizontally with minimal transformation, allowing <span class="tooltip">gradient flow<span class="tooltiptext">The backward flow of gradients during backpropagation, which is essential for learning via gradient descent</span></span> across many time steps</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 11: MCQ on Memory Cell -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "In the memory cell update equation C_t = F_t ‚äô C_{t-1} + I_t ‚äô CÃÉ_t, what happens if F_t ‚âà 1 and I_t ‚âà 0?",
                        "type": "single",
                        "options": [
                            {
                                "text": "The memory cell is completely reset to zero",
                                "correct": false,
                                "explanation": "F_t ‚âà 1 means we keep the old memory (not reset it). Resetting would require F_t ‚âà 0."
                            },
                            {
                                "text": "The memory cell stores only the new candidate values",
                                "correct": false,
                                "explanation": "I_t ‚âà 0 means we ignore the new candidate values. To store new values, we need I_t ‚âà 1."
                            },
                            {
                                "text": "The memory cell maintains its previous value unchanged",
                                "correct": true,
                                "explanation": "Correct! F_t ‚âà 1 keeps the old memory (C_{t-1}) and I_t ‚âà 0 ignores new input, so C_t ‚âà C_{t-1}. This allows LSTMs to preserve information over long sequences."
                            },
                            {
                                "text": "The memory cell averages the old and new values equally",
                                "correct": false,
                                "explanation": "Equal averaging would require F_t ‚âà 0.5 and I_t ‚âà 0.5. Here F_t ‚âà 1 and I_t ‚âà 0, so old values dominate."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 12: Hidden State Output -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - LSTM", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}]'>
                    <h2 class="truncate-title">Hidden State: The Output</h2>
                    <div style="font-size: 0.65em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Final Step: Computing Hidden State</h4>
                            <div style="background: #F5F5F5; padding: 20px; border-radius: 8px; text-align: center; margin: 15px 0;">
                                <p style="font-size: 1.3em; margin: 0;">$$\mathbf{H}_t = \mathbf{O}_t \odot \tanh(\mathbf{C}_t)$$</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Understanding the Components</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; font-size: 0.85em;">
                                <div style="background: #F0FFF9; padding: 15px; border-radius: 8px; border: 2px solid #2DD2C0;">
                                    <p style="margin: 0 0 8px 0; color: #2DD2C0;"><strong>Output Gate O<sub>t</sub></strong></p>
                                    <p style="font-size: 0.9em; margin: 0;">Controls what information from memory is exposed in the hidden state</p>
                                </div>
                                <div style="background: #FFFBF0; padding: 15px; border-radius: 8px; border: 2px solid #FAC55B;">
                                    <p style="margin: 0 0 8px 0; color: #FAC55B;"><strong>tanh(C<sub>t</sub>)</strong></p>
                                    <p style="font-size: 0.9em; margin: 0;">Squashes memory to (-1, 1) range for numerical stability</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Important Distinction</h4>
                            <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                                <ul style="font-size: 0.9em; margin: 0; line-height: 1.8;">
                                    <li><strong>Memory Cell State (C<sub>t</sub>):</strong> Internal, maintained across time steps</li>
                                    <li><strong>Hidden State (H<sub>t</sub>):</strong> External output, passed to next layer and next time step</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 13: Complete LSTM Diagram -->
                <section data-sources='[{"text": "Dive into Deep Learning - LSTM", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html"}]'>
                    <h2 class="truncate-title">Complete LSTM Cell: Putting It All Together</h2>
                    <div style="font-size: 0.75em;">
                        <img src="images/lstm-3.svg" alt="Complete LSTM Cell" style="max-width: 100%; height: auto; margin: 10px auto; display: block;">
                        <div class="fragment emphasis-box" style="background: #F5F5F5; margin-top: 15px;">
                            <p style="margin: 0; font-size: 0.9em;"><strong>Summary:</strong> X<sub>t</sub> and H<sub>t-1</sub> ‚Üí 3 gates + 1 candidate ‚Üí C<sub>t</sub> update ‚Üí H<sub>t</sub> output</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 14: Interactive LSTM Visualization -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - LSTM", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}]'>
                    <h2 class="truncate-title">Interactive LSTM Architecture</h2>
                    <div style="font-size: 0.7em;">
                        <p style="text-align: center; margin-bottom: 15px; color: #10099F;">
                            <strong>Hover over components to see formulas and parameters</strong>
                        </p>
                        <div id="lstm-interactive-viz" style="width: 100%; height: 500px; position: relative;"></div>
                    </div>
                </section>

                <!-- Slide 15: Implementation - Model Parameters -->
                <section data-sources='[{"text": "Dive into Deep Learning - LSTM Implementation", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html#initializing-model-parameters"}]'>
                    <h2 class="truncate-title">LSTM Implementation: Model Parameters</h2>
                    <div style="font-size: 0.65em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Loading the Dataset</h4>
                            <pre style="margin: 10px 0;"><code class="python" style="font-size: 0.95em;">data = d2l.TimeMachine(batch_size=1024, num_steps=32)</code></pre>
                        </div>

                        <div class="fragment" style="margin-top: 15px;">
                            <h4 style="color: #10099F;">Initializing Parameters</h4>
                            <pre style="margin: 10px 0;"><code class="python" style="font-size: 0.9em;">class LSTMScratch(d2l.Module):
    def __init__(self, num_inputs, num_hiddens, sigma=0.01):
        super().__init__()
        self.save_hyperparameters()

        init_weight = lambda *shape: nn.Parameter(torch.randn(*shape) * sigma)
        triple = lambda: (init_weight(num_inputs, num_hiddens),
                         init_weight(num_hiddens, num_hiddens),
                         nn.Parameter(torch.zeros(num_hiddens)))

        self.W_xi, self.W_hi, self.b_i = triple()  # Input gate
        self.W_xf, self.W_hf, self.b_f = triple()  # Forget gate
        self.W_xo, self.W_ho, self.b_o = triple()  # Output gate
        self.W_xc, self.W_hc, self.b_c = triple()  # Input node</code></pre>
                        </div>

                        <div class="fragment emphasis-box" style="background: #FFFBF0; border-left: 4px solid #FAC55B; margin-top: 15px;">
                            <p style="margin: 0; font-size: 0.95em;">üí° <strong>Note:</strong> Three weight matrices for each gate (x‚Üígate, h‚Üígate) plus one for the candidate cell = <strong>8 weight matrices total</strong></p>
                        </div>
                    </div>
                </section>

                <!-- Slide 15: Implementation - Forward Pass -->
                <section data-sources='[{"text": "Dive into Deep Learning - LSTM Implementation", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html#initializing-model-parameters"}]'>
                    <h2 class="truncate-title">LSTM Implementation: Forward Pass</h2>
                    <div style="font-size: 0.6em;">
                        <pre style="margin: 10px 0;"><code class="python" style="font-size: 0.95em;">@d2l.add_to_class(LSTMScratch)
def forward(self, inputs, H_C=None):
    if H_C is None:
        # Initial state with shape: (batch_size, num_hiddens)
        H = torch.zeros((inputs.shape[1], self.num_hiddens),
                       device=inputs.device)
        C = torch.zeros((inputs.shape[1], self.num_hiddens),
                       device=inputs.device)
    else:
        H, C = H_C
    outputs = []
    for X in inputs:
        I = torch.sigmoid(torch.matmul(X, self.W_xi) +
                         torch.matmul(H, self.W_hi) + self.b_i)
        F = torch.sigmoid(torch.matmul(X, self.W_xf) +
                         torch.matmul(H, self.W_hf) + self.b_f)
        O = torch.sigmoid(torch.matmul(X, self.W_xo) +
                         torch.matmul(H, self.W_ho) + self.b_o)
        C_tilde = torch.tanh(torch.matmul(X, self.W_xc) +
                            torch.matmul(H, self.W_hc) + self.b_c)
        C = F * C + I * C_tilde
        H = O * torch.tanh(C)
        outputs.append(H)
    return outputs, (H, C)</code></pre>

                        <div class="fragment emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; margin-top: 15px;">
                            <p style="margin: 0; font-size: 1em;">üí° <strong>Key:</strong> Returns both outputs and the state tuple (H, C) for next time step</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 16: MCQ on Implementation -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "How many weight matrices does an LSTM cell have (not counting biases)?",
                        "type": "single",
                        "options": [
                            {
                                "text": "3 weight matrices (one for each gate)",
                                "correct": false,
                                "explanation": "Each gate needs TWO weight matrices (input‚Üígate and hidden‚Üígate), plus the candidate cell also needs two. Total is 8."
                            },
                            {
                                "text": "4 weight matrices (three gates plus candidate cell)",
                                "correct": false,
                                "explanation": "This counts the number of components, but each component needs two weight matrices (one for input, one for hidden state)."
                            },
                            {
                                "text": "6 weight matrices (two for each gate)",
                                "correct": false,
                                "explanation": "Close! But dont forget the candidate cell CÃÉ_t also needs two weight matrices (W_xc and W_hc)."
                            },
                            {
                                "text": "8 weight matrices (two for each gate, plus two for candidate cell)",
                                "correct": true,
                                "explanation": "Correct! Each of the 3 gates (input, forget, output) needs W_x* and W_h*, plus the candidate cell needs W_xc and W_hc. Total: 3√ó2 + 2 = 8 weight matrices."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 17: Training the LSTM -->
                <section data-sources='[{"text": "Dive into Deep Learning - LSTM Training", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html#training-and-prediction"}]'>
                    <h2 class="truncate-title">Training the LSTM Model</h2>
                    <div style="font-size: 0.7em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Training Code</h4>
                            <pre style="margin: 10px 0;"><code class="python" style="font-size: 0.95em;">data = d2l.TimeMachine(batch_size=1024, num_steps=32)
lstm = LSTMScratch(num_inputs=len(data.vocab), num_hiddens=32)
model = d2l.RNNLMScratch(lstm, vocab_size=len(data.vocab), lr=4)
trainer = d2l.Trainer(max_epochs=50, gradient_clip_val=1, num_gpus=1)
trainer.fit(model, data)</code></pre>
                        </div>

                        <div class="fragment emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; margin-top: 15px;">
                            <p style="margin: 0; font-size: 0.95em;">üí° <strong>Note:</strong> Even from scratch, LSTM achieves good <span class="tooltip">perplexity<span class="tooltiptext">A measure of how well a language model predicts text; lower is better. Perplexity of 1 means perfect prediction.</span></span> on character-level language modeling</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 18: Concise Implementation -->
                <section data-sources='[{"text": "Dive into Deep Learning - LSTM Concise Implementation", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html#concise-implementation"}]'>
                    <h2 class="truncate-title">LSTM: Concise Implementation with PyTorch</h2>
                    <div style="font-size: 0.7em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Using Built-in nn.LSTM</h4>
                            <pre style="margin: 10px 0;"><code class="python" style="font-size: 0.95em;">class LSTM(d2l.RNN):
    def __init__(self, num_inputs, num_hiddens):
        d2l.Module.__init__(self)
        self.save_hyperparameters()
        self.rnn = nn.LSTM(num_inputs, num_hiddens)

    def forward(self, inputs, H_C=None):
        return self.rnn(inputs, H_C)

lstm = LSTM(num_inputs=len(data.vocab), num_hiddens=32)
model = d2l.RNNLM(lstm, vocab_size=len(data.vocab), lr=4)
trainer.fit(model, data)</code></pre>
                        </div>

                        <div class="fragment emphasis-box" style="background: #FFFBF0; border-left: 4px solid #FAC55B; margin-top: 15px;">
                            <p style="margin: 0; font-size: 0.95em;">‚ö° <strong>Advantage:</strong> Built-in implementation uses compiled operators ‚Üí significantly faster than Python loops</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 19: Prediction Example -->
                <section data-sources='[{"text": "Dive into Deep Learning - LSTM", "url": "https://d2l.ai/chapter_recurrent-modern/lstm.html#concise-implementation"}]'>
                    <h2 class="truncate-title">LSTM Prediction Example</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Generating Text</h4>
                            <pre style="margin: 10px 0;"><code class="python" style="font-size: 1em;">model.predict('it has', 20, data.vocab, d2l.try_gpu())</code></pre>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Output</h4>
                            <div style="background: #F5F5F5; padding: 20px; border-radius: 8px; text-align: center;">
                                <p style="font-family: 'Source Code Pro', monospace; font-size: 1.3em; margin: 0; color: #10099F;">
                                    "it has a the time travelly"
                                </p>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; margin-top: 25px;">
                            <p style="margin: 0; font-size: 0.95em;">üí° The LSTM has learned reasonable character-level patterns from "The Time Machine" dataset, generating plausible (though not perfect) continuations</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 20: LSTM Summary -->
                <section data-sources='[{"text": "Hochreiter & Schmidhuber (1997) - LSTM", "url": "https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory"}]'>
                    <h2 class="truncate-title">LSTM: Summary and Historical Impact</h2>
                    <div style="font-size: 0.6em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Key Innovations</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin: 15px 0; font-size: 0.9em;">
                                <div class="emphasis-box" style="background: #F0FFF9; border: 2px solid #2DD2C0;">
                                    <p style="margin: 0; font-size: 1em;"><strong>Memory Cell</strong></p>
                                    <p style="font-size: 0.85em; margin: 8px 0 0 0;">Internal state with weight-1 recurrent connection</p>
                                </div>
                                <div class="emphasis-box" style="background: #FFFBF0; border: 2px solid #FAC55B;">
                                    <p style="margin: 0; font-size: 1em;"><strong>Three Gates</strong></p>
                                    <p style="font-size: 0.85em; margin: 8px 0 0 0;">Input, forget, output - control information flow</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px; font-size: 0.9em;">
                            <h4 style="color: #10099F;">Historical Timeline</h4>
                            <div style="background: linear-gradient(135deg, #10099F 0%, #2DD2C0 100%); color: white; padding: 18px; border-radius: 8px;">
                                <ul style="font-size: 0.95em; line-height: 1.9; margin: 0;">
                                    <li><strong>1997:</strong> Published by Hochreiter & Schmidhuber</li>
                                    <li><strong>Mid-2000s:</strong> Rose to prominence with competition victories</li>
                                    <li><strong>2011-2017:</strong> Dominant model for sequence learning</li>
                                    <li><strong>2017+:</strong> Transformers emerge, but LSTMs remain important</li>
                                </ul>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="background: #FFFBF0; border-left: 4px solid #FAC55B; margin-top: 20px; font-size: 0.9em;">
                            <p style="margin: 0; font-size: 1em;">üéØ <strong>Legacy:</strong> Even Transformers owe key architectural ideas to LSTM (attention as gating mechanism)</p>
                        </div>

                        <div class="fragment emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; margin-top: 15px; font-size: 0.9em;">
                            <p style="margin: 0; font-size: 1em;">‚úÖ <strong>Solved:</strong> Vanishing and exploding gradients in RNNs through gated memory cells</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 21: MCQ on LSTM Summary -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "Which statement best describes the historical significance of LSTMs?",
                        "type": "single",
                        "options": [
                            {
                                "text": "LSTMs were the first type of recurrent neural network ever proposed",
                                "correct": false,
                                "explanation": "LSTMs came after basic RNNs. Elman-style RNNs were trained with backpropagation in 1990, and LSTMs were published in 1997."
                            },
                            {
                                "text": "LSTMs dominated sequence learning from 2011-2017 and influenced Transformer architecture",
                                "correct": true,
                                "explanation": "Correct! After rising to prominence in the mid-2000s, LSTMs were the dominant sequence model from 2011 until Transformers emerged in 2017. Key LSTM concepts like gating influenced Transformer design."
                            },
                            {
                                "text": "LSTMs completely solved all problems with training neural networks",
                                "correct": false,
                                "explanation": "LSTMs specifically addressed vanishing/exploding gradients in recurrent networks, but they dont solve all neural network training challenges."
                            },
                            {
                                "text": "LSTMs are no longer used after Transformers were invented",
                                "correct": false,
                                "explanation": "While Transformers are dominant for many tasks, LSTMs remain important and are still used in various applications, especially where sequential processing is beneficial."
                            }
                        ]
                    }'></div>
                </section>

            </section>

            <!-- Single Vertical Section: GRU (Gated Recurrent Units) -->
            <section>
                <!-- Slide 1: GRU Introduction -->
                <section data-sources='[{"text": "Cho et al. (2014) - GRU Paper", "url": "https://arxiv.org/abs/1409.1259"}, {"text": "Chung et al. (2014) - Empirical Evaluation of GRU", "url": "https://arxiv.org/abs/1412.3555"}, {"text": "Dive into Deep Learning - GRU", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html"}]'>
                    <h2 class="truncate-title">Gated Recurrent Units (GRU)</h2>
                    <div style="font-size: 0.8em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Quest for Simplicity</h4>
                            <div style="background: #F5F5F5; padding: 15px; border-radius: 8px; margin: 15px 0;">
                                <p style="font-size: 0.95em; line-height: 1.7; margin: 0;">As <span class="tooltip">LSTM<span class="tooltiptext">Long Short-Term Memory: A recurrent neural network architecture with three gates (input, forget, output) and an internal memory cell to capture long-term dependencies</span></span> rapidly gained popularity in the 2010s, researchers wondered:</p>
                                <p style="font-size: 1em; margin: 15px 0; text-align: center; font-style: italic; color: #10099F;">"Can we retain the key ideas but make it simpler and faster?"</p>
                            </div>
                        </div>
                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Enter the GRU (2014)</h4>
                            <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                                <p style="font-size: 0.95em; margin-bottom: 10px;"><strong>Key Innovation:</strong> Streamlined architecture with only <strong>2 gates</strong> instead of 3</p>
                                <ul style="font-size: 0.9em; line-height: 1.7; margin: 0;">
                                    <li><strong>Reset gate:</strong> Controls how much past to remember</li>
                                    <li><strong>Update gate:</strong> Controls how much to update with new info</li>
                                </ul>
                            </div>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0; font-size: 0.95em;">üéØ <strong>Result:</strong> Comparable performance to LSTM with faster computation</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 2: Reset and Update Gates Concept -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html"}]'>
                    <h2 class="truncate-title">Two Gates Instead of Three</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">LSTM: 3 Gates</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 10px; margin: 15px 0; font-size: 0.85em;">
                                <div style="text-align: center; background: #FFF5F5; padding: 12px; border-radius: 6px;">
                                    <strong style="color: #FC8484;">Input Gate</strong>
                                    <p style="font-size: 0.85em; margin: 5px 0 0 0;">What to add</p>
                                </div>
                                <div style="text-align: center; background: #FFFBF0; padding: 12px; border-radius: 6px;">
                                    <strong style="color: #FFA05F;">Forget Gate</strong>
                                    <p style="font-size: 0.85em; margin: 5px 0 0 0;">What to remove</p>
                                </div>
                                <div style="text-align: center; background: #F0FFF9; padding: 12px; border-radius: 6px;">
                                    <strong style="color: #2DD2C0;">Output Gate</strong>
                                    <p style="font-size: 0.85em; margin: 5px 0 0 0;">What to output</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">GRU: 2 Gates</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin: 15px 0; font-size: 0.9em;">
                                <div style="background: linear-gradient(135deg, #10099F 0%, #2DD2C0 100%); color: white; padding: 20px; border-radius: 8px;">
                                    <div style="text-align: center; font-size: 2em; margin-bottom: 10px;">üîÑ</div>
                                    <strong style="font-size: 1.1em;">Reset Gate (R<sub>t</sub>)</strong>
                                    <p style="margin: 10px 0 0 0; font-size: 0.9em; line-height: 1.5;">Controls how much of the <strong>previous state</strong> to remember when computing new candidate</p>
                                </div>
                                <div style="background: linear-gradient(135deg, #2DD2C0 0%, #00FFBA 100%); color: #262626; padding: 20px; border-radius: 8px;">
                                    <div style="text-align: center; font-size: 2em; margin-bottom: 10px;">‚öñÔ∏è</div>
                                    <strong style="font-size: 1.1em;">Update Gate (Z<sub>t</sub>)</strong>
                                    <p style="margin: 10px 0 0 0; font-size: 0.9em; line-height: 1.5;">Controls how much of the <strong>old state</strong> to keep vs. <strong>new candidate</strong> to use</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0; font-size: 0.95em;">üí° Both gates use <strong>sigmoid activation</strong> ‚Üí output ‚àà (0, 1) ‚Üí act like valves</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 3: Reset and Update Gates Mathematics -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html"}]'>
                    <h2 class="truncate-title">Reset and Update Gates: Mathematics</h2>
                    <div style="font-size: 0.7em;">
                        <div class="fragment">
                            <div style="background: #F5F5F5; padding: 12px; border-radius: 8px; margin: 10px 0;">
                                <p style="margin: 0; font-size: 0.95em;"><strong>Inputs:</strong></p>
                                <ul style="margin: 5px 0; line-height: 1.6;">
                                    <li><strong>X<sub>t</sub></strong> ‚àà ‚Ñù<sup>n√ód</sup>: Current input (n = batch size, d = input features)</li>
                                    <li><strong>H<sub>t-1</sub></strong> ‚àà ‚Ñù<sup>n√óh</sup>: Previous hidden state (h = hidden units)</li>
                                </ul>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 15px; font-size: 0.8em;">
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px;">
                                <div style="background: linear-gradient(135deg, #F0F9FF 0%, #E0F2FE 100%); padding: 15px; border-radius: 8px; border-left: 4px solid #10099F;">
                                    <p style="margin: 0 0 10px 0; color: #10099F; font-size: 1em;"><strong>Reset Gate R<sub>t</sub></strong></p>
                                    <div style="background: white; padding: 12px; border-radius: 6px; text-align: center;">
                                        <p style="font-size: 1.1em; margin: 0;">$$\mathbf{R}_t = \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xr}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hr}} + \mathbf{b}_\textrm{r})$$</p>
                                    </div>
                                    <p style="margin: 10px 0 0 0; font-size: 0.85em; line-height: 1.5;"><strong>Output:</strong> R<sub>t</sub> ‚àà ‚Ñù<sup>n√óh</sup>, values ‚àà (0, 1)</p>
                                </div>

                                <div style="background: linear-gradient(135deg, #F0FFF9 0%, #E0F9F4 100%); padding: 15px; border-radius: 8px; border-left: 4px solid #2DD2C0;">
                                    <p style="margin: 0 0 10px 0; color: #2DD2C0; font-size: 1em;"><strong>Update Gate Z<sub>t</sub></strong></p>
                                    <div style="background: white; padding: 12px; border-radius: 6px; text-align: center;">
                                        <p style="font-size: 1.1em; margin: 0;">$$\mathbf{Z}_t = \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xz}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hz}} + \mathbf{b}_\textrm{z})$$</p>
                                    </div>
                                    <p style="margin: 10px 0 0 0; font-size: 0.85em; line-height: 1.5;"><strong>Output:</strong> Z<sub>t</sub> ‚àà ‚Ñù<sup>n√óh</sup>, values ‚àà (0, 1)</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 15px;">
                            <div style="background: #F5F5F5; padding: 12px; border-radius: 8px;">
                                <p style="margin: 0; font-size: 0.9em;"><strong>Parameters:</strong></p>
                                <ul style="margin: 5px 0; line-height: 1.6; font-size: 0.9em;">
                                    <li>W<sub>xr</sub>, W<sub>xz</sub> ‚àà ‚Ñù<sup>d√óh</sup>: Input-to-hidden weight matrices</li>
                                    <li>W<sub>hr</sub>, W<sub>hz</sub> ‚àà ‚Ñù<sup>h√óh</sup>: Hidden-to-hidden weight matrices</li>
                                    <li>b<sub>r</sub>, b<sub>z</sub> ‚àà ‚Ñù<sup>1√óh</sup>: Bias vectors</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 4: Gates Diagram -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html"}]'>
                    <h2 class="truncate-title">Computing Reset and Update Gates</h2>
                    <div style="font-size: 0.8em;">
                        <img src="images/gru-1.svg" alt="GRU Reset and Update Gates" style="max-width: 85%; height: auto; margin: 20px auto; display: block;">
                        <div class="fragment emphasis-box" style="background: #F5F5F5; margin-top: 20px;">
                            <p style="margin: 0; font-size: 0.95em;">üí° Both gates are computed in parallel using the same inputs (X<sub>t</sub> and H<sub>t-1</sub>), each with its own set of weights</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 5: MCQ on Gates -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "What is the main role of the reset gate in a GRU?",
                        "type": "single",
                        "options": [
                            {
                                "text": "It controls how much of the old hidden state to keep in the final output",
                                "correct": false,
                                "explanation": "This describes the update gate, not the reset gate. The reset gate has a different role."
                            },
                            {
                                "text": "It controls how much of the previous hidden state to use when computing the candidate hidden state",
                                "correct": true,
                                "explanation": "Correct! The reset gate determines how much past information to consider when creating the new candidate. A reset gate close to 0 means ignore the past."
                            },
                            {
                                "text": "It decides whether to output the hidden state or keep it internal",
                                "correct": false,
                                "explanation": "GRUs dont have a separate output gate like LSTMs. The hidden state is always output directly (after being processed by the update gate)."
                            },
                            {
                                "text": "It removes outdated information from the memory cell",
                                "correct": false,
                                "explanation": "GRUs dont have a separate memory cell like LSTMs. The reset gate controls information flow when computing the candidate, not removing from memory."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 6: Candidate Hidden State -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html"}]'>
                    <h2 class="truncate-title">Candidate Hidden State</h2>
                    <div style="font-size: 0.55em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Computing the Candidate HÃÉ<sub>t</sub></h4>
                            <div style="background: linear-gradient(135deg, #FFFBF0 0%, #FFF5E0 100%); padding: 20px; border-radius: 8px; margin: 15px 0; border-left: 4px solid #FFA05F;">
                                <p style="font-size: 1.15em; margin: 0 0 15px 0; text-align: center;">$$\tilde{\mathbf{H}}_t = \textrm{tanh}(\mathbf{X}_t \mathbf{W}_{\textrm{xh}} + (\mathbf{R}_t \odot \mathbf{H}_{t-1}) \mathbf{W}_{\textrm{hh}} + \mathbf{b}_\textrm{h})$$</p>
                                <p style="margin: 0; font-size: 0.9em; line-height: 1.6;"><strong>Where:</strong> ‚äô denotes <span class="tooltip">element-wise multiplication<span class="tooltiptext">Also called Hadamard product: multiplies corresponding elements of two matrices/vectors of the same shape</span></span></p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #10099F;">Key Insight: Reset Gate in Action</h4>
                            <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                                <p style="font-size: 0.95em; margin-bottom: 10px;">The <strong>reset gate R<sub>t</sub></strong> multiplies the previous hidden state <strong>before</strong> it's used:</p>
                                <ul style="font-size: 0.9em; line-height: 1.7; margin: 0;">
                                    <li><strong>R<sub>t</sub> ‚âà 0:</strong> Ignore past ‚Üí "reset" to only use current input</li>
                                    <li><strong>R<sub>t</sub> ‚âà 1:</strong> Keep past ‚Üí use full history</li>
                                </ul>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #10099F;">Comparison to LSTM</h4>
                            <div style="background: #F5F5F5; padding: 15px; border-radius: 8px;">
                                <p style="margin: 0; font-size: 0.9em; line-height: 1.6;">Similar to LSTM's <strong>candidate memory cell</strong> CÃÉ<sub>t</sub>, but in GRU, the candidate directly becomes (part of) the hidden state, not a separate memory</p>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 7: Candidate Diagram -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html"}]'>
                    <h2 class="truncate-title">Computing Candidate Hidden State</h2>
                    <div style="font-size: 0.8em;">
                        <img src="images/gru-2.svg" alt="GRU Candidate Hidden State" style="max-width: 85%; height: auto; margin: 20px auto; display: block;">
                        <div class="fragment emphasis-box" style="background: #FFFBF0; border-left: 4px solid #FAC55B; margin-top: 20px;">
                            <p style="margin: 0; font-size: 0.95em;">üí° Notice how R<sub>t</sub> gates (‚äô) the previous hidden state H<sub>t-1</sub> before it contributes to the candidate</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 8: Hidden State Update -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html"}]'>
                    <h2 class="truncate-title">Hidden State Update: The Update Gate</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Final Step: Combining Old and New</h4>
                            <div style="background: linear-gradient(135deg, #F0FFF9 0%, #E0F9F4 100%); padding: 20px; border-radius: 8px; margin: 15px 0; border-left: 4px solid #2DD2C0;">
                                <p style="font-size: 1.2em; margin: 0 0 15px 0; text-align: center;">$$\mathbf{H}_t = \mathbf{Z}_t \odot \mathbf{H}_{t-1} + (1 - \mathbf{Z}_t) \odot \tilde{\mathbf{H}}_t$$</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #10099F;">Intuition: Interpolation</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 12px; font-size: 0.85em;">
                                <div class="emphasis-box" style="background: #FFF5F5; text-align: center; padding: 15px;">
                                    <p style="margin: 0 0 8px 0;"><strong>Z<sub>t</sub> ‚âà 1</strong></p>
                                    <p style="font-size: 0.9em; margin: 0; line-height: 1.5;">Keep <strong>old</strong> state<br>H<sub>t</sub> ‚âà H<sub>t-1</sub></p>
                                    <p style="margin: 8px 0 0 0; font-size: 0.85em; color: #666;">Ignore new input</p>
                                </div>
                                <div class="emphasis-box" style="background: #FFFBF0; text-align: center; padding: 15px;">
                                    <p style="margin: 0 0 8px 0;"><strong>Z<sub>t</sub> ‚âà 0.5</strong></p>
                                    <p style="font-size: 0.9em; margin: 0; line-height: 1.5;">Mix <strong>both</strong><br>H<sub>t</sub> = 50%-50%</p>
                                    <p style="margin: 8px 0 0 0; font-size: 0.85em; color: #666;">Balanced blend</p>
                                </div>
                                <div class="emphasis-box" style="background: #F0FFF9; text-align: center; padding: 15px;">
                                    <p style="margin: 0 0 8px 0;"><strong>Z<sub>t</sub> ‚âà 0</strong></p>
                                    <p style="font-size: 0.9em; margin: 0; line-height: 1.5;">Use <strong>new</strong> candidate<br>H<sub>t</sub> ‚âà HÃÉ<sub>t</sub></p>
                                    <p style="margin: 8px 0 0 0; font-size: 0.85em; color: #666;">Fresh start</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0; font-size: 0.95em;">üéØ <strong>Key Advantage:</strong> The update gate acts as a <span class="tooltip">learnable interpolation<span class="tooltiptext">The network learns optimal mixing ratios for each hidden unit at each time step during training</span></span> between keeping old information and accepting new information</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 9: Hidden State Update Diagram -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html"}]'>
                    <h2 class="truncate-title">Complete GRU Architecture</h2>
                    <div style="font-size: 0.8em;">
                        <img src="images/gru-3.svg" alt="GRU Hidden State Update" style="max-width: 85%; height: auto; margin: 20px auto; display: block;">
                        <div class="fragment emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; margin-top: 20px;">
                            <p style="margin: 0; font-size: 0.95em;">üí° The update gate Z<sub>t</sub> determines the final blend: Z<sub>t</sub> controls how much old vs. new (1-Z<sub>t</sub>)</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 10: MCQ on Update Mechanism -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "If the update gate Z_t has values close to 1 for all hidden units at time step t, what happens?",
                        "type": "single",
                        "options": [
                            {
                                "text": "The hidden state is completely replaced with the candidate hidden state",
                                "correct": false,
                                "explanation": "This would happen if Z_t ‚âà 0. When Z_t ‚âà 1, the opposite occurs - the old state is retained."
                            },
                            {
                                "text": "The previous hidden state H_{t-1} is mostly retained and the new candidate is mostly ignored",
                                "correct": true,
                                "explanation": "Correct! The formula H_t = Z_t ‚äô H_{t-1} + (1-Z_t) ‚äô HÃÉ_t shows that when Z_t ‚âà 1, we get H_t ‚âà H_{t-1}, keeping the old state."
                            },
                            {
                                "text": "The reset gate is activated to clear the memory",
                                "correct": false,
                                "explanation": "The reset and update gates serve different purposes. The reset gate affects the candidate computation, not the final state update."
                            },
                            {
                                "text": "Both old and new states are averaged equally",
                                "correct": false,
                                "explanation": "Equal averaging would occur when Z_t ‚âà 0.5. When Z_t ‚âà 1, the old state dominates."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 11: Implementation - Initialization -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU Implementation", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html#implementation-from-scratch"}]'>
                    <h2 class="truncate-title">Implementation from Scratch: Initializing Parameters</h2>
                    <div style="font-size: 0.7em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Model Parameters</h4>
                            <div style="background: #F5F5F5; padding: 12px; border-radius: 8px; margin: 10px 0;">
                                <p style="margin: 0 0 8px 0; font-size: 0.9em;">For a GRU with <strong>num_inputs</strong> input features and <strong>num_hiddens</strong> hidden units:</p>
                                <ul style="margin: 0; line-height: 1.7; font-size: 0.9em;">
                                    <li><strong>6 weight matrices:</strong> W<sub>xz</sub>, W<sub>hz</sub>, W<sub>xr</sub>, W<sub>hr</sub>, W<sub>xh</sub>, W<sub>hh</sub></li>
                                    <li><strong>3 bias vectors:</strong> b<sub>z</sub>, b<sub>r</sub>, b<sub>h</sub></li>
                                </ul>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 15px;">
                            <h4 style="color: #10099F;">PyTorch Implementation</h4>
                            <pre><code class="python" style="font-size: 0.85em;">class GRUScratch(d2l.Module):
    def __init__(self, num_inputs, num_hiddens, sigma=0.01):
        super().__init__()
        self.save_hyperparameters()

        init_weight = lambda *shape: nn.Parameter(torch.randn(*shape) * sigma)
        triple = lambda: (init_weight(num_inputs, num_hiddens),
                         init_weight(num_hiddens, num_hiddens),
                         nn.Parameter(torch.zeros(num_hiddens)))

        self.W_xz, self.W_hz, self.b_z = triple()  # Update gate
        self.W_xr, self.W_hr, self.b_r = triple()  # Reset gate
        self.W_xh, self.W_hh, self.b_h = triple()  # Candidate hidden state</code></pre>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 15px; background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                            <p style="margin: 0; font-size: 0.9em;">üí° Weights initialized from Gaussian distribution with standard deviation <code>sigma</code>, biases initialized to zero</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 12: Implementation - Forward Pass -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU Implementation", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html#defining-the-model"}]'>
                    <h2 class="truncate-title">Implementation from Scratch: Forward Pass</h2>
                    <div style="font-size: 0.68em;">
                        <div class="fragment">
                            <pre><code class="python" style="font-size: 0.9em;">@d2l.add_to_class(GRUScratch)
def forward(self, inputs, H=None):
    if H is None:
        # Initial state with shape: (batch_size, num_hiddens)
        H = torch.zeros((inputs.shape[1], self.num_hiddens),
                       device=inputs.device)
    outputs = []
    for X in inputs:
        # Update gate
        Z = torch.sigmoid(torch.matmul(X, self.W_xz) +
                         torch.matmul(H, self.W_hz) + self.b_z)
        # Reset gate
        R = torch.sigmoid(torch.matmul(X, self.W_xr) +
                         torch.matmul(H, self.W_hr) + self.b_r)
        # Candidate hidden state (note: R * H applies reset)
        H_tilde = torch.tanh(torch.matmul(X, self.W_xh) +
                            torch.matmul(R * H, self.W_hh) + self.b_h)
        # Final hidden state update
        H = Z * H + (1 - Z) * H_tilde
        outputs.append(H)
    return outputs, H</code></pre>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 15px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0; font-size: 0.95em;">üéØ Three key computations per time step: (1) Update gate, (2) Reset gate, (3) Candidate with reset applied, then (4) Interpolate old and new</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 13: Training Results -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU Training", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html#training"}]'>
                    <h2 class="truncate-title">Training a GRU Language Model</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Training Setup</h4>
                            <div style="background: #F5F5F5; padding: 12px; border-radius: 8px; margin: 10px 0;">
                                <p style="margin: 0; font-size: 0.9em; line-height: 1.6;"><strong>Task:</strong> Language modeling on <em>The Time Machine</em> dataset<br>
                                <strong>Config:</strong> 32 hidden units, batch size 1024, 32 time steps, learning rate 4</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 15px;">
                            <pre><code class="python" style="font-size: 0.85em;">data = d2l.TimeMachine(batch_size=1024, num_steps=32)
gru = GRUScratch(num_inputs=len(data.vocab), num_hiddens=32)
model = d2l.RNNLMScratch(gru, vocab_size=len(data.vocab), lr=4)
trainer = d2l.Trainer(max_epochs=50, gradient_clip_val=1, num_gpus=1)
trainer.fit(model, data)</code></pre>
                        </div>

                        <div class="fragment" style="margin-top: 15px;">
                            <h4 style="color: #10099F;">Sample Generation</h4>
                            <pre><code class="python" style="font-size: 0.85em;">model.predict('it has', 20, data.vocab, d2l.try_gpu())</code></pre>
                            <div style="background: #F0FFF9; padding: 12px; border-radius: 8px; margin-top: 10px;">
                                <p style="margin: 0; font-family: 'Source Code Pro', monospace; font-size: 0.9em;"><strong>Output:</strong> "it has so it and the time "</p>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 15px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0; font-size: 0.9em;">üí° The model learns to generate grammatically plausible text after training on sequences</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 14: Concise Implementation -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU Concise", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html#concise-implementation"}]'>
                    <h2 class="truncate-title">Concise Implementation with High-Level APIs</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">PyTorch Built-in GRU</h4>
                            <pre><code class="python" style="font-size: 0.9em;">class GRU(d2l.RNN):
    def __init__(self, num_inputs, num_hiddens):
        d2l.Module.__init__(self)
        self.save_hyperparameters()
        self.rnn = nn.GRU(num_inputs, num_hiddens)</code></pre>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #10099F;">Training with Built-in GRU</h4>
                            <pre><code class="python" style="font-size: 0.9em;">gru = GRU(num_inputs=len(data.vocab), num_hiddens=32)
model = d2l.RNNLM(gru, vocab_size=len(data.vocab), lr=4)
trainer.fit(model, data)</code></pre>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                            <p style="margin: 0; font-size: 0.95em;">‚ö° <strong>Significant speedup:</strong> High-level implementations use compiled operators and optimized <span class="tooltip">CUDA kernels<span class="tooltiptext">Low-level GPU-accelerated code that efficiently executes operations in parallel on graphics processors</span></span>, making training much faster than pure Python loops</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 15: GRU vs LSTM -->
                <section data-sources='[{"text": "Chung et al. (2014) - Empirical Evaluation", "url": "https://arxiv.org/abs/1412.3555"}, {"text": "Dive into Deep Learning - GRU", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html"}]'>
                    <h2 class="truncate-title">GRU vs LSTM: Comparison</h2>
                    <div style="font-size: 0.5em;">
                        <div class="fragment">
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 15px 0;">
                                <div style="background: linear-gradient(135deg, #10099F 0%, #2DD2C0 100%); color: white; padding: 20px; border-radius: 8px;">
                                    <h4 style="margin-top: 0; color: white;">GRU</h4>
                                    <ul style="margin: 0; line-height: 1.8; font-size: 0.9em;">
                                        <li><strong>2 gates:</strong> Reset, Update</li>
                                        <li><strong>No separate memory:</strong> Hidden state serves dual purpose</li>
                                        <li><strong>Simpler architecture:</strong> Fewer parameters</li>
                                        <li><strong>Faster:</strong> Fewer computations per step</li>
                                    </ul>
                                </div>

                                <div style="background: linear-gradient(135deg, #2DD2C0 0%, #00FFBA 100%); color: #262626; padding: 20px; border-radius: 8px;">
                                    <h4 style="margin-top: 0;">LSTM</h4>
                                    <ul style="margin: 0; line-height: 1.8; font-size: 0.9em;">
                                        <li><strong>3 gates:</strong> Input, Forget, Output</li>
                                        <li><strong>Separate memory cell:</strong> Internal state C<sub>t</sub></li>
                                        <li><strong>More expressive:</strong> More parameters</li>
                                        <li><strong>Slower:</strong> More gate computations</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #10099F;">Performance Comparison</h4>
                            <div class="emphasis-box" style="background: #FFFBF0; border-left: 4px solid #FAC55B;">
                                <p style="font-size: 0.95em; margin: 0; line-height: 1.7;">
                                    <strong>Empirical findings:</strong> GRUs achieve <strong>similar performance</strong> to LSTMs on many sequence tasks, but train <strong>10-30% faster</strong> due to fewer parameters and operations
                                </p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #10099F;">When to Use Which?</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 12px; font-size: 0.85em;">
                                <div style="background: #F0F9FF; padding: 12px; border-radius: 6px;">
                                    <p style="margin: 0 0 6px 0;"><strong>Prefer GRU:</strong></p>
                                    <ul style="margin: 0; line-height: 1.6; font-size: 0.9em;">
                                        <li>Speed is critical</li>
                                        <li>Limited computational resources</li>
                                        <li>Shorter sequences</li>
                                    </ul>
                                </div>
                                <div style="background: #F0FFF9; padding: 12px; border-radius: 6px;">
                                    <p style="margin: 0 0 6px 0;"><strong>Prefer LSTM:</strong></p>
                                    <ul style="margin: 0; line-height: 1.6; font-size: 0.9em;">
                                        <li>Very long sequences</li>
                                        <li>Complex dependencies</li>
                                        <li>When expressiveness matters</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 16: Summary -->
                <section data-sources='[{"text": "Dive into Deep Learning - GRU Summary", "url": "https://d2l.ai/chapter_recurrent-modern/gru.html#summary"}]'>
                    <h2 class="truncate-title">Summary: Gated Recurrent Units</h2>
                    <div style="font-size: 0.55em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Key Takeaways</h4>
                            <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; margin-bottom: 15px;">
                                <ul style="margin: 0; line-height: 1.8; font-size: 0.95em;">
                                    <li><strong>Streamlined LSTM:</strong> GRUs reduce 3 gates to 2, making them simpler and faster</li>
                                    <li><strong>Reset gate:</strong> Controls how much past information influences the candidate</li>
                                    <li><strong>Update gate:</strong> Interpolates between old hidden state and new candidate</li>
                                    <li><strong>Performance:</strong> Similar to LSTM on many tasks, with computational advantages</li>
                                </ul>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #10099F;">Core Equations (Recap)</h4>
                            <div style="background: #F5F5F5; padding: 15px; border-radius: 8px; font-size: 0.9em;">
                                <p style="margin: 0 0 8px 0;">$$\mathbf{R}_t = \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xr}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hr}} + \mathbf{b}_\textrm{r})$$</p>
                                <p style="margin: 8px 0;">$$\mathbf{Z}_t = \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xz}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hz}} + \mathbf{b}_\textrm{z})$$</p>
                                <p style="margin: 8px 0;">$$\tilde{\mathbf{H}}_t = \textrm{tanh}(\mathbf{X}_t \mathbf{W}_{\textrm{xh}} + (\mathbf{R}_t \odot \mathbf{H}_{t-1}) \mathbf{W}_{\textrm{hh}} + \mathbf{b}_\textrm{h})$$</p>
                                <p style="margin: 8px 0 0 0;">$$\mathbf{H}_t = \mathbf{Z}_t \odot \mathbf{H}_{t-1} + (1 - \mathbf{Z}_t) \odot \tilde{\mathbf{H}}_t$$</p>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0; font-size: 0.95em;">üí° <strong>Practical Impact:</strong> GRUs have become a popular default choice for many sequence tasks due to their excellent performance-to-complexity ratio</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 17: Final MCQ -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "What happens in a GRU when the update gate Z_t is close to 1 for all time steps in a sequence?",
                        "type": "single",
                        "options": [
                            {
                                "text": "The GRU behaves like a standard feedforward network, ignoring sequence information",
                                "correct": false,
                                "explanation": "When Z_t ‚âà 1, the hidden state is preserved across time steps, so sequence information is maintained, not ignored."
                            },
                            {
                                "text": "The hidden state is mostly preserved across time steps, making the network remember long-term patterns but adapt slowly to new inputs",
                                "correct": true,
                                "explanation": "Correct! Z_t ‚âà 1 means H_t ‚âà H_{t-1}, so the state persists across time. This helps remember long-term patterns but makes the network less responsive to new information."
                            },
                            {
                                "text": "The GRU becomes equivalent to an LSTM with all gates open",
                                "correct": false,
                                "explanation": "GRUs and LSTMs have fundamentally different architectures. A specific gate configuration in one doesnt make it equivalent to the other."
                            },
                            {
                                "text": "The network will suffer from vanishing gradients because information cannot flow backward",
                                "correct": false,
                                "explanation": "Actually, Z_t ‚âà 1 helps gradient flow because H_t ‚âà H_{t-1} creates a nearly direct path for gradients, similar to LSTMs memory cell."
                            }
                        ]
                    }'></div>
                </section>

            </section>

            <!-- Single Vertical Section: Deep Recurrent Neural Networks -->
            <section>
                <!-- Slide 1: Title Slide -->
                <section class="title-slide" data-sources='[{"text": "Dive into Deep Learning - Section 10.3: Deep RNNs", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html"}]'>
                    <h1 class="truncate-title">Deep Recurrent Neural Networks</h1>
                    <p>Stacking RNN Layers for Greater Expressiveness</p>
                    <div style="margin-top: 50px; font-size: 0.85em;">
                        <p>Section 10.3: Deep RNN Architectures</p>
                    </div>
                </section>

                <!-- Slide 2: Motivation - Why Go Deep? -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.3", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html"}]'>
                    <h2 class="truncate-title">Why Go Deep? Two Dimensions of Depth</h2>
                    <div style="font-size: 0.8em;">
                        <div class="fragment" style="margin-bottom: 30px;">
                            <h4 style="color: #10099F;">Single-Layer RNNs Are Already "Deep" in Time</h4>
                            <p>With a single hidden layer, inputs from time step 1 can influence outputs at time step \(T\) (often 100s or 1000s of steps later). These inputs pass through \(T\) applications of the <span class="tooltip">recurrent layer<span class="tooltiptext">A layer that processes sequential data by maintaining a hidden state that is updated at each time step</span></span>.</p>
                        </div>

                        <div class="fragment">
                            <h4 style="color: #2DD2C0;">But We Also Want Depth in the Input-to-Output Direction</h4>
                            <p>We often wish to express <strong>complex relationships</strong> between inputs at a given time step and outputs at that <em>same</em> time step.</p>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 30px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0;"><strong>Solution:</strong> Build RNNs that are deep in <em>both</em> directions:</p>
                            <ul style="margin: 10px 0 0 20px; font-size: 0.95em;">
                                <li><strong>Temporal depth:</strong> Information flows across time steps</li>
                                <li><strong>Spatial depth:</strong> Stack RNN layers on top of each other</li>
                            </ul>
                        </div>
                    </div>
                </section>

                <!-- Slide 3: Architecture Diagram -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.3", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html"}]'>
                    <h2 class="truncate-title">Deep RNN Architecture</h2>
                    <div style="font-size: 0.85em;">
                        <p>Given a sequence of length \(T\), the first RNN produces outputs of length \(T\). These outputs become inputs to the next RNN layer.</p>

                        <div style="margin: 20px auto; max-width: 200px;">
                            <img src="images/deep-rnn.svg" alt="Deep RNN Architecture with L layers" style="width: 100%; background: white; padding: 20px; border-radius: 8px;">
                        </div>

                        <div class="emphasis-box" style="margin-top: 20px; font-size: 0.9em;">
                            <p style="margin: 0;"><strong>Key Insight:</strong> Each RNN cell (white box) at time step \(t\) depends on:</p>
                            <ul style="margin: 8px 0 0 20px;">
                                <li>The <strong>same layer's</strong> value at the <em>previous time step</em> \((t-1)\)</li>
                                <li>The <strong>previous layer's</strong> value at the <em>same time step</em> \(t\)</li>
                            </ul>
                        </div>
                    </div>
                </section>

                <!-- Slide 3.5: Interactive Deep RNN Visualization -->
                <section>
                    <h2 class="truncate-title">Interactive: Explore Deep RNN Architecture</h2>
                    <div style="font-size: 0.8em;">
                        <p style="margin-bottom: 15px;">Adjust the number of layers and time steps to see how information flows through a deep RNN:</p>
                        <div id="deep-rnn-interactive-viz" style="position: relative; width: 100%; height: 550px; background: #f9f9f9; border-radius: 8px; border: 2px solid #EEEEEE;"></div>
                    </div>
                </section>

                <!-- Slide 4: Mathematical Formulation -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.3", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html"}]'>
                    <h2 class="truncate-title">The Mathematics of Deep RNNs</h2>
                    <div style="font-size: 0.55em;">
                        <div style="margin-bottom: 20px;">
                            <h4 style="color: #10099F;">Notation</h4>
                            <ul style="font-size: 0.9em; line-height: 1.6;">
                                <li>\(\mathbf{X}_t \in \mathbb{R}^{n \times d}\): Input at time \(t\) (batch size \(n\), input dimension \(d\))</li>
                                <li>\(\mathbf{H}_t^{(l)} \in \mathbb{R}^{n \times h}\): Hidden state of layer \(l\) at time \(t\) (\(l=1,\ldots,L\))</li>
                                <li>\(\mathbf{O}_t \in \mathbb{R}^{n \times q}\): Output at time \(t\) (\(q\) outputs)</li>
                            </ul>
                        </div>

                        <div class="fragment">
                            <h4 style="color: #2DD2C0;">Hidden State Update for Layer \(l\)</h4>
                            <p>Setting \(\mathbf{H}_t^{(0)} = \mathbf{X}_t\), the hidden state is computed as:</p>
                            <div style="background: #F5F5F5; padding: 20px; border-radius: 8px; margin: 15px 0;">
                                $$\mathbf{H}_t^{(l)} = \phi_l(\color{#10099F}{\mathbf{H}_t^{(l-1)} \mathbf{W}_{\textrm{xh}}^{(l)}} + \color{#FC8484}{\mathbf{H}_{t-1}^{(l)} \mathbf{W}_{\textrm{hh}}^{(l)}} + \mathbf{b}_\textrm{h}^{(l)})$$
                            </div>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; font-size: 0.85em;">
                                <div class="emphasis-box" style="background: #F5F5FF; border-left: 3px solid #10099F;">
                                    <p style="margin: 0;"><strong style="color: #10099F;">Blue term:</strong> Input from layer \(l-1\) at time \(t\)</p>
                                </div>
                                <div class="emphasis-box" style="background: #FFF5F5; border-left: 3px solid #FC8484;">
                                    <p style="margin: 0;"><strong style="color: #FC8484;">Red term:</strong> Recurrent connection from time \(t-1\)</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <p style="font-size: 0.9em;"><strong>Parameters:</strong> \(\mathbf{W}_{\textrm{xh}}^{(l)}, \mathbf{W}_{\textrm{hh}}^{(l)} \in \mathbb{R}^{h \times h}\) and \(\mathbf{b}_\textrm{h}^{(l)} \in \mathbb{R}^{1 \times h}\)</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 5: MCQ #1 - Layer Interactions -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "In a deep RNN with L=3 layers, what information does the hidden state H_t^(2) at layer 2 and time step t depend on?",
                        "type": "multiple",
                        "options": [
                            {
                                "text": "The hidden state from layer 2 at time t-1",
                                "correct": true,
                                "explanation": "Correct! The recurrent connection means H_t^(2) depends on H_{t-1}^(2) through the term H_{t-1}^(l) W_hh^(l)."
                            },
                            {
                                "text": "The hidden state from layer 1 at time t",
                                "correct": true,
                                "explanation": "Correct! Layer 2 receives input from the layer below (layer 1) at the same time step through H_t^(l-1) W_xh^(l)."
                            },
                            {
                                "text": "The hidden state from layer 3 at time t",
                                "correct": false,
                                "explanation": "No, information flows forward through layers (from lower to higher), not backward. Layer 2 cannot depend on layer 3."
                            },
                            {
                                "text": "The original input X_t directly",
                                "correct": false,
                                "explanation": "Not directly. Layer 2 receives processed representations from layer 1, which itself was derived from X_t. Only layer 1 directly uses X_t."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 6: Output Layer -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.3", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html"}]'>
                    <h2 class="truncate-title">Computing the Final Output</h2>
                    <div style="font-size: 0.6em;">
                        <p>The output is computed <strong>only from the final (top) layer</strong>:</p>

                        <div style="background: #F5F5F5; padding: 25px; border-radius: 8px; margin: 20px 0;">
                            $$\mathbf{O}_t = \mathbf{H}_t^{(L)} \mathbf{W}_{\textrm{hq}} + \mathbf{b}_\textrm{q}$$
                        </div>

                        <div class="fragment" style="margin-top: 30px;">
                            <div style="display: flex; align-items: center; gap: 30px;">
                                <div style="flex: 1;">
                                    <div class="emphasis-box">
                                        <p style="margin: 0; font-size: 0.95em;"><strong>Why only the final layer?</strong></p>
                                        <ul style="margin: 10px 0 0 20px; font-size: 0.9em;">
                                            <li>Each layer learns progressively more abstract representations</li>
                                            <li>The top layer \(\mathbf{H}_t^{(L)}\) contains the most refined features</li>
                                            <li>Lower layers focus on extracting hierarchical patterns</li>
                                        </ul>
                                    </div>
                                </div>
                                <div style="flex: 0.8; text-align: center;">
                                    <div style="background: white; padding: 15px; border-radius: 8px; border: 2px solid #EEEEEE;">
                                        <div style="color: #FC8484; font-weight: bold; padding: 10px; background: #FFF5F5; border-radius: 5px; margin-bottom: 8px;">Output \(\mathbf{O}_t\)</div>
                                        <div style="font-size: 1.5em; color: #CCCCCC;">‚Üë</div>
                                        <div style="color: #10099F; font-weight: bold; padding: 10px; background: #F5F5FF; border-radius: 5px; margin-bottom: 8px;">Layer \(L\): \(\mathbf{H}_t^{(L)}\)</div>
                                        <div style="font-size: 1.5em; color: #CCCCCC;">‚ãÆ</div>
                                        <div style="color: #2DD2C0; font-weight: bold; padding: 10px; background: #F0FFFD; border-radius: 5px; margin-top: 8px;">Layer 1: \(\mathbf{H}_t^{(1)}\)</div>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px; font-size: 0.9em;">
                            <p><strong>Parameters:</strong> \(\mathbf{W}_{\textrm{hq}} \in \mathbb{R}^{h \times q}\) and \(\mathbf{b}_\textrm{q} \in \mathbb{R}^{1 \times q}\)</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 7: Hyperparameters -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.3", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html"}]'>
                    <h2 class="truncate-title">Choosing Network Depth and Width</h2>
                    <div style="font-size: 0.6em;">
                        <p>Like MLPs, the number of hidden layers \(L\) and hidden units \(h\) are <span class="tooltip">hyperparameters<span class="tooltiptext">Configuration parameters that are set before training begins and control the learning process or model architecture</span></span> that we can tune.</p>

                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 30px 0;">
                            <div class="emphasis-box" style="background: linear-gradient(135deg, #10099F 0%, #2DD2C0 100%); color: white; padding: 25px;">
                                <h4 style="margin-top: 0; color: white;">Layer Width: \(h\)</h4>
                                <p style="font-size: 1.2em; font-weight: bold; margin: 15px 0;">64 ‚Äì 2056</p>
                                <p style="font-size: 0.9em; margin: 0;">Number of hidden units per layer</p>
                            </div>
                            <div class="emphasis-box" style="background: linear-gradient(135deg, #2DD2C0 0%, #00FFBA 100%); color: #262626; padding: 25px;">
                                <h4 style="margin-top: 0;">Network Depth: \(L\)</h4>
                                <p style="font-size: 1.2em; font-weight: bold; margin: 15px 0;">1 ‚Äì 8</p>
                                <p style="font-size: 0.9em; margin: 0;">Number of stacked RNN layers</p>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px;">
                            <h4 style="color: #10099F; margin-top: 0;">Extending to Gated RNNs</h4>
                            <p style="margin: 0; font-size: 0.95em;">We can easily create a deep-<span class="tooltip">gated RNN<span class="tooltiptext">RNNs with gating mechanisms (like LSTM or GRU) that control information flow to better capture long-term dependencies</span></span> by replacing the hidden state computation with that from an <strong>LSTM</strong> or <strong>GRU</strong>.</p>
                        </div>

                        <div class="fragment" style="margin-top: 25px; padding: 15px; background: #FFFBF0; border-radius: 8px; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0; font-size: 0.9em;"><strong>Trade-offs:</strong> More layers and wider layers increase model capacity but also computational cost and risk of overfitting.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 8: MCQ #2 - Hyperparameters -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "You are building a deep RNN for a language modeling task. You want to increase the models capacity to capture complex patterns. Which approach is generally recommended?",
                        "type": "single",
                        "options": [
                            {
                                "text": "Set L=20 layers with h=16 hidden units each",
                                "correct": false,
                                "explanation": "While 20 layers is very deep, having only 16 hidden units per layer severely limits representational capacity. This network would be too narrow and difficult to train."
                            },
                            {
                                "text": "Set L=2-4 layers with h=512-1024 hidden units each",
                                "correct": true,
                                "explanation": "Correct! This is a balanced approach within the recommended ranges (L ‚àà [1,8], h ‚àà [64,2056]). It provides good capacity without being excessively deep or wide."
                            },
                            {
                                "text": "Set L=1 layer with h=10000 hidden units",
                                "correct": false,
                                "explanation": "While this has many parameters, a single extremely wide layer doesnt capture hierarchical features as effectively as multiple layers. Its also computationally inefficient."
                            },
                            {
                                "text": "Always use the maximum values: L=8 and h=2056",
                                "correct": false,
                                "explanation": "Bigger is not always better. Very large models are expensive to train, prone to overfitting, and may not generalize well. Start smaller and increase capacity if needed."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 9: Implementation from Scratch -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.3.1", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html#implementation-from-scratch"}]'>
                    <h2 class="truncate-title">Building a Stacked RNN from Scratch</h2>
                    <div style="font-size: 0.7em;">
                        <p>We treat each layer as an <code>RNNScratch</code> instance with its own learnable parameters:</p>

                        <pre><code class="python" style="font-size: 0.85em; max-height: 450px;">class StackedRNNScratch(d2l.Module):
    def __init__(self, num_inputs, num_hiddens, num_layers, sigma=0.01):
        super().__init__()
        self.save_hyperparameters()
        # Create a sequential container with num_layers RNN layers
        self.rnns = nn.Sequential(*[
            d2l.RNNScratch(
                num_inputs if i==0 else num_hiddens,  # First layer: num_inputs
                num_hiddens,                            # Others: num_hiddens
                sigma
            )
            for i in range(num_layers)
        ])</code></pre>

                        <div class="fragment" style="margin-top: 20px;">
                            <div class="emphasis-box">
                                <p style="margin: 0; font-size: 0.95em;"><strong>Key Design Decision:</strong></p>
                                <ul style="margin: 8px 0 0 20px; font-size: 0.9em;">
                                    <li><strong>First layer</strong> (\(i=0\)): Input dimension is <code>num_inputs</code> (vocabulary size)</li>
                                    <li><strong>Subsequent layers</strong> (\(i>0\)): Input dimension is <code>num_hiddens</code> (output from previous layer)</li>
                                    <li>Each layer has independent parameters initialized with standard deviation <code>sigma</code></li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 10: Forward Pass -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.3.1", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html#implementation-from-scratch"}]'>
                    <h2 class="truncate-title">Multi-layer Forward Computation</h2>
                    <div style="font-size: 0.6em;">
                        <p>The forward pass processes each layer sequentially:</p>

                        <pre><code class="python" style="font-size: 0.85em;">@d2l.add_to_class(StackedRNNScratch)
def forward(self, inputs, Hs=None):
    outputs = inputs
    # Initialize hidden states for all layers if not provided
    if Hs is None:
        Hs = [None] * self.num_layers

    # Process through each layer sequentially
    for i in range(self.num_layers):
        outputs, Hs[i] = self.rnns[i](outputs, Hs[i])
        outputs = torch.stack(outputs, 0)  # Stack time steps

    return outputs, Hs</code></pre>

                        <div class="fragment" style="margin-top: 20px;">
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px;">
                                <div class="emphasis-box" style="background: #F5F5FF; border-left: 3px solid #10099F;">
                                    <h5 style="color: #10099F; margin-top: 0;">Layer-by-Layer Processing</h5>
                                    <p style="font-size: 0.85em; margin: 0;">Each layer's outputs become the next layer's inputs. Hidden states are maintained separately for each layer.</p>
                                </div>
                                <div class="emphasis-box" style="background: #F0FFFD; border-left: 3px solid #2DD2C0;">
                                    <h5 style="color: #2DD2C0; margin-top: 0;">State Management</h5>
                                    <p style="font-size: 0.85em; margin: 0;"><code>Hs</code> is a list storing hidden states for all \(L\) layers, enabling proper <span class="tooltip">stateful processing<span class="tooltiptext">Maintaining hidden states across sequence processing to preserve temporal context</span></span>.</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px; padding: 12px; background: #FFFBF0; border-radius: 6px; font-size: 0.9em;">
                            <p style="margin: 0;"><strong>Note:</strong> The <code>torch.stack(outputs, 0)</code> operation combines the sequence of time step outputs into a single tensor.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 11: MCQ #3 - Implementation -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "In the StackedRNNScratch implementation, why does the first layer use num_inputs while subsequent layers use num_hiddens as their input dimension?",
                        "type": "single",
                        "options": [
                            {
                                "text": "Its a programming error - all layers should use num_inputs",
                                "correct": false,
                                "explanation": "This is not an error. Each layer has different input dimensions based on where it receives data from."
                            },
                            {
                                "text": "The first layer receives raw input data (e.g., one-hot encoded tokens), while subsequent layers receive hidden state representations from the previous layer",
                                "correct": true,
                                "explanation": "Correct! Layer 1 processes the original input X_t (dimension: num_inputs). Layers 2+ process the hidden states from the layer below (dimension: num_hiddens)."
                            },
                            {
                                "text": "To reduce memory usage by making upper layers narrower than the first layer",
                                "correct": false,
                                "explanation": "This is not about memory optimization. The dimensions reflect the actual data flow: first layer takes input_dim, others take hidden_dim from previous layer."
                            },
                            {
                                "text": "num_inputs and num_hiddens must always be equal, so theres no actual difference",
                                "correct": false,
                                "explanation": "These are typically different. For example, num_inputs might be 5000 (vocabulary size) while num_hiddens might be 256 (hidden state dimension)."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 12: Training Example -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.3.1", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html#implementation-from-scratch"}]'>
                    <h2 class="truncate-title">Training on The Time Machine Dataset</h2>
                    <div style="font-size: 0.65em;">
                        <p>Training a 2-layer deep RNN on the classic text dataset:</p>

                        <pre><code class="python" style="font-size: 0.85em;">data = d2l.TimeMachine(batch_size=1024, num_steps=32)

# Create a 2-layer stacked RNN
rnn_block = StackedRNNScratch(
    num_inputs=len(data.vocab),    # Vocabulary size
    num_hiddens=32,                # Hidden units per layer
    num_layers=2                   # Stack 2 layers
)

# Create language model with the stacked RNN
model = d2l.RNNLMScratch(rnn_block, vocab_size=len(data.vocab), lr=2)

# Train with gradient clipping
trainer = d2l.Trainer(max_epochs=100, gradient_clip_val=1, num_gpus=1)
trainer.fit(model, data)</code></pre>

                        <div class="fragment" style="margin-top: 20px;">
                            <div style="text-align: center;">
                                <img src="images/deep-rnn-training-pytorch.svg" alt="Training curves showing perplexity decrease" style="max-width: 200px; width: 100%; background: white; padding: 15px; border-radius: 8px;">
                            </div>
                            <p style="text-align: center; font-size: 0.9em; margin-top: 10px;"><span class="tooltip">Perplexity<span class="tooltiptext">A measure of how well the model predicts the next token. Lower perplexity means better predictions. Perplexity = exp(cross-entropy loss)</span></span> decreases as the model learns to predict text sequences</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 13: Concise Implementation -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.3.2", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html#concise-implementation"}]'>
                    <h2 class="truncate-title">Using Built-in GRU Layers</h2>
                    <div style="font-size: 0.65em;">
                        <p>High-level APIs make implementing deep RNNs simple. Here's a multilayer GRU:</p>

                        <pre><code class="python" style="font-size: 0.85em;">class GRU(d2l.RNN):  #@save
    """The multilayer GRU model."""
    def __init__(self, num_inputs, num_hiddens, num_layers, dropout=0):
        d2l.Module.__init__(self)
        self.save_hyperparameters()
        # PyTorch's GRU handles multiple layers automatically!
        self.rnn = nn.GRU(
            num_inputs,
            num_hiddens,
            num_layers,      # Just specify the number of layers
            dropout=dropout  # Optional: dropout between layers
        )</code></pre>

                        <div class="fragment" style="margin-top: 25px;">
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px;">
                                <div class="emphasis-box" style="background: #F5F5FF; border-left: 3px solid #10099F;">
                                    <h5 style="color: #10099F; margin-top: 0;">‚ú® Simplicity</h5>
                                    <p style="font-size: 0.85em; margin: 0;">No need to manually stack layers or manage state lists. The framework handles it all!</p>
                                </div>
                                <div class="emphasis-box" style="background: #FFFBF0; border-left: 3px solid #FAC55B;">
                                    <h5 style="color: #FAC55B; margin-top: 0;">üîß Regularization</h5>
                                    <p style="font-size: 0.85em; margin: 0;"><span class="tooltip">Dropout<span class="tooltiptext">A regularization technique that randomly sets a fraction of layer outputs to zero during training to prevent overfitting</span></span> is applied between layers (not within time steps)</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #F0FFFD; border-left: 4px solid #2DD2C0;">
                            <p style="margin: 0; font-size: 0.95em;"><strong>Performance:</strong> Built-in implementations are highly optimized (CUDA kernels, memory efficiency) and typically much faster than scratch implementations.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 14: Training Results -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.3.2", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html#concise-implementation"}]'>
                    <h2 class="truncate-title">Practical Performance with Deep GRU</h2>
                    <div style="font-size: 0.65em;">
                        <p>Training the same 2-layer configuration with PyTorch's built-in GRU:</p>

                        <pre><code class="python" style="font-size: 0.8em;">gru = GRU(num_inputs=len(data.vocab), num_hiddens=32, num_layers=2)
model = d2l.RNNLM(gru, vocab_size=len(data.vocab), lr=2)
trainer.fit(model, data)</code></pre>

                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 20px; font-size: 0.8em;">
                            <div>
                                <img src="images/deep-rnn-training-gru.svg" alt="GRU training curves" style="width: 70%; background: white; padding: 10px; border-radius: 8px;">
                                <p style="text-align: center; font-size: 0.85em; margin-top: 8px;">Training and validation perplexity</p>
                            </div>
                            <div style="display: flex; flex-direction: column; justify-content: center;">
                                <div class="emphasis-box" style="background: #F5F5FF; margin-bottom: 15px;">
                                    <h5 style="color: #10099F; margin-top: 0;">Text Generation Example</h5>
                                    <pre style="font-size: 0.8em; margin: 5px 0; background: #262626; color: #00FFBA; padding: 10px; border-radius: 5px;"><code>Input:  "it has"
Output: "it has the time traveller"</code></pre>
                                </div>
                                <div class="emphasis-box" style="background: #FFFBF0; border-left: 3px solid #FAC55B;">
                                    <p style="margin: 0; font-size: 0.85em;"><strong>Observation:</strong> The 2-layer GRU learns to generate coherent text that respects the vocabulary and style of the training data.</p>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px; padding: 12px; background: #F0FFFD; border-radius: 6px;">
                            <p style="margin: 0; font-size: 0.9em;"><strong>Prediction:</strong> <code>model.predict('it has', 20, data.vocab, d2l.try_gpu())</code> generates 20 characters continuing from "it has"</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 15: MCQ #4 - Practical Aspects -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "What is the purpose of the dropout parameter in the multilayer GRU implementation?",
                        "type": "single",
                        "options": [
                            {
                                "text": "To randomly remove entire layers during training to speed up computation",
                                "correct": false,
                                "explanation": "Dropout doesnt remove layers. It randomly zeros out individual activation values to prevent overfitting."
                            },
                            {
                                "text": "To apply regularization between RNN layers by randomly zeroing outputs, helping prevent overfitting",
                                "correct": true,
                                "explanation": "Correct! Dropout is applied to the outputs of each layer (except the last) before feeding to the next layer. This helps the model generalize better by preventing co-adaptation of features."
                            },
                            {
                                "text": "To drop time steps from the sequence to make training faster",
                                "correct": false,
                                "explanation": "Dropout does not remove time steps. It operates on the feature dimension between layers, not on the temporal dimension."
                            },
                            {
                                "text": "To initialize weights to zero for better gradient flow",
                                "correct": false,
                                "explanation": "Dropout is not related to weight initialization. Its a regularization technique applied during training, and weights are typically initialized with small random values."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 16: Summary -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.3.3", "url": "https://d2l.ai/chapter_recurrent-modern/deep-rnn.html#summary"}]'>
                    <h2 class="truncate-title">Deep RNNs: Key Takeaways</h2>
                    <div style="font-size: 0.5em;">
                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 25px 0;">
                            <div class="emphasis-box" style="background: linear-gradient(135deg, #10099F 0%, #2DD2C0 100%); color: white; padding: 20px;">
                                <h4 style="margin-top: 0; color: white;">üèóÔ∏è Architecture</h4>
                                <ul style="margin: 8px 0; font-size: 0.9em; line-height: 1.6;">
                                    <li>Stack RNN layers to create spatial depth</li>
                                    <li>Information flows both <strong>temporally</strong> (across time) and <strong>spatially</strong> (across layers)</li>
                                    <li>Each cell depends on same-layer's past and previous-layer's present</li>
                                </ul>
                            </div>
                            <div class="emphasis-box" style="background: linear-gradient(135deg, #2DD2C0 0%, #00FFBA 100%); color: #262626; padding: 20px;">
                                <h4 style="margin-top: 0;">‚ö° Implementation</h4>
                                <ul style="margin: 8px 0; font-size: 0.9em; line-height: 1.6;">
                                    <li>Can build from scratch or use high-level APIs</li>
                                    <li>PyTorch/TensorFlow handle layer stacking automatically</li>
                                    <li>Works with any RNN variant: vanilla, LSTM, GRU</li>
                                </ul>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="background: #FFFBF0; border-left: 4px solid #FAC55B; padding: 20px;">
                            <h4 style="color: #FAC55B; margin-top: 0;">‚öôÔ∏è Training Considerations</h4>
                            <ul style="margin: 8px 0; font-size: 0.9em; line-height: 1.6;">
                                <li><strong>Gradient clipping:</strong> Essential to prevent exploding gradients</li>
                                <li><strong>Learning rate:</strong> Requires careful tuning for convergence</li>
                                <li><strong>Dropout:</strong> Regularizes between layers (not within time steps)</li>
                                <li><strong>Initialization:</strong> Proper weight initialization is critical for deep networks</li>
                            </ul>
                        </div>

                        <div class="fragment" style="margin-top: 25px; text-align: center; padding: 15px; background: #F5F5FF; border-radius: 8px;">
                            <p style="margin: 0; font-size: 0.95em;"><strong>Bottom Line:</strong> Deep RNNs require considerable care to train properly, but they can learn complex hierarchical representations that single-layer models cannot.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 17: Final Comprehensive MCQ -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "You train a 3-layer deep GRU on a language modeling task. Compared to a single-layer GRU with the same number of total parameters, what is the most likely advantage of the deep architecture?",
                        "type": "single",
                        "options": [
                            {
                                "text": "The deep model will always train faster due to better gradient flow",
                                "correct": false,
                                "explanation": "Actually, deeper models are typically slower to train due to more sequential operations. Gradient flow can be challenging in deep networks despite using GRUs."
                            },
                            {
                                "text": "The deep model can learn hierarchical representations, with lower layers capturing simple patterns and higher layers capturing more abstract concepts",
                                "correct": true,
                                "explanation": "Correct! This is the key advantage of depth. Lower layers might learn character or word-level patterns, while upper layers capture syntax and semantics. This hierarchy mirrors how deep CNNs learn from edges to complex objects."
                            },
                            {
                                "text": "The deep model will use less memory during training",
                                "correct": false,
                                "explanation": "Deep models actually require more memory to store intermediate hidden states for all layers at all time steps during backpropagation."
                            },
                            {
                                "text": "The deep model eliminates the need for gradient clipping",
                                "correct": false,
                                "explanation": "Deep RNNs still suffer from gradient instability and typically require gradient clipping. Adding depth can even make this problem worse if not handled properly."
                            }
                        ]
                    }'></div>
                </section>

            </section>

            <!-- Bidirectional RNN Section -->
            <section>
                <!-- Slide 1: Title - Bidirectional RNNs -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.4: Bidirectional RNNs", "url": "https://d2l.ai/chapter_recurrent-modern/bi-rnn.html"}]'>
                    <h2 class="truncate-title">Bidirectional Recurrent Neural Networks</h2>
                    <div style="font-size: 0.7em; margin-top: 40px;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Limitation of Unidirectional RNNs</h4>
                            <p>Standard RNNs process sequences in only one direction (left-to-right), conditioning predictions solely on <strong>past context</strong>.</p>
                        </div>

                        <div class="fragment" style="margin-top: 30px;">
                            <h4 style="color: #10099F;">The Opportunity</h4>
                            <p>Many tasks benefit from considering <strong>both past and future context</strong>:</p>
                            <ul style="font-size: 0.9em; margin-top: 15px;">
                                <li><strong>Part-of-speech tagging:</strong> The role of a word depends on surrounding words</li>
                                <li><strong>Masked language modeling:</strong> Predicting missing tokens using full context</li>
                                <li><strong>Sequence encoding:</strong> Creating representations that capture complete sequence information</li>
                            </ul>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 30px;">
                            <p><strong>Key Insight:</strong> Bidirectional RNNs process sequences in both directions simultaneously, enabling richer representations.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 2: Motivation with Examples -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.4: Bidirectional RNNs", "url": "https://d2l.ai/chapter_recurrent-modern/bi-rnn.html"}]'>
                    <h2 class="truncate-title">Motivation: Why Bidirectional Context Matters</h2>
                    <div style="font-size: 0.7em;">
                        <p>Consider predicting a missing token (represented by <code>___</code>) in these sentences:</p>

                        <div style="margin-top: 30px; background: #f9f9f9; padding: 20px; border-radius: 8px;">
                            <div class="fragment" style="margin-bottom: 25px;">
                                <div style="font-family: monospace; font-size: 1.1em; margin-bottom: 10px;">
                                    I am <span style="background: #FAC55B; padding: 3px 8px; border-radius: 3px;">___</span>.
                                </div>
                                <div style="margin-left: 30px; color: #10099F;">
                                    ‚Üí Likely: <strong>"happy"</strong>, "tired", "ready"
                                </div>
                            </div>

                            <div class="fragment" style="margin-bottom: 25px;">
                                <div style="font-family: monospace; font-size: 1.1em; margin-bottom: 10px;">
                                    I am <span style="background: #FAC55B; padding: 3px 8px; border-radius: 3px;">___</span> hungry.
                                </div>
                                <div style="margin-left: 30px; color: #10099F;">
                                    ‚Üí Likely: <strong>"very"</strong>, "not", "still"<br>
                                    ‚Üí The word "hungry" changes the prediction!
                                </div>
                            </div>

                            <div class="fragment">
                                <div style="font-family: monospace; font-size: 1.1em; margin-bottom: 10px;">
                                    I am <span style="background: #FAC55B; padding: 3px 8px; border-radius: 3px;">___</span> hungry, and I can eat half a pig.
                                </div>
                                <div style="margin-left: 30px; color: #10099F;">
                                    ‚Üí Likely: <strong>"so"</strong>, "extremely"<br>
                                    ‚Üí "not" is now incompatible with the full context!
                                </div>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 25px;">
                            <p><strong>Observation:</strong> The likely value of the missing token changes dramatically depending on what comes <em>after</em> it, not just before.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 3: MCQ on Bidirectional Context -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "In which of the following NLP tasks would a bidirectional RNN be MOST beneficial?",
                        "type": "single",
                        "options": [
                            {
                                "text": "Real-time speech recognition where predictions must be made as words are spoken",
                                "correct": false,
                                "explanation": "Real-time speech recognition requires online predictions where future context is not available, making unidirectional RNNs more appropriate."
                            },
                            {
                                "text": "Predicting masked words in a sentence for a language model pretraining task",
                                "correct": true,
                                "explanation": "Correct! Masked language modeling benefits greatly from bidirectional context since both past and future words help determine the missing token."
                            },
                            {
                                "text": "Generating the next word in a text generation system",
                                "correct": false,
                                "explanation": "Text generation is an autoregressive task where we generate one token at a time based only on previous tokens, so bidirectional processing is not applicable."
                            },
                            {
                                "text": "Online stock price prediction where predictions must be made before future data arrives",
                                "correct": false,
                                "explanation": "Online prediction tasks cannot use bidirectional RNNs because future context is not yet available at prediction time."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 4: Architecture Overview -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.4: Bidirectional RNNs", "url": "https://d2l.ai/chapter_recurrent-modern/bi-rnn.html"}]'>
                    <h2 class="truncate-title">Bidirectional RNN Architecture</h2>
                    <div style="font-size: 0.65em;">
                        <div style="text-align: center; margin: 30px 0;">
                            <img src="images/birnn.svg" alt="Bidirectional RNN Architecture" style="max-width: 50%; height: auto;">
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Key Architecture Components</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px; font-size: 0.9em; margin-top: 15px;">
                                <div class="emphasis-box" style="background: #F0F8FF; border-left: 4px solid #10099F;">
                                    <h5 style="color: #10099F; margin-top: 0;">Forward RNN Layer</h5>
                                    <p style="font-size: 0.85em;">Processes sequence left-to-right</p>
                                    <p style="font-size: 0.85em;">First input: \(\mathbf{x}_1\)<br>Last input: \(\mathbf{x}_T\)</p>
                                    <p style="font-size: 0.85em;">Produces: \(\overrightarrow{\mathbf{H}}_t\)</p>
                                </div>
                                <div class="emphasis-box" style="background: #F0FFF0; border-left: 4px solid #2DD2C0;">
                                    <h5 style="color: #2DD2C0; margin-top: 0;">Backward RNN Layer</h5>
                                    <p style="font-size: 0.85em;">Processes sequence right-to-left</p>
                                    <p style="font-size: 0.85em;">First input: \(\mathbf{x}_T\)<br>Last input: \(\mathbf{x}_1\)</p>
                                    <p style="font-size: 0.85em;">Produces: \(\overleftarrow{\mathbf{H}}_t\)</p>
                                </div>
                                <div class="emphasis-box" style="background: #FFFBF0; border-left: 4px solid #FAC55B;">
                                    <h5 style="color: #FAC55B; margin-top: 0;">Simple Technique</h5>
                                    <p style="font-size: 0.85em;">Implement two unidirectional RNN layers in opposite directions</p>
                                    <p style="font-size: 0.85em;">Then concatenate their outputs:</p>
                                    <p style="font-size: 0.85em;">\(\mathbf{H}_t = [\overrightarrow{\mathbf{H}}_t; \overleftarrow{\mathbf{H}}_t]\)</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 5: Mathematical Formulation -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.4: Bidirectional RNNs", "url": "https://d2l.ai/chapter_recurrent-modern/bi-rnn.html"}]'>
                    <h2 class="truncate-title">Forward and Backward Hidden State Updates</h2>
                    <div style="font-size: 0.5em;">
                        <p>For time step \(t\), with minibatch input \(\mathbf{X}_t \in \mathbb{R}^{n \times d}\) and activation function \(\phi\):</p>

                        <div class="fragment" style="margin-top: 25px;">
                            <div style="background: #F0F8FF; padding: 10px; border-radius: 8px; border-left: 4px solid #10099F; margin-bottom: 20px;">
                                <h4 style="color: #10099F; margin-top: 0;">Forward Hidden State</h4>
                                <p style="font-size: 0.95em;">$$\overrightarrow{\mathbf{H}}_t = \phi(\mathbf{X}_t \mathbf{W}_{\textrm{xh}}^{(f)} + \overrightarrow{\mathbf{H}}_{t-1} \mathbf{W}_{\textrm{hh}}^{(f)} + \mathbf{b}_\textrm{h}^{(f)})$$</p>
                                <p style="font-size: 0.85em; margin-top: 10px;">
                                    Where \(\overrightarrow{\mathbf{H}}_t \in \mathbb{R}^{n \times h}\) depends on <span style="color: #10099F; font-weight: bold;">previous</span> hidden state \(\overrightarrow{\mathbf{H}}_{t-1}\)
                                </p>
                            </div>
                        </div>

                        <div class="fragment">
                            <div style="background: #F0FFF0; padding: 10px; border-radius: 8px; border-left: 4px solid #2DD2C0; margin-bottom: 20px;">
                                <h4 style="color: #2DD2C0; margin-top: 0;">Backward Hidden State</h4>
                                <p style="font-size: 0.95em;">$$\overleftarrow{\mathbf{H}}_t = \phi(\mathbf{X}_t \mathbf{W}_{\textrm{xh}}^{(b)} + \overleftarrow{\mathbf{H}}_{t+1} \mathbf{W}_{\textrm{hh}}^{(b)} + \mathbf{b}_\textrm{h}^{(b)})$$</p>
                                <p style="font-size: 0.85em; margin-top: 10px;">
                                    Where \(\overleftarrow{\mathbf{H}}_t \in \mathbb{R}^{n \times h}\) depends on <span style="color: #2DD2C0; font-weight: bold;">next</span> hidden state \(\overleftarrow{\mathbf{H}}_{t+1}\)
                                </p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 20px; font-size: 0.85em;">
                            <p><strong>Parameters:</strong></p>
                            <ul style="line-height: 1.6;">
                                <li><span class="tooltip">Weight matrices<span class="tooltiptext">Forward: W_xh^(f), W_hh^(f); Backward: W_xh^(b), W_hh^(b). Each RNN direction has its own learnable parameters.</span></span>: \(\mathbf{W}_{\textrm{xh}}^{(f)}, \mathbf{W}_{\textrm{hh}}^{(f)}, \mathbf{W}_{\textrm{xh}}^{(b)}, \mathbf{W}_{\textrm{hh}}^{(b)} \in \mathbb{R}^{d \times h}\) or \(\mathbb{R}^{h \times h}\)</li>
                                <li>Bias vectors: \(\mathbf{b}_\textrm{h}^{(f)}, \mathbf{b}_\textrm{h}^{(b)} \in \mathbb{R}^{1 \times h}\)</li>
                                <li>\(h\) = number of hidden units in each direction</li>
                            </ul>
                        </div>
                    </div>
                </section>

                <!-- Slide 7: MCQ on Hidden State Dimensions -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "If each unidirectional RNN has h=64 hidden units, what is the dimension of the concatenated hidden state H_t in a bidirectional RNN?",
                        "type": "single",
                        "options": [
                            {
                                "text": "64",
                                "correct": false,
                                "explanation": "This would be the size of just one direction. The bidirectional RNN concatenates both forward and backward hidden states."
                            },
                            {
                                "text": "128",
                                "correct": true,
                                "explanation": "Correct! The bidirectional RNN concatenates the forward hidden state (64 units) and backward hidden state (64 units), resulting in 2h = 128 total hidden units."
                            },
                            {
                                "text": "32",
                                "correct": false,
                                "explanation": "This would be h/2, but concatenation increases the dimension, not decreases it."
                            },
                            {
                                "text": "256",
                                "correct": false,
                                "explanation": "This would be 4h. The concatenation doubles the dimension (to 2h), not quadruples it."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 8: Output Layer Computation -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.4: Bidirectional RNNs", "url": "https://d2l.ai/chapter_recurrent-modern/bi-rnn.html"}]'>
                    <h2 class="truncate-title">Output Layer: Combining Both Directions</h2>
                    <div style="font-size: 0.5em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Concatenating Hidden States</h4>
                            <p>The forward and backward hidden states are concatenated to form the complete hidden representation:</p>
                            <p style="font-size: 1.1em; text-align: center; margin: 20px 0;">
                                $$\mathbf{H}_t = [\overrightarrow{\mathbf{H}}_t; \overleftarrow{\mathbf{H}}_t] \in \mathbb{R}^{n \times 2h}$$
                            </p>
                            <p style="font-size: 0.9em;">This <span class="tooltip">concatenated representation<span class="tooltiptext">The concatenation operator [¬∑;¬∑] combines the forward and backward hidden states along the feature dimension, doubling the hidden size from h to 2h</span></span> contains information from both past and future context.</p>
                        </div>

                        <div class="fragment" style="margin-top: 10px;">
                            <h4 style="color: #10099F;">Computing the Output</h4>
                            <p>The output layer uses the concatenated hidden state:</p>
                            <div style="background: #FFF5E6; padding: 10px; border-radius: 8px; border-left: 4px solid #FC8484; margin: 10px 0;">
                                <p style="font-size: 1.1em; text-align: center; margin: 10px 0;">
                                    $$\mathbf{O}_t = \mathbf{H}_t \mathbf{W}_{\textrm{hq}} + \mathbf{b}_\textrm{q}$$
                                </p>
                                <p style="font-size: 0.9em; margin-top: 15px;">
                                    Where:<br>
                                    ‚Ä¢ \(\mathbf{W}_{\textrm{hq}} \in \mathbb{R}^{2h \times q}\) maps from <strong>doubled hidden size</strong> (2h) to output size (q)<br>
                                    ‚Ä¢ \(\mathbf{b}_\textrm{q} \in \mathbb{R}^{1 \times q}\) is the output bias<br>
                                    ‚Ä¢ \(\mathbf{O}_t \in \mathbb{R}^{n \times q}\) is the output for time step \(t\)
                                </p>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 10px;">
                            <p><strong>Key Point:</strong> The output weight matrix must have input dimension 2h (not h) to accommodate the concatenated hidden states from both directions.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 9: Implementation from Scratch -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.4: Bidirectional RNNs", "url": "https://d2l.ai/chapter_recurrent-modern/bi-rnn.html"}]'>
                    <h2 class="truncate-title">Implementation from Scratch (PyTorch)</h2>
                    <div style="font-size: 0.5em;">
                        <p>A bidirectional RNN can be implemented using two unidirectional RNN instances:</p>

                        <div style="margin-top: 20px;">
                            <h4 style="color: #10099F;">Class Definition</h4>
                            <pre><code class="language-python" style="font-size: 0.9em;">class BiRNNScratch(d2l.Module):
    def __init__(self, num_inputs, num_hiddens, sigma=0.01):
        super().__init__()
        self.save_hyperparameters()
        # Forward RNN processes sequence left-to-right
        self.f_rnn = d2l.RNNScratch(num_inputs, num_hiddens, sigma)
        # Backward RNN processes sequence right-to-left
        self.b_rnn = d2l.RNNScratch(num_inputs, num_hiddens, sigma)
        # Output dimension is doubled due to concatenation
        self.num_hiddens *= 2</code></pre>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Forward Pass</h4>
                            <pre><code class="language-python" style="font-size: 0.9em;">@d2l.add_to_class(BiRNNScratch)
def forward(self, inputs, Hs=None):
    # Separate hidden states for forward and backward RNNs
    f_H, b_H = Hs if Hs is not None else (None, None)

    # Forward RNN: process inputs left-to-right
    f_outputs, f_H = self.f_rnn(inputs, f_H)

    # Backward RNN: process REVERSED inputs (right-to-left)
    b_outputs, b_H = self.b_rnn(reversed(inputs), b_H)

    # Concatenate forward and backward outputs at each time step
    # Note: backward outputs are also reversed to align with time steps
    outputs = [torch.cat((f, b), -1) for f, b in zip(
        f_outputs, reversed(b_outputs))]

    return outputs, (f_H, b_H)</code></pre>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px; font-size: 0.95em;">
                            <p><strong>Key Implementation Detail:</strong> The backward RNN receives the reversed input sequence, and its outputs are reversed again before concatenation to align with the forward outputs.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 10: MCQ on Implementation -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "Why must the backward RNN process reversed inputs in the implementation?",
                        "type": "single",
                        "options": [
                            {
                                "text": "To save memory during training",
                                "correct": false,
                                "explanation": "Reversing inputs does not save memory. The reason is related to the direction of processing."
                            },
                            {
                                "text": "Because the backward RNN must condition each hidden state on future time steps, which become past time steps when the sequence is reversed",
                                "correct": true,
                                "explanation": "Correct! By reversing the input, the backward RNN can use the standard recurrent structure (conditioning on previous hidden states) while effectively processing the sequence right-to-left. At time t, it needs information from t+1, which becomes the previous step in the reversed sequence."
                            },
                            {
                                "text": "To make the forward and backward outputs have the same shape",
                                "correct": false,
                                "explanation": "The outputs would have the same shape regardless of reversing. The reversal is about the order of processing and dependencies."
                            },
                            {
                                "text": "To ensure both RNNs learn the same parameters",
                                "correct": false,
                                "explanation": "The forward and backward RNNs have separate, independently learned parameters. Reversing the input does not affect parameter sharing."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 11: Concise Implementation -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.4: Bidirectional RNNs", "url": "https://d2l.ai/chapter_recurrent-modern/bi-rnn.html"}]'>
                    <h2 class="truncate-title">Concise Implementation with High-Level APIs</h2>
                    <div style="font-size: 0.5em;">
                        <p>Modern deep learning frameworks provide built-in support for bidirectional RNNs:</p>

                        <div style="margin-top: 10px;">
                            <h4 style="color: #10099F;">PyTorch Implementation</h4>
                            <pre><code class="language-python" style="font-size: 0.95em;">class BiGRU(d2l.RNN):
    def __init__(self, num_inputs, num_hiddens):
        d2l.Module.__init__(self)
        self.save_hyperparameters()
        # Simply set bidirectional=True!
        self.rnn = nn.GRU(num_inputs, num_hiddens, bidirectional=True)
        # The framework automatically doubles the output dimension
        self.num_hiddens *= 2</code></pre>
                        </div>

                        <div class="fragment" style="margin-top: 10px;">
                            <h4 style="color: #10099F;">Key Advantages</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 0px;">
                                <div class="emphasis-box" style="background: #F0FFF0; border-left: 4px solid #2DD2C0; margin-top: 0px;">
                                    <h5 style="color: #2DD2C0; margin-top: 0;">‚úì Simplicity</h5>
                                    <ul style="font-size: 0.85em; margin-top: 0px;">
                                        <li>Single parameter: <code>bidirectional=True</code></li>
                                        <li>No manual reversing needed</li>
                                        <li>Automatic concatenation</li>
                                    </ul>
                                </div>
                                <div class="emphasis-box" style="background: #F0F8FF; border-left: 4px solid #10099F; margin-top: 0px;">
                                    <h5 style="color: #10099F; margin-top: 0;">‚úì Performance</h5>
                                    <ul style="font-size: 0.85em; margin-top: 0px;">
                                        <li>Optimized implementations</li>
                                        <li>GPU acceleration</li>
                                        <li>Efficient memory usage</li>
                                    </ul>
                                </div>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 0px;">
                            <h4 style="color: #10099F;">Works with Any RNN Variant</h4>
                            <pre><code class="language-python" style="font-size: 0.9em;"># Bidirectional LSTM
bi_lstm = nn.LSTM(input_size, hidden_size, bidirectional=True)

# Bidirectional vanilla RNN
bi_rnn = nn.RNN(input_size, hidden_size, bidirectional=True)

# All automatically handle the forward/backward processing</code></pre>
                        </div>
                    </div>
                </section>

                <!-- Slide 12: Key Properties and Limitations -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.4: Bidirectional RNNs", "url": "https://d2l.ai/chapter_recurrent-modern/bi-rnn.html"}]'>
                    <h2 class="truncate-title">Properties and Limitations of Bidirectional RNNs</h2>
                    <div style="font-size: 0.45em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">When to Use Bidirectional RNNs ‚úì</h4>
                            <div style="background: #F0FFF0; padding: 20px; border-radius: 8px; border-left: 4px solid #2DD2C0; margin: 15px 0;">
                                <ul style="line-height: 1.8;">
                                    <li><strong>Sequence Encoding:</strong> Creating fixed representations of complete sequences (e.g., for classification)</li>
                                    <li><strong>Masked Language Modeling:</strong> Predicting missing tokens with full context (e.g., BERT pretraining)</li>
                                    <li><strong>Sequence Labeling:</strong> Tasks like <span class="tooltip">part-of-speech tagging<span class="tooltiptext">Part-of-speech (POS) tagging assigns grammatical categories (noun, verb, adjective, etc.) to each word in a sentence based on both its definition and context</span></span> or <span class="tooltip">named entity recognition<span class="tooltiptext">Named Entity Recognition (NER) identifies and classifies named entities (people, organizations, locations, etc.) in text</span></span></li>
                                    <li><strong>Offline Tasks:</strong> Any task where the entire sequence is available before prediction</li>
                                </ul>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #FC8484;">When NOT to Use Bidirectional RNNs ‚úó</h4>
                            <div style="background: #FFF5F5; padding: 20px; border-radius: 8px; border-left: 4px solid #FC8484; margin: 15px 0;">
                                <ul style="line-height: 1.8;">
                                    <li><strong>Online/Streaming Prediction:</strong> Real-time systems where future input is not yet available (e.g., live speech recognition)</li>
                                    <li><strong>Autoregressive Generation:</strong> Generating sequences one token at a time (e.g., text generation, machine translation decoding)</li>
                                    <li><strong>Causal Modeling:</strong> Tasks where future information would cause data leakage</li>
                                </ul>
                            </div>
                        </div>

                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #FAC55B;">‚ö† Computational Cost</h4>
                            <div class="emphasis-box" style="background: #FFFBF0; border-left: 4px solid #FAC55B;">
                                <p style="margin: 0;"><strong>Training is expensive!</strong> Bidirectional RNNs have very long <span class="tooltip">gradient chains<span class="tooltiptext">During backpropagation, gradients must flow through both forward and backward RNN chains, doubling the sequential dependency length and making training slower</span></span> because:</p>
                                <ul style="font-size: 0.9em; margin-top: 10px;">
                                    <li>Gradients must flow through both forward and backward passes</li>
                                    <li>Cannot parallelize across time (sequential dependencies)</li>
                                    <li>Approximately doubles training time compared to unidirectional RNNs</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 13: MCQ on Use Cases -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "Which of the following tasks would MOST benefit from using a bidirectional RNN? (Select the best answer)",
                        "type": "single",
                        "options": [
                            {
                                "text": "Building a chatbot that generates responses in real-time as the user types",
                                "correct": false,
                                "explanation": "Real-time generation requires autoregressive decoding where each token depends only on previous tokens, making bidirectional RNNs inappropriate."
                            },
                            {
                                "text": "Classifying the sentiment of movie reviews where the entire review text is available",
                                "correct": true,
                                "explanation": "Correct! Sentiment classification is a sequence encoding task where the complete text is available before prediction. Bidirectional RNNs can leverage both early and late context to better understand sentiment, especially when key sentiment indicators appear at different positions in the review."
                            },
                            {
                                "text": "Predicting the next word in an autocomplete system while the user is typing",
                                "correct": false,
                                "explanation": "Autocomplete is an online prediction task where future words are not yet available. Only unidirectional RNNs are suitable here."
                            },
                            {
                                "text": "Forecasting the stock price of tomorrow based on historical price data up to today",
                                "correct": false,
                                "explanation": "Stock price forecasting is a causal prediction task where using future information would be data leakage. Only past information should be used."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 14: Summary -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.4: Bidirectional RNNs", "url": "https://d2l.ai/chapter_recurrent-modern/bi-rnn.html"}]'>
                    <h2 class="truncate-title">Summary: Bidirectional RNNs</h2>
                    <div style="font-size: 0.55em;">
                        <div class="emphasis-box" style="background: #F0F8FF; border-left: 4px solid #10099F; margin-bottom: 25px;">
                            <h4 style="color: #10099F; margin-top: 0;">Architecture</h4>
                            <ul style="line-height: 1.7;">
                                <li>Two RNN layers: <strong>forward</strong> (‚Üí) processes left-to-right, <strong>backward</strong> (‚Üê) processes right-to-left</li>
                                <li>Hidden states are <strong>concatenated</strong>: \(\mathbf{H}_t = [\overrightarrow{\mathbf{H}}_t; \overleftarrow{\mathbf{H}}_t]\)</li>
                                <li>Output dimension is <strong>doubled</strong> from \(h\) to \(2h\)</li>
                            </ul>
                        </div>

                        <div class="emphasis-box" style="background: #FFF9F0; border-left: 4px solid #FAC55B; margin-bottom: 25px;">
                            <h4 style="color: #FAC55B; margin-top: 0;">Key Characteristics</h4>
                            <ul style="line-height: 1.7;">
                                <li><strong>Advantages:</strong> Rich representations with full sequence context, better performance on encoding tasks</li>
                                <li><strong>Limitations:</strong> Cannot be used for online prediction, expensive training due to long gradient chains</li>
                                <li><strong>Best Use Cases:</strong> Sequence classification, masked language modeling, sequence labeling</li>
                            </ul>
                        </div>

                        <div class="fragment emphasis-box" style="background: #F5F5F5;">
                            <p style="margin: 0;"><strong>Next Topic:</strong> We'll explore attention mechanisms that can selectively focus on different parts of sequences without the sequential processing constraints of RNNs.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 15: Final Comprehensive MCQ -->
                <section>
                    <h2 class="truncate-title">Final Assessment</h2>
                    <div data-mcq='{
                        "question": "Consider a bidirectional LSTM for named entity recognition with input dimension d=300, hidden dimension h=128, and output vocabulary size q=10. What are the key architectural properties?",
                        "type": "multiple",
                        "options": [
                            {
                                "text": "Each time step receives information from both past and future context",
                                "correct": true,
                                "explanation": "Correct! This is the fundamental property of bidirectional RNNs - each hidden state H_t is computed using both forward (past) and backward (future) RNN outputs."
                            },
                            {
                                "text": "The concatenated hidden state at each time step has dimension 256",
                                "correct": true,
                                "explanation": "Correct! The concatenation of forward hidden state (128) and backward hidden state (128) results in a hidden dimension of 2h = 256."
                            },
                            {
                                "text": "The model can be used for real-time prediction as text is being typed",
                                "correct": false,
                                "explanation": "Incorrect! Bidirectional RNNs require the complete sequence to be available because the backward pass needs future tokens. They cannot be used for online/streaming prediction."
                            },
                            {
                                "text": "The output weight matrix W_hq has shape (256, 10)",
                                "correct": true,
                                "explanation": "Correct! The output layer must map from the concatenated hidden dimension (2h=256) to the output vocabulary size (q=10), so W_hq ‚àà ‚Ñù^(256√ó10)."
                            },
                            {
                                "text": "Training is faster than unidirectional LSTMs because both directions can be computed in parallel",
                                "correct": false,
                                "explanation": "Incorrect! While forward and backward passes can be computed independently, bidirectional RNNs are actually slower to train because gradients must flow through both chains, and the sequential nature of RNNs prevents parallelization across time steps."
                            }
                        ]
                    }'></div>
                </section>

            </section>

            <!-- Single Vertical Section: Machine Translation and the Dataset -->
            <section>
                <!-- Slide 1: Section Title -->
                <section class="title-slide" data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5: Machine Translation and the Dataset", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html"}]'>
                    <h1 class="truncate-title">Machine Translation and the Dataset</h1>
                    <p>Preparing Data for Sequence-to-Sequence Learning</p>
                    <div style="margin-top: 40px; font-size: 0.55em;">
                        <div class="emphasis-box">
                            <p><strong>Learning Objectives:</strong></p>
                            <ul style="text-align: left; display: inline-block; margin: 10px 0 0 0;">
                                <li>Understand machine translation as a sequence mapping problem</li>
                                <li>Learn dataset preprocessing and tokenization techniques</li>
                                <li>Master padding, truncation, and vocabulary construction</li>
                                <li>Understand the decoder input/output relationship</li>
                            </ul>
                        </div>
                    </div>
                </section>

                <!-- Slide 2: What is Machine Translation? -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html"}]'>
                    <h2 class="truncate-title">What is Machine Translation?</h2>
                    <div style="font-size: 0.85em;">
                        <div class="fragment">
                            <p style="font-size: 1.1em; margin-bottom: 30px;"><strong>Definition:</strong> Automatic mapping from a sequence in a <span class="tooltip">source language<span class="tooltiptext">The original language of the input text that needs to be translated</span></span> to a plausible translation in a <span class="tooltip">target language<span class="tooltiptext">The destination language into which the source text is being translated</span></span></p>
                        </div>
                        <div class="fragment" style="margin-top: 30px;">
                            <div style="display: grid; grid-template-columns: 1fr auto 1fr; gap: 20px; align-items: center;">
                                <div class="emphasis-box" style="background: linear-gradient(135deg, #10099F 0%, #2DD2C0 100%); color: white; padding: 25px;">
                                    <h4 style="margin: 0 0 15px 0; color: white;">Source Language</h4>
                                    <p style="font-size: 1.2em; margin: 0;">"Go."</p>
                                    <p style="font-size: 0.9em; margin: 10px 0 0 0; opacity: 0.9;">English</p>
                                </div>
                                <div style="font-size: 3em; color: #10099F;">‚Üí</div>
                                <div class="emphasis-box" style="background: linear-gradient(135deg, #2DD2C0 0%, #00FFBA 100%); padding: 25px;">
                                    <h4 style="margin: 0 0 15px 0;">Target Language</h4>
                                    <p style="font-size: 1.2em; margin: 0;">"Va !"</p>
                                    <p style="font-size: 0.9em; margin: 10px 0 0 0; color: #666;">French</p>
                                </div>
                            </div>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 30px; background: #FFF9E6; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0;">üí° <strong>Key Challenge:</strong> Both source and target are <span class="tooltip">variable-length sequences<span class="tooltiptext">Sequences that can have different numbers of tokens, making batch processing challenging</span></span></p>
                        </div>
                    </div>
                </section>

                <!-- Slide 3: The Tatoeba Dataset -->
                <section data-sources='[{"text": "Tatoeba Project", "url": "https://tatoeba.org"}, {"text": "Dive into Deep Learning - Chapter 10.5", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html"}]'>
                    <h2 class="truncate-title">The Tatoeba Dataset</h2>
                    <div style="font-size: 0.6em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Dataset Characteristics</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 25px;">
                                <div class="emphasis-box">
                                    <p><strong>Language Pair:</strong> English ‚Üî French</p>
                                    <p style="font-size: 0.9em; margin: 5px 0 0 0; color: #666;">Bilingual sentence pairs</p>
                                </div>
                                <div class="emphasis-box">
                                    <p><strong>Format:</strong> Tab-delimited</p>
                                    <p style="font-size: 0.9em; margin: 5px 0 0 0; color: #666;">Source \t Target</p>
                                </div>
                            </div>
                        </div>
                        <div class="fragment">
                            <h4 style="color: #10099F;">Raw Data Example</h4>
                            <div style="background: #262626; color: #00FFBA; padding: 20px; border-radius: 8px; font-family: 'Source Code Pro', monospace; font-size: 0.95em;">
                                <div style="margin-bottom: 8px;">Go.	Va !</div>
                                <div style="margin-bottom: 8px;">Hi.	Salut !</div>
                                <div style="margin-bottom: 8px;">Run!	Cours !</div>
                                <div style="margin-bottom: 8px;">Run!	Courez !</div>
                                <div style="margin-bottom: 8px;">Who?	Qui ?</div>
                                <div>Wow!	√áa alors !</div>
                            </div>
                        </div>
                        <div class="fragment" style="margin-top: 20px;">
                            <p style="font-size: 0.95em;"><strong>Note:</strong> Each sequence can be a single sentence or multiple sentences</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 4: Preprocessing Pipeline -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5.1", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#downloading-and-preprocessing-the-dataset"}]'>
                    <h2 class="truncate-title">Text Preprocessing Pipeline</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Three Preprocessing Steps</h4>
                            <div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px; margin-bottom: 25px;">
                                <div class="emphasis-box" style="background: #FFF5F5; border-left: 4px solid #FC8484;">
                                    <h5 style="color: #FC8484; margin: 0 0 10px 0;">Step 1</h5>
                                    <p style="margin: 0; font-size: 0.9em;">Replace non-breaking spaces with regular spaces</p>
                                </div>
                                <div class="emphasis-box" style="background: #FFF9E6; border-left: 4px solid #FAC55B;">
                                    <h5 style="color: #FAC55B; margin: 0 0 10px 0;">Step 2</h5>
                                    <p style="margin: 0; font-size: 0.9em;">Convert all uppercase letters to lowercase</p>
                                </div>
                                <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                                    <h5 style="color: #2DD2C0; margin: 0 0 10px 0;">Step 3</h5>
                                    <p style="margin: 0; font-size: 0.9em;">Insert space between words and punctuation</p>
                                </div>
                            </div>
                        </div>
                        <div class="fragment">
                            <h4 style="color: #10099F;">Implementation: <code>_preprocess()</code> Method</h4>
                            <pre><code class="python" style="font-size: 0.85em;">@d2l.add_to_class(MTFraEng)
def _preprocess(self, text):
    # Replace non-breaking space with space
    text = text.replace('\u202f', ' ').replace('\xa0', ' ')

    # Insert space between words and punctuation marks
    no_space = lambda char, prev_char: char in ',.!?' and prev_char != ' '
    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char
           for i, char in enumerate(text.lower())]

    return ''.join(out)</code></pre>
                        </div>
                    </div>
                </section>

                <!-- Slide 5: Preprocessing Example (Interactive) -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5.1", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#downloading-and-preprocessing-the-dataset"}]'>
                    <h2 class="truncate-title">Preprocessing in Action</h2>
                    <div style="font-size: 0.8em;">
                        <div id="preprocess-demo" style="margin-top: 20px;"></div>
                    </div>
                </section>

                <!-- MCQ #1: Preprocessing -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding: Preprocessing</h2>
                    <div data-mcq='{
                        "question": "Why do we insert spaces between words and punctuation marks during preprocessing?",
                        "type": "single",
                        "options": [
                            {
                                "text": "To make the text easier to read for humans",
                                "correct": false,
                                "explanation": "While this may be a side effect, the primary purpose is related to tokenization, not human readability."
                            },
                            {
                                "text": "To ensure punctuation marks are treated as separate tokens during tokenization",
                                "correct": true,
                                "explanation": "Correct! By adding spaces, punctuation marks become separate tokens (e.g., \"Go.\" becomes \"go\" and \".\" as two tokens), which is important for the model to learn their meaning and usage."
                            },
                            {
                                "text": "To reduce the vocabulary size",
                                "correct": false,
                                "explanation": "Actually, separating punctuation increases the vocabulary slightly because punctuation marks become separate vocabulary items."
                            },
                            {
                                "text": "To remove special characters from the text",
                                "correct": false,
                                "explanation": "We are not removing punctuation marks, just separating them with spaces so they can be tokenized independently."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 7: Word-Level Tokenization -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5.2", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#tokenization"}]'>
                    <h2 class="truncate-title">Word-Level Tokenization</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Word-Level vs Character-Level</h4>
                            <table style="width: 100%; border-collapse: collapse; margin-bottom: 25px;">
                                <thead style="background: #10099F; color: white;">
                                    <tr>
                                        <th style="padding: 12px; border: 1px solid #EEEEEE;">Aspect</th>
                                        <th style="padding: 12px; border: 1px solid #EEEEEE;">Word-Level</th>
                                        <th style="padding: 12px; border: 1px solid #EEEEEE;">Character-Level</th>
                                    </tr>
                                </thead>
                                <tbody style="font-size: 0.9em;">
                                    <tr>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE;"><strong>Vocabulary Size</strong></td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE; background: #FFF5F5;">Larger (thousands)</td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE; background: #F0FFF9;">Smaller (< 100)</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE;"><strong>Sequence Length</strong></td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE; background: #F0FFF9;">Shorter</td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE; background: #FFF5F5;">Longer</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE;"><strong>Semantic Meaning</strong></td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE; background: #F0FFF9;">Direct (words have meaning)</td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE; background: #FFF5F5;">Must be learned</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE;"><strong>Preferred for MT</strong></td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE; background: #F0FFF9;">‚úì Yes</td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE;">Less common</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                        <div class="fragment">
                            <h4 style="color: #10099F;">Special Tokens</h4>
                            <div style="display: grid; grid-template-columns: repeat(4, 1fr); gap: 12px;">
                                <div class="emphasis-box" style="background: #FFF5F5; border: 2px solid #FC8484;">
                                    <p style="margin: 0; font-family: 'Source Code Pro', monospace; font-weight: bold; color: #FC8484;">&lt;eos&gt;</p>
                                    <p style="margin: 5px 0 0 0; font-size: 0.85em;"><span class="tooltip">End of sequence<span class="tooltiptext">Token appended to mark the end of a sequence; signals the model to stop generation</span></span></p>
                                </div>
                                <div class="emphasis-box" style="background: #FFF9E6; border: 2px solid #FAC55B;">
                                    <p style="margin: 0; font-family: 'Source Code Pro', monospace; font-weight: bold; color: #FAC55B;">&lt;bos&gt;</p>
                                    <p style="margin: 5px 0 0 0; font-size: 0.85em;"><span class="tooltip">Beginning of sequence<span class="tooltiptext">Token prepended as the first input to the decoder to start generation</span></span></p>
                                </div>
                                <div class="emphasis-box" style="background: #F0FFF9; border: 2px solid #2DD2C0;">
                                    <p style="margin: 0; font-family: 'Source Code Pro', monospace; font-weight: bold; color: #2DD2C0;">&lt;pad&gt;</p>
                                    <p style="margin: 5px 0 0 0; font-size: 0.85em;"><span class="tooltip">Padding<span class="tooltiptext">Token added to short sequences to make all sequences the same length for batch processing</span></span></p>
                                </div>
                                <div class="emphasis-box" style="background: #F5F5FF; border: 2px solid #10099F;">
                                    <p style="margin: 0; font-family: 'Source Code Pro', monospace; font-weight: bold; color: #10099F;">&lt;unk&gt;</p>
                                    <p style="margin: 5px 0 0 0; font-size: 0.85em;"><span class="tooltip">Unknown<span class="tooltiptext">Token used to replace rare words that appear less than the minimum frequency threshold</span></span></p>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 8: Tokenization Implementation -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5.2", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#tokenization"}]'>
                    <h2 class="truncate-title">Tokenization Implementation</h2>
                    <div style="font-size: 0.5em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The <code>_tokenize()</code> Method</h4>
                            <pre><code class="python" style="font-size: 0.85em;">@d2l.add_to_class(MTFraEng)
def _tokenize(self, text, max_examples=None):
    src, tgt = [], []
    for i, line in enumerate(text.split('\n')):
        if max_examples and i > max_examples: break
        parts = line.split('\t')
        if len(parts) == 2:
            # Skip empty tokens
            src.append([t for t in f'{parts[0]} <eos>'.split(' ') if t])
            tgt.append([t for t in f'{parts[1]} <eos>'.split(' ') if t])
    return src, tgt</code></pre>
                        </div>
                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Example Output</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px;">
                                <div>
                                    <p style="margin-bottom: 10px;"><strong>Source (English):</strong></p>
                                    <pre style="background: #F5F5FF; padding: 15px; border-radius: 8px; margin: 0; font-size: 0.8em;"><code>[['go', '.', '<eos>'],
 ['hi', '.', '<eos>'],
 ['run', '!', '<eos>'],
 ['who', '?', '<eos>']]</code></pre>
                                </div>
                                <div>
                                    <p style="margin-bottom: 10px;"><strong>Target (French):</strong></p>
                                    <pre style="background: #F0FFF9; padding: 15px; border-radius: 8px; margin: 0; font-size: 0.8em;"><code>[['va', '!', '<eos>'],
 ['salut', '!', '<eos>'],
 ['cours', '!', '<eos>'],
 ['qui', '?', '<eos>']]</code></pre>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 9: Sequence Length Distribution -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5.2", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#tokenization"}]'>
                    <h2 class="truncate-title">Sequence Length Distribution</h2>
                    <div style="font-size: 0.85em;">
                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #FFF9E6; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0;">üí° <strong>Key Observation:</strong> Most text sequences in this dataset have fewer than 20 tokens</p>
                        </div>
                    </div>
                </section>

                <!-- MCQ #2: Tokenization -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding: Tokenization</h2>
                    <div data-mcq='{
                        "question": "What is the purpose of appending the &lt;eos&gt; token to every sequence during tokenization?",
                        "type": "single",
                        "options": [
                            {
                                "text": "To mark where padding should begin",
                                "correct": false,
                                "explanation": "The &lt;pad&gt; token is used for padding, not &lt;eos&gt;. The &lt;eos&gt; token serves a different purpose related to sequence completion."
                            },
                            {
                                "text": "To indicate the end of the sequence and signal when generation should stop",
                                "correct": true,
                                "explanation": "Correct! The &lt;eos&gt; token tells the model when a sequence is complete. During generation, when the model predicts &lt;eos&gt;, it knows to stop producing more tokens."
                            },
                            {
                                "text": "To separate source and target sequences",
                                "correct": false,
                                "explanation": "Source and target sequences are already separated in the dataset format (tab-delimited). The &lt;eos&gt; token marks the end of individual sequences, not the boundary between source and target."
                            },
                            {
                                "text": "To increase the vocabulary size",
                                "correct": false,
                                "explanation": "While &lt;eos&gt; does add one token to the vocabulary, this is not its purpose. Its purpose is to mark sequence boundaries for the model."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 11: The Fixed-Length Challenge -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5.3", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#loading-sequences-of-fixed-length"}]'>
                    <h2 class="truncate-title">The Fixed-Length Challenge</h2>
                    <div style="font-size: 0.6em;">
                        <div class="fragment">
                            <div class="emphasis-box" style="background: #FFF5F5; border-left: 4px solid #FC8484; margin-bottom: 25px;">
                                <p style="margin: 0;"><strong>Problem:</strong> Text sequences have <span class="tooltip">variable lengths<span class="tooltiptext">Different sequences contain different numbers of tokens, making it difficult to batch them together efficiently</span></span>, but neural networks require fixed-size inputs for efficient batch processing</p>
                            </div>
                        </div>
                        <div class="fragment">
                            <h4 style="color: #10099F;">Solution: Padding and Truncation</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 25px; margin-top: 20px;">
                                <div>
                                    <div class="emphasis-box" style="background: #F0FFF9; border: 2px solid #2DD2C0;">
                                        <h5 style="color: #2DD2C0; margin: 0 0 15px 0;">üìè Padding (Sequence Too Short)</h5>
                                        <div style="font-family: 'Source Code Pro', monospace; font-size: 0.85em; line-height: 1.8;">
                                            <div>['go', '.', '<eos>']</div>
                                            <div style="color: #666;">‚Üì Add &lt;pad&gt; tokens</div>
                                            <div>['go', '.', '<eos>', <span style="color: #2DD2C0;">'&lt;pad&gt;', '&lt;pad&gt;'</span>]</div>
                                        </div>
                                    </div>
                                </div>
                                <div>
                                    <div class="emphasis-box" style="background: #FFF5F5; border: 2px solid #FC8484;">
                                        <h5 style="color: #FC8484; margin: 0 0 15px 0;">‚úÇÔ∏è Truncation (Sequence Too Long)</h5>
                                        <div style="font-family: 'Source Code Pro', monospace; font-size: 0.85em; line-height: 1.8;">
                                            <div>['this', 'is', 'a', 'very', 'long', '...']</div>
                                            <div style="color: #666;">‚Üì Keep first <code>num_steps</code></div>
                                            <div>['this', 'is', 'a', 'very', 'long']</div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 25px; background: #FFF9E6; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0;">üí° <strong>Result:</strong> Every sequence has exactly <code>num_steps</code> tokens (default: 9)</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 12: Padding and Truncation Details -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5.3", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#loading-sequences-of-fixed-length"}]'>
                    <h2 class="truncate-title">Implementation Details</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The <code>pad_or_trim</code> Lambda Function</h4>
                            <pre><code class="python" style="font-size: 0.9em;">pad_or_trim = lambda seq, t: (
    seq[:t] if len(seq) > t else seq + ['<pad>'] * (t - len(seq))
)</code></pre>
                            <p style="margin-top: 15px;"><strong>Logic:</strong></p>
                            <ul style="font-size: 0.9em; line-height: 1.6;">
                                <li>If <code>len(seq) > t</code>: Truncate to first <code>t</code> tokens</li>
                                <li>If <code>len(seq) ‚â§ t</code>: Append <code>&lt;pad&gt;</code> tokens until length = <code>t</code></li>
                            </ul>
                        </div>
                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Recording Source Sequence Lengths</h4>
                            <pre><code class="python" style="font-size: 0.9em;">valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)</code></pre>
                            <div class="emphasis-box" style="margin-top: 15px; background: #FFF9E6; border-left: 4px solid #FAC55B;">
                                <p style="margin: 0; font-size: 0.95em;">üí° <strong>Why record lengths?</strong> Some models need to know the actual sequence length (excluding padding) to properly handle <span class="tooltip">variable-length sequences<span class="tooltiptext">Sequences with different actual content lengths, even though they are padded to the same size</span></span></p>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Slide 13: Vocabulary Construction -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5.3", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#loading-sequences-of-fixed-length"}]'>
                    <h2 class="truncate-title">Vocabulary Construction</h2>
                    <div style="font-size: 0.45em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">Building Separate Vocabularies</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 25px;">
                                <div class="emphasis-box" style="background: #F5F5FF; border-left: 4px solid #10099F;">
                                    <h5 style="color: #10099F; margin: 0 0 10px 0;">Source Vocabulary</h5>
                                    <p style="margin: 0; font-size: 0.9em;">Contains all unique tokens from the source language (English)</p>
                                </div>
                                <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                                    <h5 style="color: #2DD2C0; margin: 0 0 10px 0;">Target Vocabulary</h5>
                                    <p style="margin: 0; font-size: 0.9em;">Contains all unique tokens from the target language (French)</p>
                                </div>
                            </div>
                        </div>
                        <div class="fragment">
                            <h4 style="color: #10099F;">Handling Infrequent Tokens</h4>
                            <pre><code class="python" style="font-size: 0.9em;">vocab = d2l.Vocab(sentences, min_freq=2)</code></pre>
                            <div class="emphasis-box" style="margin-top: 15px; background: #FFF5F5; border-left: 4px solid #FC8484;">
                                <p style="margin: 0;"><strong>Strategy:</strong> Tokens appearing fewer than <span class="tooltip"><code>min_freq=2</code><span class="tooltiptext">Minimum frequency threshold: tokens appearing less than this number are replaced with &lt;unk&gt;</span></span> times are replaced with <code>&lt;unk&gt;</code></p>
                            </div>
                        </div>
                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">Vocabulary Size Comparison</h4>
                            <table style="width: 100%; border-collapse: collapse;">
                                <thead style="background: #10099F; color: white;">
                                    <tr>
                                        <th style="padding: 10px; border: 1px solid #EEEEEE;">Tokenization Type</th>
                                        <th style="padding: 10px; border: 1px solid #EEEEEE;">Typical Vocabulary Size</th>
                                        <th style="padding: 10px; border: 1px solid #EEEEEE;">Trade-off</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE;"><strong>Word-Level</strong></td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE;">Thousands (e.g., 10K-50K)</td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE;">Larger vocab, shorter sequences</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE;"><strong>Character-Level</strong></td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE;">< 100</td>
                                        <td style="padding: 10px; border: 1px solid #EEEEEE;">Smaller vocab, longer sequences</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                </section>

                <!-- MCQ #3: Padding & Vocabulary -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding: Padding & Vocabulary</h2>
                    <div data-mcq='{
                        "question": "Why do we replace infrequent tokens (appearing < min_freq times) with &lt;unk&gt; instead of keeping them in the vocabulary?",
                        "type": "single",
                        "options": [
                            {
                                "text": "To reduce memory usage and improve generalization by preventing overfitting to rare words",
                                "correct": true,
                                "explanation": "Correct! Rare words that appear only once or twice are unreliable for learning meaningful representations. Replacing them with &lt;unk&gt; reduces vocabulary size, saves memory, and forces the model to learn more robust patterns that generalize better to unseen rare words."
                            },
                            {
                                "text": "To make all sequences the same length",
                                "correct": false,
                                "explanation": "Sequence length normalization is handled by padding and truncation, not by replacing rare tokens with &lt;unk&gt;."
                            },
                            {
                                "text": "To ensure the source and target vocabularies have the same size",
                                "correct": false,
                                "explanation": "Source and target vocabularies are built independently and typically have different sizes. The &lt;unk&gt; token replacement is about handling rare words, not matching vocabulary sizes."
                            },
                            {
                                "text": "To remove punctuation from the vocabulary",
                                "correct": false,
                                "explanation": "Punctuation marks are kept in the vocabulary as separate tokens. The &lt;unk&gt; replacement targets infrequent words, not punctuation."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 15: Decoder Input/Output Relationship (Interactive) -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5.3", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#loading-sequences-of-fixed-length"}]'>
                    <h2 class="truncate-title">Decoder Input/Output Relationship</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <div class="emphasis-box" style="background: #FFF9E6; border-left: 4px solid #FAC55B; margin-bottom: 20px;">
                                <p style="margin: 0;"><strong>Critical Concept:</strong> The decoder input is the target sequence <em>shifted by one token</em> compared to the labels</p>
                            </div>
                        </div>
                        <div id="decoder-shift-demo" style="margin-top: 20px;"></div>
                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #10099F;">In Code:</h4>
                            <pre><code class="python" style="font-size: 0.85em;">return ((src_array, tgt_array[:,:-1], src_valid_len, tgt_array[:,1:]),
        src_vocab, tgt_vocab)

# tgt_array[:,:-1]  ‚Üí Decoder input (all but last token)
# tgt_array[:,1:]   ‚Üí Labels (all but first token)</code></pre>
                        </div>
                    </div>
                </section>

                <!-- Slide 16: Complete Code Implementation -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5.3", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#loading-sequences-of-fixed-length"}]'>
                    <h2 class="truncate-title">Complete <code>_build_arrays()</code> Implementation</h2>
                    <div style="font-size: 0.65em;">
                        <pre><code class="python" style="font-size: 1em;">@d2l.add_to_class(MTFraEng)
def _build_arrays(self, raw_text, src_vocab=None, tgt_vocab=None):
    def _build_array(sentences, vocab, is_tgt=False):
        # Pad or truncate to num_steps
        pad_or_trim = lambda seq, t: (
            seq[:t] if len(seq) > t else seq + ['<pad>'] * (t - len(seq)))
        sentences = [pad_or_trim(s, self.num_steps) for s in sentences]

        # Add <bos> token for target sequences
        if is_tgt:
            sentences = [['<bos>'] + s for s in sentences]

        # Build vocabulary with min_freq=2 (infrequent ‚Üí <unk>)
        if vocab is None:
            vocab = d2l.Vocab(sentences, min_freq=2)

        # Convert tokens to indices
        array = torch.tensor([vocab[s] for s in sentences])

        # Calculate valid length (excluding padding)
        valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)

        return array, vocab, valid_len

    # Tokenize the text
    src, tgt = self._tokenize(self._preprocess(raw_text),
                              self.num_train + self.num_val)

    # Build source and target arrays
    src_array, src_vocab, src_valid_len = _build_array(src, src_vocab)
    tgt_array, tgt_vocab, _ = _build_array(tgt, tgt_vocab, True)

    # Return: (source, decoder_input, source_lengths, labels), vocabs
    return ((src_array, tgt_array[:,:-1], src_valid_len, tgt_array[:,1:]),
            src_vocab, tgt_vocab)</code></pre>
                    </div>
                </section>

                <!-- MCQ #4: Dataset Structure -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding: Dataset Structure</h2>
                    <div data-mcq='{
                        "question": "In the returned tuple (src_array, tgt_array[:,:-1], src_valid_len, tgt_array[:,1:]), what is the relationship between tgt_array[:,:-1] and tgt_array[:,1:]?",
                        "type": "single",
                        "options": [
                            {
                                "text": "They are identical copies",
                                "correct": false,
                                "explanation": "They are not identical. One is shifted by one position relative to the other."
                            },
                            {
                                "text": "tgt_array[:,:-1] is the decoder input (with &lt;bos&gt;), and tgt_array[:,1:] is the labels (without &lt;bos&gt;)",
                                "correct": true,
                                "explanation": "Correct! The decoder uses tgt_array[:,:-1] as input (which starts with &lt;bos&gt;) and tries to predict tgt_array[:,1:] as output (which does not have &lt;bos&gt; but has all subsequent tokens). This shifted relationship is fundamental to training sequence-to-sequence models."
                            },
                            {
                                "text": "One is for the source language and one is for the target language",
                                "correct": false,
                                "explanation": "Both tgt_array[:,:-1] and tgt_array[:,1:] are from the target language. The source language is in src_array."
                            },
                            {
                                "text": "One contains tokens and the other contains token frequencies",
                                "correct": false,
                                "explanation": "Both contain token indices (not frequencies). They differ in which tokens are included due to the one-position shift."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 20: Special Tokens Reference -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html"}]'>
                    <h2 class="truncate-title">Special Tokens Quick Reference</h2>
                    <div style="font-size: 0.8em;">
                        <table style="width: 100%; border-collapse: collapse; margin-top: 20px;">
                            <thead style="background: #10099F; color: white;">
                                <tr>
                                    <th style="padding: 15px; border: 1px solid #EEEEEE; text-align: left;">Token</th>
                                    <th style="padding: 15px; border: 1px solid #EEEEEE; text-align: left;">Purpose</th>
                                    <th style="padding: 15px; border: 1px solid #EEEEEE; text-align: left;">Usage</th>
                                </tr>
                            </thead>
                            <tbody style="font-size: 0.95em;">
                                <tr style="background: #FFF5F5;">
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;"><code style="color: #FC8484; font-weight: bold;">&lt;eos&gt;</code></td>
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;">End of sequence</td>
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;">Appended to source and target sequences to mark the end; signals model to stop generation</td>
                                </tr>
                                <tr style="background: #FFF9E6;">
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;"><code style="color: #FAC55B; font-weight: bold;">&lt;bos&gt;</code></td>
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;">Beginning of sequence</td>
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;">Prepended to target sequences as first decoder input to start generation</td>
                                </tr>
                                <tr style="background: #F0FFF9;">
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;"><code style="color: #2DD2C0; font-weight: bold;">&lt;pad&gt;</code></td>
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;">Padding</td>
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;">Added to sequences shorter than num_steps to make all sequences the same length</td>
                                </tr>
                                <tr style="background: #F5F5FF;">
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;"><code style="color: #10099F; font-weight: bold;">&lt;unk&gt;</code></td>
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;">Unknown</td>
                                    <td style="padding: 12px; border: 1px solid #EEEEEE;">Replaces infrequent tokens (appearing < min_freq times) to reduce vocabulary size</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </section>

                <!-- Slide 21: Key Takeaways -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.5.5", "url": "https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#summary"}]'>
                    <h2 class="truncate-title">Key Takeaways</h2>
                    <div style="font-size: 0.5em;">
                        <div class="emphasis-box" style="background: #F5F5FF; border-left: 4px solid #10099F; margin-bottom: 15px;">
                            <p style="margin: 0;"><strong>1. Machine Translation:</strong> Automatic mapping from a sequence in a source language to a plausible translation in a target language</p>
                        </div>
                        <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; margin-bottom: 15px;">
                            <p style="margin: 0;"><strong>2. Tokenization Trade-offs:</strong> Word-level tokenization yields larger vocabularies but shorter sequences compared to character-level</p>
                        </div>
                        <div class="emphasis-box" style="background: #FFF9E6; border-left: 4px solid #FAC55B; margin-bottom: 15px;">
                            <p style="margin: 0;"><strong>3. Handling Large Vocabularies:</strong> Treat infrequent tokens as <code>&lt;unk&gt;</code> to mitigate vocabulary size and improve generalization</p>
                        </div>
                        <div class="emphasis-box" style="background: #FFF5F5; border-left: 4px solid #FC8484; margin-bottom: 15px;">
                            <p style="margin: 0;"><strong>4. Sequence Length Normalization:</strong> Use truncation and padding to ensure all sequences have the same length for efficient minibatch processing</p>
                        </div>
                        <div class="emphasis-box" style="background: #FFFBF0; border-left: 4px solid #FFA05F;">
                            <p style="margin: 0;"><strong>5. Modern Implementation:</strong> Often bucket sequences with similar lengths to avoid wasting excessive computation on padding</p>
                        </div>
                    </div>
                </section>

                <!-- MCQ #5: Comprehensive Understanding -->
                <section>
                    <h2 class="truncate-title">Final Assessment: Comprehensive Understanding</h2>
                    <div data-mcq='{
                        "question": "Consider a machine translation dataset with num_steps=9. A target sequence is [\"bonjour\", \".\", \"<eos>\"]. What will be the decoder input and label for this sequence after preprocessing?",
                        "type": "single",
                        "options": [
                            {
                                "text": "Decoder input: [\"<bos>\", \"bonjour\", \".\", \"<eos>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"], Label: [\"bonjour\", \".\", \"<eos>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]",
                                "correct": true,
                                "explanation": "Correct! The sequence is first padded to num_steps=9, then &lt;bos&gt; is prepended. The decoder input is tgt_array[:,:-1] (all but last token) and label is tgt_array[:,1:] (all but first token, which is &lt;bos&gt;). This creates the one-token shift needed for training."
                            },
                            {
                                "text": "Decoder input: [\"bonjour\", \".\", \"<eos>\"], Label: [\"bonjour\", \".\", \"<eos>\"]",
                                "correct": false,
                                "explanation": "This is missing several preprocessing steps: padding to num_steps, prepending &lt;bos&gt;, and creating the shifted relationship between input and labels."
                            },
                            {
                                "text": "Decoder input: [\"<bos>\", \"bonjour\", \".\"], Label: [\"bonjour\", \".\", \"<eos>\"]",
                                "correct": false,
                                "explanation": "While this shows the correct shifting concept, it is missing the padding to num_steps=9. All sequences must have the same fixed length."
                            },
                            {
                                "text": "Decoder input: [\"bonjour\", \".\", \"<eos>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"], Label: [\"<bos>\", \"bonjour\", \".\", \"<eos>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]",
                                "correct": false,
                                "explanation": "The roles are reversed here. The decoder input should start with &lt;bos&gt;, not the label. Also, the label should not contain &lt;bos&gt;."
                            }
                        ]
                    }'></div>
                </section>

            </section>

            <!-- New Vertical Section: Encoder-Decoder Architecture -->
            <section>
                <!-- Slide 1: Introduction to Encoder-Decoder Architecture -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.6: The Encoder-Decoder Architecture", "url": "https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html"}]'>
                    <h2 class="truncate-title">The Encoder-Decoder Architecture</h2>
                    <div style="font-size: 0.85em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Challenge of Sequence-to-Sequence Problems</h4>
                            <p>In problems like machine translation, inputs and outputs are <strong>variable-length sequences</strong> that are <strong>unaligned</strong>.</p>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <img src="images/encoder-decoder.svg" alt="Encoder-Decoder Architecture" style="width: 70%; margin: 20px auto; display: block;">
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #F0F8FF; border-left: 4px solid #10099F;">
                            <p style="margin: 0;"><strong>Example:</strong> English ‚Üí French</p>
                            <p style="margin: 10px 0 0 0; font-family: 'Source Code Pro', monospace;">
                                <span style="color: #10099F;">Input:</span> "They", "are", "watching", "." <br>
                                <span style="color: #2DD2C0;">Output:</span> "Ils", "regardent", "."
                            </p>
                        </div>
                    </div>
                </section>

                <!-- Slide 2: The Core Concept -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.6", "url": "https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html"}]'>
                    <h2 class="truncate-title">The Core Concept: Two-Stage Processing</h2>
                    <div style="font-size: 0.5em;">
                        <div class="fragment">
                            <div class="emphasis-box" style="background: #F0F8FF; border-left: 4px solid #10099F; margin-bottom: 20px;">
                                <h4 style="color: #10099F; margin-top: 0;">üîµ Encoder</h4>
                                <ul style="line-height: 1.8; margin: 0;">
                                    <li><strong>Input:</strong> Variable-length sequence</li>
                                    <li><strong>Output:</strong> Fixed-shape <span class="tooltip">encoded state<span class="tooltiptext">A compact representation that captures all the information from the input sequence in a fixed-dimensional format</span></span></li>
                                    <li><strong>Purpose:</strong> Compress the input sequence into a state</li>
                                </ul>
                            </div>
                        </div>

                        <div class="fragment">
                            <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; margin-bottom: 20px;">
                                <h4 style="color: #2DD2C0; margin-top: 0;">üü¢ Decoder</h4>
                                <ul style="line-height: 1.8; margin: 0;">
                                    <li><strong>Input:</strong> Encoded state + previous target tokens</li>
                                    <li><strong>Output:</strong> Variable-length sequence (token by token)</li>
                                    <li><strong>Purpose:</strong> Acts as a <span class="tooltip">conditional language model<span class="tooltiptext">A model that predicts the next token based on both the encoded input and the previously generated tokens</span></span></li>
                                </ul>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="background: #FFF9E6; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0;"><strong>üí° Key Insight:</strong> The encoder-decoder architecture allows us to handle sequences of different lengths by using a fixed-size intermediate representation.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 3: Encoder Interface -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.6.1: Encoder", "url": "https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html#encoder"}]'>
                    <h2 class="truncate-title">The Encoder Interface</h2>
                    <div style="font-size: 0.5em;">
                        <div class="fragment">
                            <p>The encoder takes a <span class="tooltip">variable-length sequence<span class="tooltiptext">A sequence that can have different numbers of elements (tokens) for different inputs, such as sentences of varying lengths</span></span> as input and transforms it into a state.</p>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #10099F;">PyTorch Implementation</h4>
                            <pre><code class="python" data-trim data-line-numbers="1-8">
class Encoder(nn.Module):  #@save
    """The base encoder interface for the encoder-decoder architecture."""
    def __init__(self):
        super().__init__()

    # Later there can be additional arguments (e.g., length excluding padding)
    def forward(self, X, *args):
        raise NotImplementedError
                            </code></pre>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #F5F5FF; border-left: 4px solid #10099F;">
                            <p style="margin: 0;"><strong>Note:</strong> This is a <em>base interface</em> that will be inherited by specific encoder implementations (e.g., RNN-based, CNN-based, Transformer-based).</p>
                        </div>

                        <div class="fragment" style="margin-top: 15px;">
                            <p><strong>Key Points:</strong></p>
                            <ul style="line-height: 1.7;">
                                <li>The <code>forward</code> method takes input <code>X</code></li>
                                <li>Additional arguments (<code>*args</code>) can include sequence lengths (for handling padding)</li>
                                <li>Specific implementations will define how to process the input</li>
                            </ul>
                        </div>
                    </div>
                </section>

                <!-- Slide 4: Decoder Interface -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.6.2: Decoder", "url": "https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html#decoder"}]'>
                    <h2 class="truncate-title">The Decoder Interface</h2>
                    <div style="font-size: 0.5em;">
                        <div class="fragment">
                            <p>The decoder generates output tokens one at a time, conditioned on the encoded state.</p>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #2DD2C0;">PyTorch Implementation</h4>
                            <pre><code class="python" data-trim data-line-numbers="1-12">
class Decoder(nn.Module):  #@save
    """The base decoder interface for the encoder-decoder architecture."""
    def __init__(self):
        super().__init__()

    # Later there can be additional arguments (e.g., length excluding padding)
    def init_state(self, enc_all_outputs, *args):
        raise NotImplementedError

    def forward(self, X, state):
        raise NotImplementedError
                            </code></pre>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px;">
                                <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                                    <h5 style="color: #2DD2C0; margin-top: 0;">init_state</h5>
                                    <p style="font-size: 0.95em; margin: 0;">Converts encoder output into the decoder's initial state. May require extra inputs like valid sequence length.</p>
                                </div>
                                <div class="emphasis-box" style="background: #F0F8FF; border-left: 4px solid #10099F;">
                                    <h5 style="color: #10099F; margin-top: 0;">forward</h5>
                                    <p style="font-size: 0.95em; margin: 0;">Maps input (previous token) and current state to output token at current time step.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- MCQ #1: Encoder and Decoder Understanding -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "What is the primary reason for having an `init_state` method separate from the decoder forward method?",
                        "type": "single",
                        "options": [
                            {
                                "text": "To save memory by initializing the state only once",
                                "correct": false,
                                "explanation": "While memory efficiency is a benefit, this is not the primary reason. The main purpose is to properly transform the encoder output into a format suitable for the decoder."
                            },
                            {
                                "text": "To convert the encoder output into the appropriate format/shape needed by the decoder",
                                "correct": true,
                                "explanation": "Correct! The encoder output (enc_all_outputs) may need transformation before it can be used as the decoder state. For example, the encoder might output all hidden states, but the decoder only needs the final state, or the output might need reshaping/projection to match the hidden size of the decoder."
                            },
                            {
                                "text": "To ensure the decoder can run without an encoder",
                                "correct": false,
                                "explanation": "The decoder requires encoder outputs to initialize its state. The init_state method does not make the decoder independent of the encoder."
                            },
                            {
                                "text": "To allow the decoder to process multiple sequences in parallel",
                                "correct": false,
                                "explanation": "Parallel processing is handled through batching in the forward method, not through init_state. The init_state method is about transforming the encoder output format."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 5: EncoderDecoder Class -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.6.3: Putting the Encoder and Decoder Together", "url": "https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html#putting-the-encoder-and-decoder-together"}]'>
                    <h2 class="truncate-title">Putting the Encoder and Decoder Together</h2>
                    <div style="font-size: 0.75em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Complete EncoderDecoder Class</h4>
                            <pre><code class="python" data-trim data-line-numbers="1-11">
class EncoderDecoder(d2l.Classifier):  #@save
    """The base class for the encoder-decoder architecture."""
    def __init__(self, encoder, decoder):
        super().__init__()
        self.encoder = encoder
        self.decoder = decoder

    def forward(self, enc_X, dec_X, *args):
        enc_all_outputs = self.encoder(enc_X, *args)
        dec_state = self.decoder.init_state(enc_all_outputs, *args)
        # Return decoder output only
        return self.decoder(dec_X, dec_state)[0]
                            </code></pre>
                        </div>

                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #2DD2C0;">Forward Propagation Flow</h4>
                            <div style="background: #F5F5F5; padding: 20px; border-radius: 8px; margin-top: 10px;">
                                <div style="display: flex; align-items: center; justify-content: space-around; font-family: 'Source Code Pro', monospace; font-size: 0.9em;">
                                    <div style="text-align: center;">
                                        <div style="background: #10099F; color: white; padding: 15px; border-radius: 8px;">enc_X</div>
                                        <div style="margin: 5px 0; font-size: 0.8em; color: #666;">Source sequence</div>
                                    </div>
                                    <div style="font-size: 2em; color: #10099F;">‚Üí</div>
                                    <div style="text-align: center;">
                                        <div style="background: #10099F; color: white; padding: 15px; border-radius: 8px;">Encoder</div>
                                        <div style="margin: 5px 0; font-size: 0.8em; color: #666;">Line 9</div>
                                    </div>
                                    <div style="font-size: 2em; color: #2DD2C0;">‚Üí</div>
                                    <div style="text-align: center;">
                                        <div style="background: #FAC55B; color: #262626; padding: 15px; border-radius: 8px;">State</div>
                                        <div style="margin: 5px 0; font-size: 0.8em; color: #666;">Line 10</div>
                                    </div>
                                    <div style="font-size: 2em; color: #2DD2C0;">‚Üí</div>
                                    <div style="text-align: center;">
                                        <div style="background: #2DD2C0; color: white; padding: 15px; border-radius: 8px;">Decoder</div>
                                        <div style="margin: 5px 0; font-size: 0.8em; color: #666;">Line 12</div>
                                    </div>
                                    <div style="font-size: 2em; color: #FC8484;">‚Üí</div>
                                    <div style="text-align: center;">
                                        <div style="background: #FC8484; color: white; padding: 15px; border-radius: 8px;">Output</div>
                                        <div style="margin: 5px 0; font-size: 0.8em; color: #666;">Target sequence</div>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #FFF9E6; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0;"><strong>üí° Note:</strong> <code>dec_X</code> is the target sequence (shifted by one position) used during training for <span class="tooltip">teacher forcing<span class="tooltiptext">A training strategy where the decoder receives the true previous target token as input, rather than its own prediction, to speed up training</span></span>.</p>
                        </div>
                    </div>
                </section>

                <!-- Slide 6: Interactive Visualization -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.6", "url": "https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html"}]'>
                    <h2 class="truncate-title">Encoder-Decoder in Action</h2>
                    <div style="font-size: 0.8em;">
                        <div class="demo-controls" style="display: flex; align-items: center; justify-content: center; gap: 15px; margin-bottom: 15px; padding: 10px; background: #f9f9f9; border-radius: 5px; z-index: 100; position: relative;">
                            <button id="animate-btn" style="background: #10099F; color: white; border: none; padding: 8px 16px; border-radius: 5px; cursor: pointer;">‚ñ∂ Animate</button>
                            <button id="reset-btn" style="background: #FC8484; color: white; border: none; padding: 8px 16px; border-radius: 5px; cursor: pointer;">‚ü≤ Reset</button>
                            <label style="display: flex; align-items: center; gap: 8px;">
                                Speed:
                                <input type="range" id="speed-slider" min="0.5" max="2" step="0.1" value="1" style="width: 100px;">
                                <span id="speed-value">1.0x</span>
                            </label>
                        </div>
                        <div id="encoder-decoder-viz" style="width: 100%; height: 450px; margin-top: 10px;"></div>
                    </div>
                </section>

                <!-- MCQ #2: Architecture Flow Understanding -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "In the EncoderDecoder forward method, why is `dec_X` passed to the decoder along with the decoder state?",
                        "type": "single",
                        "options": [
                            {
                                "text": "To provide the decoder with the source sequence for reference",
                                "correct": false,
                                "explanation": "The source sequence information is already captured in the decoder state (which comes from the encoder). The decoder does not need the original source sequence."
                            },
                            {
                                "text": "To provide the ground truth previous tokens during training (teacher forcing)",
                                "correct": true,
                                "explanation": "Correct! During training, dec_X contains the target sequence shifted by one position. This allows the decoder to learn by receiving the correct previous token as input, rather than its own (potentially incorrect) predictions. This technique is called teacher forcing and speeds up training."
                            },
                            {
                                "text": "To initialize the decoder hidden state",
                                "correct": false,
                                "explanation": "The decoder hidden state is initialized by the init_state method using the encoder outputs, not by dec_X."
                            },
                            {
                                "text": "To specify how many tokens the decoder should generate",
                                "correct": false,
                                "explanation": "While the length of dec_X does indicate sequence length during training, this is not the primary purpose. The main purpose is to provide ground truth tokens for teacher forcing."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Slide 7: Summary -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.6.4: Summary", "url": "https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html#summary"}]'>
                    <h2 class="truncate-title">Summary: Encoder-Decoder Architecture</h2>
                    <div style="font-size: 0.6em;">
                        <div class="emphasis-box" style="background: #F0F8FF; border-left: 4px solid #10099F; margin-bottom: 20px;">
                            <h4 style="color: #10099F; margin-top: 0;">üéØ Key Capabilities</h4>
                            <ul style="line-height: 1.8; margin: 0;">
                                <li><strong>Variable-length handling:</strong> Can process input and output sequences of different lengths</li>
                                <li><strong>Suitable for seq2seq:</strong> Perfect for machine translation, text summarization, question answering, etc.</li>
                                <li><strong>Modular design:</strong> Encoder and decoder can be implemented with different architectures (RNN, CNN, Transformer)</li>
                            </ul>
                        </div>

                        <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; margin-bottom: 20px;">
                            <h4 style="color: #2DD2C0; margin-top: 0;">üîß How It Works</h4>
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px;">
                                <div>
                                    <p style="margin: 5px 0;"><strong>Encoder:</strong></p>
                                    <p style="margin: 5px 0; font-size: 0.95em;">Input: Variable-length sequence</p>
                                    <p style="margin: 5px 0; font-size: 0.95em;">Output: Fixed-shape state</p>
                                </div>
                                <div>
                                    <p style="margin: 5px 0;"><strong>Decoder:</strong></p>
                                    <p style="margin: 5px 0; font-size: 0.95em;">Input: Fixed-shape state</p>
                                    <p style="margin: 5px 0; font-size: 0.95em;">Output: Variable-length sequence</p>
                                </div>
                            </div>
                        </div>

                        <div class="emphasis-box" style="background: #FFF9E6; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0;"><strong>üí° Next Steps:</strong> In the following sections, we will see how to implement RNN-based sequence-to-sequence models using this encoder-decoder architecture.</p>
                        </div>
                    </div>
                </section>

                <!-- MCQ #3: Final Comprehensive Question -->
                <section>
                    <h2 class="truncate-title">Final Assessment: Comprehensive Understanding</h2>
                    <div data-mcq='{
                        "question": "Suppose you want to build a system that takes a variable-length code comment and generates a variable-length function name. You decide to use the encoder-decoder architecture. Which statement is TRUE about this setup?",
                        "type": "single",
                        "options": [
                            {
                                "text": "The encoder and decoder must use the same type of neural network (e.g., both RNN or both Transformer)",
                                "correct": false,
                                "explanation": "False! The encoder-decoder architecture is modular. You can mix different architectures - for example, using a CNN encoder with an RNN decoder, or an RNN encoder with a Transformer decoder."
                            },
                            {
                                "text": "The encoder must output a sequence with the same length as the input comment",
                                "correct": false,
                                "explanation": "False! The encoder outputs a fixed-shape state (or set of states), not necessarily matching the input length. This fixed representation is then used to initialize the decoder."
                            },
                            {
                                "text": "The decoder can generate function names of arbitrary length by producing tokens sequentially",
                                "correct": true,
                                "explanation": "Correct! The decoder acts as a conditional language model that generates tokens one at a time. It can produce sequences of any length by continuing generation until it outputs an end-of-sequence token or reaches a maximum length."
                            },
                            {
                                "text": "During training, the decoder must always use its own predictions as input for the next time step",
                                "correct": false,
                                "explanation": "False! During training, we typically use teacher forcing, where the decoder receives the ground truth previous token as input rather than its own prediction. This speeds up training and provides more stable gradients."
                            }
                        ]
                    }'></div>
                </section>

            </section>

            <!-- Sequence-to-Sequence Learning Section -->
            <section>

                <!-- Section Title Slide -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.7: Sequence-to-Sequence Learning", "url": "https://d2l.ai/chapter_recurrent-modern/seq2seq.html"}]'>
                    <h2 class="truncate-title">Sequence-to-Sequence Learning for Machine Translation</h2>
                    <p>Using RNN encoder-decoder architectures for variable-length sequence transformation</p>
                    <div class="emphasis-box" style="margin-top: 30px;">
                        <p><strong>Learning Objectives:</strong></p>
                        <ul style="font-size: 0.9em; text-align: left;">
                            <li>Understand the seq2seq architecture for machine translation</li>
                            <li>Learn about teacher forcing and training strategies</li>
                            <li>Implement encoder-decoder with RNNs</li>
                            <li>Evaluate translation quality with BLEU metric</li>
                        </ul>
                    </div>
                </section>

                <!-- Problem Definition -->
                <section>
                    <h2 class="truncate-title">Sequence-to-Sequence Problems</h2>
                    <p>In <span class="tooltip">seq2seq<span class="tooltiptext">Sequence-to-sequence: Problems where both inputs and outputs are variable-length sequences that may not be aligned</span></span> problems, we need to transform variable-length input sequences into variable-length output sequences</p>

                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 30px;">
                        <div>
                            <h4 style="color: #10099F;">Examples</h4>
                            <ul style="font-size: 0.85em;">
                                <li><strong>Machine Translation</strong><br>
                                    "Hello world" ‚Üí "Bonjour le monde"</li>
                                <li><strong>Text Summarization</strong><br>
                                    Long article ‚Üí Short summary</li>
                                <li><strong>Question Answering</strong><br>
                                    Question ‚Üí Answer</li>
                                <li><strong>Code Generation</strong><br>
                                    Comment ‚Üí Function</li>
                            </ul>
                        </div>
                        <div>
                            <h4 style="color: #10099F;">Key Characteristics</h4>
                            <ul style="font-size: 0.85em;">
                                <li>Variable input length</li>
                                <li>Variable output length</li>
                                <li>Input ‚â† Output length</li>
                                <li>No token alignment</li>
                            </ul>
                            <div class="emphasis-box" style="margin-top: 15px;">
                                <p style="font-size: 0.8em;"><strong>Solution:</strong> Encoder-decoder architecture compresses input into fixed-shape context, then generates output</p>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Seq2Seq Architecture Overview -->
                <section>
                    <h2 class="truncate-title">Seq2Seq Architecture with RNNs</h2>

                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-top: 20px; font-size: 0.85em;">
                        <div style="background: #f5f5f5; padding: 15px; border-radius: 8px; border-left: 4px solid #10099F;">
                            <h4 style="color: #10099F; margin-top: 0;">Encoder RNN</h4>
                            <ul style="margin: 0;">
                                <li>Processes input sequence</li>
                                <li>Transforms to fixed-shape state</li>
                                <li>Context variable = final hidden state</li>
                            </ul>
                        </div>
                        <div style="background: #f5f5f5; padding: 15px; border-radius: 8px; border-left: 4px solid #2DD2C0;">
                            <h4 style="color: #2DD2C0; margin-top: 0;">Decoder RNN</h4>
                            <ul style="margin: 0;">
                                <li>Generates output token-by-token</li>
                                <li>Conditioned on context + previous tokens</li>
                                <li>Acts as language model</li>
                            </ul>
                        </div>
                    </div>

                    <p style="margin-top: 20px; font-size: 0.85em;"><strong>Special Tokens:</strong>
                        <code>&lt;bos&gt;</code> begins generation,
                        <code>&lt;eos&gt;</code> signals completion
                    </p>
                </section>

                <!-- Teacher Forcing -->
                <section>
                    <h2 class="truncate-title">Teacher Forcing During Training</h2>
                    <p><span class="tooltip">Teacher forcing<span class="tooltiptext">Training technique where the decoder receives ground truth tokens as input rather than its own predictions</span></span> feeds the original target sequence (labels) into the decoder during training</p>

                    <div style="margin: 30px 0; font-size: 0.5em;">
                        <h4 style="color: #10099F;">Example: English ‚Üí French</h4>
                        <div style="background: #f5f5f5; padding: 20px; border-radius: 8px; font-family: 'Source Code Pro', monospace; font-size: 0.85em;">
                            <div style="margin-bottom: 15px;">
                                <strong>Input to encoder:</strong> "They", "are", "watching", "."
                            </div>
                            <div style="margin-bottom: 15px; padding: 15px; background: white; border-radius: 5px;">
                                <strong style="color: #2DD2C0;">Decoder input:</strong> "&lt;bos&gt;", "Ils", "regardent", "."<br>
                                <strong style="color: #FC8484;">Decoder output (labels):</strong> "Ils", "regardent", ".", "&lt;eos&gt;"
                            </div>
                            <div style="color: #666;">
                                ‚Üë Target sequence shifted by one token
                            </div>
                        </div>
                    </div>

                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; font-size: 0.85em;">
                        <div>
                            <h4 style="color: #10099F;">Benefits</h4>
                            <ul>
                                <li>Faster training convergence</li>
                                <li>More stable gradients</li>
                                <li>Parallel processing possible</li>
                            </ul>
                        </div>
                        <div>
                            <h4 style="color: #FC8484;">Alternative</h4>
                            <ul>
                                <li>Feed predicted tokens</li>
                                <li>Matches inference behavior</li>
                                <li>Slower but more robust</li>
                            </ul>
                        </div>
                    </div>
                </section>

                <!-- Teacher Forcing MCQ -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding: Teacher Forcing</h2>
                    <div data-mcq='{
                        "question": "During teacher forcing, if the target sequence is \"Je suis ici .\", what is fed as input to the decoder at training time?",
                        "type": "single",
                        "options": [
                            {
                                "text": "\"Je suis ici .\"",
                                "correct": false,
                                "explanation": "Incorrect. The input sequence needs to be shifted and start with the beginning-of-sequence token."
                            },
                            {
                                "text": "\"<bos> Je suis ici\"",
                                "correct": true,
                                "explanation": "Correct! Teacher forcing feeds <bos> followed by all tokens except the last one. The decoder then predicts \"Je suis ici .\" as output, effectively shifting by one position."
                            },
                            {
                                "text": "\"<bos> Je suis ici .\"",
                                "correct": false,
                                "explanation": "Incorrect. This would make the input and output the same length when the output should include <eos>. The input should exclude the final token."
                            },
                            {
                                "text": "The decoder predictions from the previous time step",
                                "correct": false,
                                "explanation": "Incorrect. That describes inference or scheduled sampling, not teacher forcing. Teacher forcing specifically uses ground truth tokens."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Encoder Architecture -->
                <section>
                    <h2 class="truncate-title">The RNN Encoder</h2>
                    <p>The encoder transforms a variable-length input sequence into a fixed-shape <span class="tooltip">context variable<span class="tooltiptext">A fixed-size representation that encodes all information from the input sequence</span></span></p>

                    <div style="margin: 25px 0; font-size: 0.5em;">
                        <h4 style="color: #10099F;">Recurrent Transformation</h4>
                        <p style="font-size: 0.9em;">At each time step $t$, the RNN transforms the input and previous hidden state:</p>
                        $$\mathbf{h}_t = f(\mathbf{x}_t, \mathbf{h}_{t-1})$$
                        <p style="font-size: 0.85em; color: #666; margin-top: 10px;">
                            where $\mathbf{x}_t$ is the input feature vector for token $x_t$, and $\mathbf{h}_{t-1}$ is the previous hidden state
                        </p>
                    </div>

                    <div style="margin: 25px 0; font-size: 0.5em;">
                        <h4 style="color: #10099F;">Context Variable</h4>
                        <p style="font-size: 0.9em;">The context is derived from all hidden states through a function $q$:</p>
                        $$\mathbf{c} = q(\mathbf{h}_1, \ldots, \mathbf{h}_T)$$
                        <div class="emphasis-box" style="margin-top: 15px;">
                            <p style="font-size: 0.85em;"><strong>Common Choice:</strong> $\mathbf{c} = \mathbf{h}_T$ (final hidden state)<br>
                            This captures information from the entire input sequence through the recurrent connections</p>
                        </div>
                    </div>
                </section>

                <!-- Encoder Implementation -->
                <section>
                    <h2 class="truncate-title">Encoder Implementation</h2>
                    <p style="font-size: 0.9em;">Using a multilayer <span class="tooltip">GRU<span class="tooltiptext">Gated Recurrent Unit: A type of RNN that uses gating mechanisms to better capture long-term dependencies</span></span> with embedding layer</p>

                    <pre><code class="language-python" style="font-size: 0.65em; max-height: 250px;">class Seq2SeqEncoder(d2l.Encoder):
    """The RNN encoder for sequence-to-sequence learning."""
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0):
        super().__init__()
        # Embedding layer: converts token indices to feature vectors
        self.embedding = nn.Embedding(vocab_size, embed_size)
        # Multi-layer GRU
        self.rnn = d2l.GRU(embed_size, num_hiddens, num_layers, dropout)
        self.apply(init_seq2seq)

    def forward(self, X, *args):
        # X shape: (batch_size, num_steps)
        embs = self.embedding(X.t().type(torch.int64))
        # embs shape: (num_steps, batch_size, embed_size)
        outputs, state = self.rnn(embs)
        # outputs shape: (num_steps, batch_size, num_hiddens)
        # state shape: (num_layers, batch_size, num_hiddens)
        return outputs, state</code></pre>

                    <div style="margin-top: 20px; font-size: 0.65em;">
                        <p><strong>Key Components:</strong></p>
                        <ul>
                            <li><strong>Embedding layer:</strong> Maps vocab_size ‚Üí embed_size dimensional vectors</li>
                            <li><strong>GRU layers:</strong> Process sequence and maintain hidden states</li>
                            <li><strong>Return values:</strong> All hidden states + final state for decoder initialization</li>
                        </ul>
                    </div>
                </section>

                <!-- Encoder Details -->
                <section>
                    <h2 class="truncate-title">Encoder Design Choices</h2>

                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 25px; font-size: 0.5em;">
                        <div style="background: #f5f5f5; padding: 20px; border-radius: 8px;">
                            <h4 style="color: #10099F; margin-top: 0;">Unidirectional RNN</h4>
                            <p style="font-size: 0.85em;">Hidden state $\mathbf{h}_t$ depends only on:</p>
                            <ul style="font-size: 0.85em;">
                                <li>Input at time $t$: $x_t$</li>
                                <li>Previous inputs: $x_1, \ldots, x_{t-1}$</li>
                            </ul>
                            <p style="font-size: 0.8em; color: #666; margin-top: 15px;">
                                ‚úì Simpler architecture<br>
                                ‚úì Suitable for online processing<br>
                                ‚úó Cannot see future context
                            </p>
                        </div>

                        <div style="background: #f5f5f5; padding: 20px; border-radius: 8px;">
                            <h4 style="color: #2DD2C0; margin-top: 0;">Bidirectional RNN</h4>
                            <p style="font-size: 0.85em;">Hidden state $\mathbf{h}_t$ depends on:</p>
                            <ul style="font-size: 0.85em;">
                                <li>Input at time $t$: $x_t$</li>
                                <li>All other inputs: $x_1, \ldots, x_T$</li>
                            </ul>
                            <p style="font-size: 0.8em; color: #666; margin-top: 15px;">
                                ‚úì Encodes full sequence info<br>
                                ‚úì Better representations<br>
                                ‚úó Requires complete sequence
                            </p>
                        </div>
                    </div>

                    <div class="emphasis-box" style="margin-top: 25px;">
                        <p style="font-size: 0.85em;"><strong>Shape Information (with batch_size=4, num_steps=9, num_hiddens=16, num_layers=2):</strong></p>
                        <ul style="font-size: 0.8em; margin: 10px 0 0 20px;">
                            <li><code>outputs</code>: (num_steps=9, batch_size=4, num_hiddens=16)</li>
                            <li><code>state</code>: (num_layers=2, batch_size=4, num_hiddens=16)</li>
                        </ul>
                    </div>
                </section>

                <!-- Decoder Architecture -->
                <section>
                    <h2 class="truncate-title">The RNN Decoder</h2>
                    <p>The decoder generates output tokens sequentially, conditioned on the context and previous outputs</p>

                    <div style="margin: 25px 0; font-size: 0.5em;">
                        <h4 style="color: #2DD2C0;">Hidden State Update</h4>
                        <p style="font-size: 0.9em;">At each decoding step $t'$, transform previous output, context, and hidden state:</p>
                        $$\mathbf{s}_{t'} = g(y_{t'-1}, \mathbf{c}, \mathbf{s}_{t'-1})$$
                        <p style="font-size: 0.85em; color: #666; margin-top: 10px;">
                            where $y_{t'-1}$ is the previous output token, $\mathbf{c}$ is the context variable, and $\mathbf{s}_{t'-1}$ is the previous decoder hidden state
                        </p>
                    </div>

                    <div style="margin: 25px 0; font-size: 0.5em;">
                        <h4 style="color: #2DD2C0;">Output Distribution</h4>
                        <p style="font-size: 0.9em;">Predict probability of next token conditioned on history:</p>
                        $$P(y_{t'+1} \mid y_1, \ldots, y_{t'}, \mathbf{c})$$
                        <div class="emphasis-box" style="margin-top: 15px;">
                            <p style="font-size: 0.85em;"><strong>Implementation:</strong> Use fully connected layer + softmax on $\mathbf{s}_{t'}$ to compute this distribution over the vocabulary</p>
                        </div>
                    </div>
                </section>

                <!-- Decoder Implementation -->
                <section>
                    <h2 class="truncate-title">Decoder Implementation</h2>
                    <p style="font-size: 0.9em;">Context variable concatenated with decoder input at all time steps</p>

                    <pre><code class="language-python" style="font-size: 0.58em; max-height: 250px;">class Seq2SeqDecoder(d2l.Decoder):
    """The RNN decoder for sequence to sequence learning."""
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_size)
        # Input size = embed_size + num_hiddens (embedding + context)
        self.rnn = d2l.GRU(embed_size+num_hiddens, num_hiddens,
                           num_layers, dropout)
        self.dense = nn.LazyLinear(vocab_size)
        self.apply(init_seq2seq)

    def init_state(self, enc_all_outputs, *args):
        return enc_all_outputs

    def forward(self, X, state):
        # X shape: (batch_size, num_steps)
        embs = self.embedding(X.t().type(torch.int32))
        # embs shape: (num_steps, batch_size, embed_size)
        enc_output, hidden_state = state
        # context shape: (batch_size, num_hiddens)
        context = enc_output[-1]  # Use final encoder output
        # Broadcast context to (num_steps, batch_size, num_hiddens)
        context = context.repeat(embs.shape[0], 1, 1)
        # Concatenate embeddings and context
        embs_and_context = torch.cat((embs, context), -1)
        outputs, hidden_state = self.rnn(embs_and_context, hidden_state)
        outputs = self.dense(outputs).swapaxes(0, 1)
        # outputs shape: (batch_size, num_steps, vocab_size)
        return outputs, [enc_output, hidden_state]</code></pre>

                    <p style="margin-top: 15px; font-size: 0.85em;"><strong>Key Design:</strong> Context $\mathbf{c}$ is concatenated with every decoder input, providing encoder information at each step</p>
                </section>

                <!-- Decoder MCQ -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding: Decoder Mechanics</h2>
                    <div data-mcq='{
                        "question": "Why is the context variable concatenated with the decoder input at EVERY time step, rather than just initializing the decoder hidden state?",
                        "type": "single",
                        "options": [
                            {
                                "text": "To reduce the computational cost of the decoder",
                                "correct": false,
                                "explanation": "Incorrect. Concatenating context at every step actually increases computation compared to just using it for initialization."
                            },
                            {
                                "text": "To ensure encoder information is directly available throughout generation",
                                "correct": true,
                                "explanation": "Correct! By concatenating context at each step, we provide direct access to encoded source information throughout the entire generation process, not just through the recurrent hidden state which may forget earlier information."
                            },
                            {
                                "text": "To match the dimensions of the encoder and decoder",
                                "correct": false,
                                "explanation": "Incorrect. Dimension matching is achieved through layer design, not by concatenating context repeatedly."
                            },
                            {
                                "text": "Because teacher forcing requires the context at each step",
                                "correct": false,
                                "explanation": "Incorrect. Teacher forcing is about using ground truth tokens as input, not about concatenating context. Context concatenation is independent of the teacher forcing strategy."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Complete Seq2Seq Model -->
                <section>
                    <h2 class="truncate-title">Complete Seq2Seq Model</h2>
                    <p style="font-size: 0.9em;">Combining encoder and decoder into a trainable model</p>

                    <pre><code class="language-python" style="font-size: 0.7em; max-height: 150px;">class Seq2Seq(d2l.EncoderDecoder):
    """The RNN encoder-decoder for sequence to sequence learning."""
    def __init__(self, encoder, decoder, tgt_pad, lr):
        super().__init__(encoder, decoder)
        self.save_hyperparameters()

    def validation_step(self, batch):
        Y_hat = self(*batch[:-1])
        self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)

    def configure_optimizers(self):
        # Adam optimizer is used here
        return torch.optim.Adam(self.parameters(), lr=self.lr)</code></pre>

                    <div style="margin-top: 25px; font-size: 0.5em;">
                        <h4 style="color: #10099F;">Model Components</h4>
                        <ul>
                            <li><strong>encoder:</strong> Seq2SeqEncoder instance</li>
                            <li><strong>decoder:</strong> Seq2SeqDecoder instance</li>
                            <li><strong>tgt_pad:</strong> Padding token index for masking</li>
                            <li><strong>lr:</strong> Learning rate for optimization</li>
                        </ul>
                    </div>

                    <div class="emphasis-box" style="margin-top: 20px; font-size: 0.5em;">
                        <p style="font-size: 0.85em;"><strong>Optimizer Choice:</strong> Adam is commonly used for seq2seq models due to its adaptive learning rates and momentum, which handle the varying gradients across encoder and decoder effectively</p>
                    </div>
                </section>

                <!-- Loss Function with Masking -->
                <section>
                    <h2 class="truncate-title">Loss Function with Masking</h2>
                    <p>We must exclude padding tokens from loss calculations to avoid biasing the model</p>

                    <div style="margin: 25px 0; font-size: 0.5em;">
                        <h4 style="color: #10099F;">The Problem</h4>
                        <p style="font-size: 0.85em;">Sequences have varying lengths, but are batched into fixed-shape tensors using padding:</p>
                        <div style="background: #f5f5f5; padding: 15px; border-radius: 8px; margin-top: 15px; font-family: 'Source Code Pro', monospace; font-size: 0.8em;">
                            Sequence 1: "Hello world" + <code>&lt;pad&gt;</code> + <code>&lt;pad&gt;</code><br>
                            Sequence 2: "Hi" + <code>&lt;pad&gt;</code> + <code>&lt;pad&gt;</code> + <code>&lt;pad&gt;</code><br>
                            Sequence 3: "Good morning everyone" (no padding)
                        </div>
                        <p style="font-size: 0.85em; color: #666; margin-top: 10px;">
                            Computing loss on <code>&lt;pad&gt;</code> tokens is meaningless and harmful
                        </p>
                    </div>

                    <div style="margin: 25px 0; font-size: 0.5em;">
                        <h4 style="color: #10099F;">The Solution: Masking</h4>
                        <pre><code class="language-python" style="font-size: 0.7em;">@d2l.add_to_class(Seq2Seq)
def loss(self, Y_hat, Y):
    l = super(Seq2Seq, self).loss(Y_hat, Y, averaged=False)
    # Create mask: 1 for real tokens, 0 for padding
    mask = (Y.reshape(-1) != self.tgt_pad).type(torch.float32)
    # Multiply loss by mask (zeros out padding positions)
    return (l * mask).sum() / mask.sum()</code></pre>
                    </div>

                    <p style="font-size: 0.85em; margin-top: 20px; font-size: 0.5em;">
                        <strong>Effect:</strong> Only genuine tokens contribute to loss; padding tokens are effectively ignored
                    </p>
                </section>

                <!-- Masking MCQ -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding: Masking</h2>
                    <div data-mcq='{
                        "question": "What would happen if we did NOT use masking in the loss calculation for padded sequences?",
                        "type": "multiple",
                        "options": [
                            {
                                "text": "The model would learn to predict padding tokens well",
                                "correct": true,
                                "explanation": "Correct! Without masking, padding tokens contribute to the loss, so the model would optimize for predicting them, which is not useful."
                            },
                            {
                                "text": "Shorter sequences would have disproportionately lower loss values",
                                "correct": false,
                                "explanation": "Incorrect. Shorter sequences have MORE padding, so they would actually have higher loss from all the padding positions if not masked."
                            },
                            {
                                "text": "The model might learn to generate padding tokens in its output",
                                "correct": true,
                                "explanation": "Correct! If padding is part of the training signal, the model might learn it as a valid output token, which would corrupt generated sequences."
                            },
                            {
                                "text": "Training would be faster because we compute loss on all positions",
                                "correct": false,
                                "explanation": "Incorrect. While we still compute loss at all positions, the quality of training would be worse because the model is learning from meaningless signals."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Training -->
                <section>
                    <h2 class="truncate-title">Training the Seq2Seq Model</h2>
                    <p style="font-size: 0.9em;">Training on English-French translation dataset</p>

                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 20px; font-size: 0.5em;">
                        <div>
                            <h4 style="color: #10099F;">Hyperparameters</h4>
                            <pre><code class="language-python" style="font-size: 0.65em;">embed_size = 256
num_hiddens = 256
num_layers = 2
dropout = 0.2
lr = 0.005
batch_size = 128
max_epochs = 30
gradient_clip_val = 1</code></pre>
                        </div>
                        <div>
                            <h4 style="color: #10099F;">Training Setup</h4>
                            <pre><code class="language-python" style="font-size: 0.65em;">encoder = Seq2SeqEncoder(
    len(data.src_vocab),
    embed_size, num_hiddens,
    num_layers, dropout)
decoder = Seq2SeqDecoder(
    len(data.tgt_vocab),
    embed_size, num_hiddens,
    num_layers, dropout)
model = Seq2Seq(encoder, decoder,
    tgt_pad=data.tgt_vocab['<pad>'],
    lr=lr)</code></pre>
                        </div>
                    </div>

                    <div class="emphasis-box" style="margin-top: 25px; font-size: 0.5em;">
                        <p style="font-size: 0.85em;"><strong>Gradient Clipping:</strong> Essential for RNN training to prevent exploding gradients. Clips gradient norm to maximum value of 1.0</p>
                    </div>

                    <p style="margin-top: 20px; font-size: 0.85em; font-size: 0.5em;">
                        <strong>Dataset:</strong> English-French sentence pairs from the Tatoeba project
                    </p>
                </section>

                <!-- Training Results -->
                <section>
                    <h2 class="truncate-title">Training Curves and Convergence</h2>
                    <p style="font-size: 0.9em;">Loss decreases over epochs, showing model learning</p>

                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 25px; font-size: 0.85em;">
                        <div style="background: #f5f5f5; padding: 15px; border-radius: 8px;">
                            <h4 style="color: #10099F; margin-top: 0;">Observations</h4>
                            <ul style="margin: 0;">
                                <li>Training loss decreases steadily</li>
                                <li>Validation loss stabilizes after ~15 epochs</li>
                                <li>Gap indicates some overfitting</li>
                                <li>Model converges in ~30 epochs</li>
                            </ul>
                        </div>
                        <div style="background: #f5f5f5; padding: 15px; border-radius: 8px;">
                            <h4 style="color: #2DD2C0; margin-top: 0;">Typical Issues</h4>
                            <ul style="margin: 0;">
                                <li><strong>Exploding gradients:</strong> Use gradient clipping</li>
                                <li><strong>Slow convergence:</strong> Adjust learning rate</li>
                                <li><strong>Poor generalization:</strong> Add dropout or regularization</li>
                            </ul>
                        </div>
                    </div>
                </section>

                <!-- Prediction Process -->
                <section>
                    <h2 class="truncate-title">Prediction: Generating Output Sequences</h2>
                    <p>At test time, generate output token-by-token using <span class="tooltip">greedy decoding<span class="tooltiptext">Selecting the highest probability token at each step</span></span></p>


                    <div style="margin-top: 25px; font-size: 0.5em;">
                        <h4 style="color: #10099F;">Generation Process</h4>
                        <ol style="font-size: 0.85em;">
                            <li><strong>Initialize:</strong> Feed <code>&lt;bos&gt;</code> token to decoder</li>
                            <li><strong>Predict:</strong> Decoder outputs probability distribution over vocabulary</li>
                            <li><strong>Select:</strong> Choose token with highest probability (greedy)</li>
                            <li><strong>Feed back:</strong> Use selected token as next input</li>
                            <li><strong>Repeat:</strong> Until <code>&lt;eos&gt;</code> generated or max length reached</li>
                        </ol>
                    </div>

                    <div class="emphasis-box" style="margin-top: 20px; font-size: 0.5em;">
                        <p style="font-size: 0.85em;"><strong>Key Difference from Training:</strong> At test time, decoder uses its own predictions (not ground truth) as input, making generation <span class="tooltip">autoregressive<span class="tooltiptext">Each prediction depends on all previous predictions</span></span></p>
                    </div>
                </section>

                <!-- Prediction Implementation -->
                <section>
                    <h2 class="truncate-title">Prediction Implementation</h2>
                    <pre><code class="language-python" style="font-size: 0.6em; max-height: 250px;">@d2l.add_to_class(d2l.EncoderDecoder)
def predict_step(self, batch, device, num_steps,
                 save_attention_weights=False):
    batch = [a.to(device) for a in batch]
    src, tgt, src_valid_len, _ = batch

    # Encode the source sequence
    enc_all_outputs = self.encoder(src, src_valid_len)
    dec_state = self.decoder.init_state(enc_all_outputs, src_valid_len)

    # Start with <bos> token
    outputs, attention_weights = [tgt[:, (0)].unsqueeze(1), ], []

    # Generate tokens autoregressively
    for _ in range(num_steps):
        # Predict next token distribution
        Y, dec_state = self.decoder(outputs[-1], dec_state)
        # Select token with highest probability (greedy)
        outputs.append(Y.argmax(2))
        # Save attention weights (for visualization, covered later)
        if save_attention_weights:
            attention_weights.append(self.decoder.attention_weights)

    return torch.cat(outputs[1:], 1), attention_weights</code></pre>

                    <p style="margin-top: 20px; font-size: 0.85em;">
                        <strong>Note:</strong> <code>Y.argmax(2)</code> implements greedy decoding - selecting the most probable token. More sophisticated strategies like beam search will be covered in the next section.
                    </p>
                </section>

                <!-- Prediction MCQ -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding: Training vs Prediction</h2>
                    <div data-mcq='{
                        "question": "What is the main difference between how the decoder receives input during training versus during prediction/inference?",
                        "type": "single",
                        "options": [
                            {
                                "text": "During training the decoder uses greedy decoding, during inference it uses beam search",
                                "correct": false,
                                "explanation": "Incorrect. This describes different decoding strategies, not the fundamental difference in input handling."
                            },
                            {
                                "text": "During training the decoder receives ground truth previous tokens, during inference it receives its own predictions",
                                "correct": true,
                                "explanation": "Correct! This is the key difference. Training uses teacher forcing (ground truth tokens as input), while inference uses autoregressive generation (model predictions as input). This is why exposure bias can occur."
                            },
                            {
                                "text": "During training the decoder processes all tokens in parallel, during inference it processes one token at a time",
                                "correct": false,
                                "explanation": "Incorrect. While teacher forcing enables more parallel processing during training, RNNs still process sequences sequentially. The key difference is about what input is used, not parallelization."
                            },
                            {
                                "text": "During training the decoder uses dropout, during inference dropout is disabled",
                                "correct": false,
                                "explanation": "While true that dropout is disabled during inference, this is a general practice for all neural networks and not specific to the encoder-decoder input handling difference."
                            }
                        ]
                    }'></div>
                </section>

                <!-- BLEU Introduction -->
                <section>
                    <h2 class="truncate-title">Evaluating Translation Quality: BLEU</h2>
                    <p><span class="tooltip">BLEU<span class="tooltiptext">Bilingual Evaluation Understudy: An automatic metric for evaluating machine translation quality</span></span> (Bilingual Evaluation Understudy) measures similarity between predicted and reference sequences</p>

                    <div style="margin: 25px 0; font-size: 0.5em;">
                        <h4 style="color: #10099F;">Why BLEU?</h4>
                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; font-size: 0.85em;">
                            <div style="background: #f5f5f5; padding: 15px; border-radius: 8px;">
                                <h5 style="color: #2DD2C0; margin-top: 0;">Problems with Exact Match</h5>
                                <ul style="margin: 0;">
                                    <li>Many valid translations exist</li>
                                    <li>Word order can vary</li>
                                    <li>Synonyms are acceptable</li>
                                    <li>Too strict for evaluation</li>
                                </ul>
                            </div>
                            <div style="background: #f5f5f5; padding: 15px; border-radius: 8px;">
                                <h5 style="color: #10099F; margin-top: 0;">BLEU Advantages</h5>
                                <ul style="margin: 0;">
                                    <li>Automatic (no human judges)</li>
                                    <li>Fast and scalable</li>
                                    <li>Language-agnostic</li>
                                    <li>Correlates with human judgment</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div style="margin: 25px 0; font-size: 0.5em;">
                        <h4 style="color: #10099F;">Core Idea</h4>
                        <p style="font-size: 0.9em;">For any <span class="tooltip">n-gram<span class="tooltiptext">A contiguous sequence of n tokens</span></span> in the predicted sequence, check if it appears in the target sequence</p>
                        <div class="emphasis-box" style="margin-top: 15px;">
                            <p style="font-size: 0.85em;">BLEU rewards predictions that share n-grams with references, with higher weight for longer n-gram matches</p>
                        </div>
                    </div>
                </section>

                <!-- BLEU Formula -->
                <section>
                    <h2 class="truncate-title">BLEU Mathematical Definition</h2>
                    <p style="font-size: 0.9em;">BLEU combines n-gram precision with a brevity penalty</p>

                    <div style="margin: 25px 0; font-size: 0.5em;">
                        $$\text{BLEU} = \exp\left(\min\left(0, 1 - \frac{\text{len}_{\text{label}}}{\text{len}_{\text{pred}}}\right)\right) \prod_{n=1}^k p_n^{1/2^n}$$

                        <div style="margin-top: 20px; font-size: 0.85em;">
                            <p><strong>Components:</strong></p>
                            <ul>
                                <li>$p_n$: Precision of n-grams (ratio of matched n-grams to total n-grams in prediction)</li>
                                <li>$\text{len}_{\text{label}}$: Number of tokens in reference sequence</li>
                                <li>$\text{len}_{\text{pred}}$: Number of tokens in predicted sequence</li>
                                <li>$k$: Maximum n-gram length to consider (typically 4)</li>
                            </ul>
                        </div>
                    </div>

                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-top: 20px; font-size: 0.85em; font-size: 0.5em;">
                        <div style="background: #f5f5f5; padding: 15px; border-radius: 8px;">
                            <h4 style="color: #10099F; margin-top: 0;">Brevity Penalty</h4>
                            <p>$\exp\left(\min\left(0, 1 - \frac{\text{len}_{\text{label}}}{\text{len}_{\text{pred}}}\right)\right)$</p>
                            <p style="font-size: 0.9em; color: #666;">Penalizes predictions shorter than reference</p>
                        </div>
                        <div style="background: #f5f5f5; padding: 15px; border-radius: 8px;">
                            <h4 style="color: #2DD2C0; margin-top: 0;">Weighted Precision</h4>
                            <p>$\prod_{n=1}^k p_n^{1/2^n}$</p>
                            <p style="font-size: 0.9em; color: #666;">Higher weight for longer n-gram matches</p>
                        </div>
                    </div>
                </section>

                <!-- BLEU Example -->
                <section>
                    <h2 class="truncate-title">BLEU Calculation Example</h2>
                    <div style="font-size: 0.5em;">
                        <p><strong>Target sequence:</strong> <code>A B C D E F</code></p>
                        <p><strong>Predicted sequence:</strong> <code>A B B C D</code></p>
                    </div>

                    <div style="margin: 25px 0; background: #f5f5f5; padding: 20px; border-radius: 8px; font-size: 0.3em;">
                        <h4 style="color: #10099F; margin-top: 0;">Calculate n-gram Precisions</h4>

                        <div style="margin: 15px 0;">
                            <strong>1-grams (unigrams):</strong><br>
                            Predicted: A, B, B, C, D (5 total)<br>
                            Matched: A, B, C, D (4 matched, one B is duplicate)<br>
                            $p_1 = 4/5 = 0.8$
                        </div>

                        <div style="margin: 15px 0;">
                            <strong>2-grams (bigrams):</strong><br>
                            Predicted: AB, BB, BC, CD (4 total)<br>
                            Matched: AB, BC, CD (3 matched, BB not in target)<br>
                            $p_2 = 3/4 = 0.75$
                        </div>

                        <div style="margin: 15px 0;">
                            <strong>3-grams (trigrams):</strong><br>
                            Predicted: ABB, BBC, BCD (3 total)<br>
                            Matched: BCD (1 matched)<br>
                            $p_3 = 1/3 \approx 0.333$
                        </div>

                        <div style="margin: 15px 0;">
                            <strong>4-grams:</strong><br>
                            Predicted: ABBC, BBCD (2 total)<br>
                            Matched: none (0 matched)<br>
                            $p_4 = 0/2 = 0$
                        </div>
                    </div>

                    <div style="margin: 25px 0; background: #e8f4f8; padding: 15px; border-radius: 8px; font-size: 0.85em;">
                        <strong>Brevity penalty:</strong> $\exp\left(\min(0, 1 - 6/5)\right) = \exp(-0.2) \approx 0.819$<br>
                        <strong>Final BLEU (k=2):</strong> $0.819 \times 0.8^{1/2} \times 0.75^{1/4} \approx 0.71$
                    </div>
                </section>

                <!-- BLEU MCQ -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding: BLEU Metric</h2>
                    <div data-mcq='{
                        "question": "Consider two translations of the same source sentence. Translation A is shorter than the reference but has perfect word overlap. Translation B matches the reference length but has some word mismatches. Which statements are TRUE about their BLEU scores?",
                        "type": "multiple",
                        "options": [
                            {
                                "text": "Translation A will be penalized by the brevity penalty term",
                                "correct": true,
                                "explanation": "Correct! The brevity penalty exp(min(0, 1 - len_label/len_pred)) reduces the score when the prediction is shorter than the reference."
                            },
                            {
                                "text": "Translation B will have perfect BLEU score if it has the same length as reference",
                                "correct": false,
                                "explanation": "Incorrect. Even with matching length, BLEU also depends on n-gram precision. If there are word mismatches, the n-gram precisions will be less than 1."
                            },
                            {
                                "text": "Longer n-gram matches are weighted more heavily than shorter ones",
                                "correct": true,
                                "explanation": "Correct! The exponent 1/2^n means that as n increases, the precision is raised to a smaller power, but the geometric mean structure gives more weight to matching longer n-grams."
                            },
                            {
                                "text": "A BLEU score of 1.0 means the prediction exactly matches the reference",
                                "correct": true,
                                "explanation": "Correct! BLEU = 1.0 only when the prediction matches the reference exactly (same length, all n-grams match), giving perfect precision and no brevity penalty."
                            }
                        ]
                    }'></div>
                </section>

                <!-- BLEU Implementation -->
                <section>
                    <h2 class="truncate-title">BLEU Implementation</h2>
                    <pre><code class="language-python" style="font-size: 0.58em; max-height: 480px;">def bleu(pred_seq, label_seq, k):
    """Compute the BLEU score."""
    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')
    len_pred, len_label = len(pred_tokens), len(label_tokens)

    # Brevity penalty: penalize predictions shorter than reference
    score = math.exp(min(0, 1 - len_label / len_pred))

    # Calculate precision for each n-gram length
    for n in range(1, min(k, len_pred) + 1):
        num_matches, label_subs = 0, collections.defaultdict(int)

        # Count n-grams in label (reference)
        for i in range(len_label - n + 1):
            label_subs[' '.join(label_tokens[i: i + n])] += 1

        # Count matched n-grams in prediction
        for i in range(len_pred - n + 1):
            ngram = ' '.join(pred_tokens[i: i + n])
            if label_subs[ngram] > 0:
                num_matches += 1
                label_subs[ngram] -= 1  # Prevent double counting

        # Update score with n-gram precision
        # Note: p_n^(1/2^n) gives higher weight to longer n-grams
        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))

    return score</code></pre>

                    <p style="margin-top: 20px; font-size: 0.85em;">
                        <strong>Key Detail:</strong> Using <code>defaultdict</code> and decrementing counts prevents the same n-gram from being matched multiple times
                    </p>
                </section>

                <!-- Translation Examples -->
                <section>
                    <h2 class="truncate-title">Translation Examples and BLEU Scores</h2>
                    <p style="font-size: 0.7em;">Results from our trained seq2seq model on English ‚Üí French translation</p>

                    <div style="margin: 25px 0; font-family: 'Source Code Pro', monospace; font-size: 0.4em;">
                        <div style="background: #f5f5f5; padding: 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #10099F;">
                            <strong>Input:</strong> go .<br>
                            <strong style="color: #10099F;">Prediction:</strong> va !<br>
                            <strong style="color: #2DD2C0;">Reference:</strong> va !<br>
                            <strong style="color: #FC8484;">BLEU:</strong> 1.000 ‚úì
                        </div>

                        <div style="background: #f5f5f5; padding: 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #10099F;">
                            <strong>Input:</strong> i lost .<br>
                            <strong style="color: #10099F;">Prediction:</strong> j'ai perdu .<br>
                            <strong style="color: #2DD2C0;">Reference:</strong> j'ai perdu .<br>
                            <strong style="color: #FC8484;">BLEU:</strong> 1.000 ‚úì
                        </div>

                        <div style="background: #f5f5f5; padding: 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #FAC55B;">
                            <strong>Input:</strong> he's calm .<br>
                            <strong style="color: #10099F;">Prediction:</strong> il est mouill√© .<br>
                            <strong style="color: #2DD2C0;">Reference:</strong> il est calme .<br>
                            <strong style="color: #FC8484;">BLEU:</strong> 0.658 (partial match)
                        </div>

                        <div style="background: #f5f5f5; padding: 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #10099F;">
                            <strong>Input:</strong> i'm home .<br>
                            <strong style="color: #10099F;">Prediction:</strong> je suis chez moi .<br>
                            <strong style="color: #2DD2C0;">Reference:</strong> je suis chez moi .<br>
                            <strong style="color: #FC8484;">BLEU:</strong> 1.000 ‚úì
                        </div>
                    </div>

                    <p style="font-size: 0.65em; margin-top: 20px;">
                        <strong>Observations:</strong> Simple sentences achieve perfect translation. More complex sentences may produce semantically different but grammatically correct outputs.
                    </p>
                </section>

                <!-- Summary -->
                <section>
                    <h2 class="truncate-title">Summary: Sequence-to-Sequence Learning</h2>

                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 25px; font-size: 0.55em;">
                        <div>
                            <h4 style="color: #10099F;">Architecture</h4>
                            <ul>
                                <li><strong>Encoder RNN:</strong> Compresses input into fixed context $\mathbf{c}$</li>
                                <li><strong>Decoder RNN:</strong> Generates output conditioned on context</li>
                                <li><strong>Context concatenation:</strong> Provides encoder info at each decoder step</li>
                            </ul>
                        </div>

                        <div>
                            <h4 style="color: #10099F;">Training</h4>
                            <ul>
                                <li><strong>Teacher forcing:</strong> Use ground truth as decoder input</li>
                                <li><strong>Masking:</strong> Exclude padding from loss</li>
                                <li><strong>Gradient clipping:</strong> Prevent exploding gradients</li>
                            </ul>
                        </div>

                        <div>
                            <h4 style="color: #10099F;">Inference</h4>
                            <ul>
                                <li><strong>Autoregressive:</strong> Feed predictions back as input</li>
                                <li><strong>Greedy decoding:</strong> Select highest probability token</li>
                                <li><strong>Stop condition:</strong> Generate until &lt;eos&gt; or max length</li>
                            </ul>
                        </div>

                        <div>
                            <h4 style="color: #10099F;">Evaluation</h4>
                            <ul>
                                <li><strong>BLEU metric:</strong> n-gram precision with brevity penalty</li>
                                <li><strong>Range:</strong> 0 (no match) to 1 (perfect match)</li>
                                <li><strong>Automatic:</strong> No human evaluation needed</li>
                            </ul>
                        </div>
                    </div>

                    <div class="emphasis-box" style="margin-top: 25px; font-size: 0.5em;">
                        <p><strong>Limitations:</strong> Fixed-size context bottleneck, information loss for long sequences ‚Üí Next: Attention mechanisms!</p>
                    </div>
                </section>

                <!-- Final Comprehensive MCQ -->
                <section>
                    <h2 class="truncate-title">Final Assessment: Seq2Seq Comprehensive</h2>
                    <div data-mcq='{
                        "question": "You train a seq2seq model for English‚ÜíGerman translation. During inference, you notice the model often generates very short translations compared to the reference. Which combination of factors could explain this behavior?",
                        "type": "multiple",
                        "options": [
                            {
                                "text": "The BLEU metric heavily penalizes long predictions, so the model learned to generate short sequences",
                                "correct": false,
                                "explanation": "Incorrect! BLEU penalizes SHORT predictions (brevity penalty), not long ones. Also, BLEU is only used for evaluation, not as a training loss."
                            },
                            {
                                "text": "During training with teacher forcing, the model never learned to handle its own potentially incorrect predictions",
                                "correct": true,
                                "explanation": "Correct! This is called exposure bias. The model trained on ground truth inputs but must use its own predictions at inference. Early errors can cascade, causing the model to enter unfamiliar states and potentially stop generation early."
                            },
                            {
                                "text": "The model learned that generating <eos> token yields lower loss than continuing with uncertain predictions",
                                "correct": true,
                                "explanation": "Correct! If the model is uncertain, it might learn that stopping (generating <eos>) is safer than continuing with potentially wrong tokens that would increase loss."
                            },
                            {
                                "text": "The context variable is too small to encode complete input meaning, causing information loss",
                                "correct": true,
                                "explanation": "Correct! A fixed-size context vector may not capture all necessary information, especially for longer inputs. This can cause the decoder to miss important details and generate incomplete translations."
                            }
                        ]
                    }'></div>
                </section>

            </section>

            <!-- Vertical Section: Beam Search -->
            <section>
                <!-- Title Slide for Beam Search -->
                <section data-sources='[{"text": "Dive into Deep Learning - Chapter 10.8: Beam Search", "url": "https://d2l.ai/chapter_recurrent-modern/beam-search.html"}]'>
                    <h2 class="truncate-title">Beam Search: Generating Better Sequences</h2>
                    <div style="font-size: 0.65em;">
                        <div class="fragment">
                            <div class="emphasis-box" style="background: #F5F5FF; border-left: 4px solid #10099F;">
                                <h4 style="color: #10099F; margin-top: 0;">The Core Challenge</h4>
                                <p>We've learned how to train encoder-decoder models end-to-end. But at test time, how do we generate the output sequence?</p>
                            </div>
                        </div>
                        <div class="fragment" style="margin-top: 30px;">
                            <h4 style="color: #10099F;">The Search Space</h4>
                            <p>Goal: Find the most likely output from all possible sequences</p>
                            <div style="background: #F5F5F5; padding: 20px; border-radius: 8px; margin-top: 15px;">
                                <p style="margin: 0; font-size: 0.95em;">If vocabulary size is \(|\mathcal{Y}|\) and max sequence length is \(T'\), there are approximately <strong>\(\mathcal{O}(|\mathcal{Y}|^{T'})\)</strong> possible output sequences</p>
                            </div>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 25px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0;"><strong>Three Strategies:</strong> Greedy search (fast but suboptimal), Exhaustive search (optimal but impossible), and Beam search (the practical compromise)</p>
                        </div>
                    </div>
                </section>

                <!-- Greedy Search -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.8.1", "url": "https://d2l.ai/chapter_recurrent-modern/beam-search.html#greedy-search"}]'>
                    <h2 class="truncate-title">Greedy Search: The Simplest Strategy</h2>
                    <div style="font-size: 0.8em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Algorithm</h4>
                            <p>At each time step \(t'\), select the token with the highest conditional probability:</p>
                            <div style="background: #F5F5F5; padding: 15px; border-radius: 8px; margin: 15px 0;">
                                $$y_{t'} = \operatorname*{argmax}_{y \in \mathcal{Y}} P(y \mid y_1, \ldots, y_{t'-1}, \mathbf{c})$$
                            </div>
                            <p style="font-size: 0.9em;">Stop when we output "<span class="tooltip">&lt;eos&gt;<span class="tooltiptext">End-of-sequence token: A special token that signals the completion of the output sequence</span></span>" or reach maximum length \(T'\)</p>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #FFF5F5; border-left: 4px solid #FC8484;">
                            <h5 style="color: #FC8484; margin-top: 0;">‚ö†Ô∏è The Problem</h5>
                            <p style="margin: 0; font-size: 0.9em;">Greedy search finds the sequence of <em>most likely tokens</em>, NOT the <em>most likely sequence</em>!</p>
                        </div>
                    </div>
                </section>

                <!-- Greedy Search Example -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.8.1", "url": "https://d2l.ai/chapter_recurrent-modern/beam-search.html#greedy-search"}]'>
                    <h2 class="truncate-title">Why Greedy Search Can Fail</h2>
                    <div style="font-size: 0.55em;">
                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 20px;">
                            <div>
                                <h4 style="color: #10099F; font-size: 0.95em;">Greedy Choice: Always Pick Maximum</h4>
                                <img src="../shared/images/s2s-prob1.svg" alt="Greedy search example" style="width: 100%; max-width: 400px;">
                                <div style="background: #FFF5F5; padding: 12px; border-radius: 8px; margin-top: 10px; border: 2px solid #FC8484;">
                                    <p style="margin: 0;"><strong>Sequence:</strong> A ‚Üí B ‚Üí C ‚Üí &lt;eos&gt;</p>
                                    <p style="margin: 5px 0 0 0;"><strong>Probability:</strong> \(0.5 \times 0.4 \times 0.4 \times 0.6 = 0.048\)</p>
                                </div>
                            </div>
                            <div>
                                <h4 style="color: #2DD2C0; font-size: 0.95em;">Better Choice: Pick Second-Best at Step 2</h4>
                                <img src="../shared/images/s2s-prob2.svg" alt="Better sequence example" style="width: 100%; max-width: 400px;">
                                <div style="background: #F0FFF9; padding: 12px; border-radius: 8px; margin-top: 10px; border: 2px solid #2DD2C0;">
                                    <p style="margin: 0;"><strong>Sequence:</strong> A ‚Üí C ‚Üí B ‚Üí &lt;eos&gt;</p>
                                    <p style="margin: 5px 0 0 0;"><strong>Probability:</strong> \(0.5 \times 0.3 \times 0.6 \times 0.6 = 0.054\)</p>
                                </div>
                            </div>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #FFFBF0;">
                            <p style="margin: 0;"><strong>Key Insight:</strong> By choosing the <em>second</em> highest probability at step 2, we get a better overall sequence! The greedy output is suboptimal.</p>
                        </div>
                    </div>
                </section>

                <!-- MCQ: Greedy Search -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "What is the main limitation of greedy search in sequence generation?",
                        "type": "single",
                        "options": [
                            {
                                "text": "It is too computationally expensive",
                                "correct": false,
                                "explanation": "Greedy search is actually very efficient with O(|Y|Tprime) complexity, making it one of the fastest methods."
                            },
                            {
                                "text": "It maximizes the probability of individual tokens rather than the entire sequence",
                                "correct": true,
                                "explanation": "Correct! Greedy search selects the most likely token at each step, but this does not guarantee the most likely overall sequence."
                            },
                            {
                                "text": "It cannot handle variable-length sequences",
                                "correct": false,
                                "explanation": "Greedy search works fine with variable-length sequences by stopping when it generates the end-of-sequence token."
                            },
                            {
                                "text": "It requires knowing the output length in advance",
                                "correct": false,
                                "explanation": "Greedy search generates tokens until it outputs the end-of-sequence token or reaches a maximum length."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Exhaustive Search -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.8.2", "url": "https://d2l.ai/chapter_recurrent-modern/beam-search.html#exhaustive-search"}]'>
                    <h2 class="truncate-title">Exhaustive Search: The Optimal but Impractical Solution</h2>
                    <div style="font-size: 0.6em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Ideal Approach</h4>
                            <p>Enumerate <strong>all</strong> possible output sequences, compute their probabilities, and select the one with the highest probability.</p>
                            <div style="background: #F0FFF9; padding: 15px; border-radius: 8px; margin: 15px 0; border-left: 4px solid #2DD2C0;">
                                <p style="margin: 0;"><strong>Goal:</strong> Find the sequence that maximizes</p>
                                <p style="margin: 10px 0 0 0; text-align: center;">$$\prod_{t'=1}^{T'} P(y_{t'} \mid y_1, \ldots, y_{t'-1}, \mathbf{c})$$</p>
                            </div>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #FFF5F5; border-left: 4px solid #FC8484;">
                            <h5 style="color: #FC8484; margin-top: 0;">üö´ The Problem: Computational Explosion</h5>
                            <p><strong>Complexity:</strong> \(\mathcal{O}(|\mathcal{Y}|^{T'})\)</p>
                            <div style="background: white; padding: 15px; border-radius: 8px; margin-top: 12px;">
                                <p style="margin: 0; font-size: 0.95em;"><strong>Example:</strong> With vocabulary size \(|\mathcal{Y}| = 10{,}000\) and sequence length \(T' = 10\):</p>
                                <p style="margin: 8px 0 0 0; text-align: center; font-size: 1.1em; color: #FC8484;">$$10{,}000^{10} = 10^{40} \text{ sequences}$$</p>
                                <p style="margin: 8px 0 0 0; font-size: 0.9em;">This is beyond the capability of any foreseeable computer!</p>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Computational Comparison -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.8.2", "url": "https://d2l.ai/chapter_recurrent-modern/beam-search.html#exhaustive-search"}]'>
                    <h2 class="truncate-title">Greedy vs. Exhaustive: A Massive Gap</h2>
                    <div style="font-size: 0.6em;">
                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 25px; margin-top: 30px;">
                            <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0;">
                                <h4 style="color: #2DD2C0; margin-top: 0;">‚úì Greedy Search</h4>
                                <p><strong>Complexity:</strong> \(\mathcal{O}(|\mathcal{Y}|T')\)</p>
                                <div style="background: white; padding: 12px; border-radius: 8px; margin-top: 12px;">
                                    <p style="margin: 0; font-size: 0.9em;"><strong>Example:</strong> \(|\mathcal{Y}| = 10{,}000\), \(T' = 10\)</p>
                                    <p style="margin: 8px 0 0 0; text-align: center; font-size: 1.2em; color: #2DD2C0;">$$10{,}000 \times 10 = 10^5$$</p>
                                </div>
                                <p style="margin-top: 12px; font-size: 0.9em;"><strong>Status:</strong> Miraculously cheap! üöÄ</p>
                            </div>
                            <div class="emphasis-box" style="background: #FFF5F5; border-left: 4px solid #FC8484;">
                                <h4 style="color: #FC8484; margin-top: 0;">‚úó Exhaustive Search</h4>
                                <p><strong>Complexity:</strong> \(\mathcal{O}(|\mathcal{Y}|^{T'})\)</p>
                                <div style="background: white; padding: 12px; border-radius: 8px; margin-top: 12px;">
                                    <p style="margin: 0; font-size: 0.9em;"><strong>Example:</strong> \(|\mathcal{Y}| = 10{,}000\), \(T' = 10\)</p>
                                    <p style="margin: 8px 0 0 0; text-align: center; font-size: 1.2em; color: #FC8484;">$$10{,}000^{10} = 10^{40}$$</p>
                                </div>
                                <p style="margin-top: 12px; font-size: 0.9em;"><strong>Status:</strong> Computationally infeasible! üí•</p>
                            </div>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 25px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0;"><strong>We need something in between:</strong> More accurate than greedy, but computationally feasible. Enter <strong style="color: #10099F;">beam search</strong>!</p>
                        </div>
                    </div>
                </section>

                <!-- Beam Search Introduction -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.8.3", "url": "https://d2l.ai/chapter_recurrent-modern/beam-search.html#beam-search"}]'>
                    <h2 class="truncate-title">Beam Search: The Practical Compromise</h2>
                    <div style="font-size: 0.6em;">
                        <div class="fragment">
                            <div class="emphasis-box" style="background: #F5F5FF; border-left: 4px solid #10099F;">
                                <h4 style="color: #10099F; margin-top: 0;">The Core Idea</h4>
                                <p>Maintain \(k\) candidate sequences at each time step, where \(k\) is the <span class="tooltip">beam size<span class="tooltiptext">A hyperparameter that controls the number of candidate sequences maintained during search. Larger beam sizes explore more possibilities but increase computational cost.</span></span>.</p>
                            </div>
                        </div>
                        <div class="fragment" style="margin-top: 25px;">
                            <h4 style="color: #10099F;">The Algorithm</h4>
                            <ol style="font-size: 0.95em; line-height: 1.6;">
                                <li><strong>Step 1:</strong> Select the \(k\) tokens with highest probabilities as the first token of \(k\) candidate sequences</li>
                                <li><strong>Step t':</strong> Based on the \(k\) candidates from step \(t'-1\), expand each with all vocabulary tokens (creating \(k|\mathcal{Y}|\) possibilities)</li>
                                <li><strong>Keep top k:</strong> Select the \(k\) candidates with highest probabilities from all \(k|\mathcal{Y}|\) possibilities</li>
                                <li><strong>Repeat:</strong> Continue until all candidates end with "&lt;eos&gt;" or reach max length</li>
                            </ol>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #F0FFF9;">
                            <p style="margin: 0;"><strong>Special Case:</strong> When \(k=1\), beam search reduces to greedy search!</p>
                        </div>
                    </div>
                </section>

                <!-- Beam Search Visualization -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.8.3", "url": "https://d2l.ai/chapter_recurrent-modern/beam-search.html#beam-search"}]'>
                    <h2 class="truncate-title">Beam Search in Action</h2>
                    <div style="font-size: 0.75em;">
                        <p style="font-size: 0.8em;"><strong>Example:</strong> Vocabulary \(\mathcal{Y} = \{A, B, C, D, E\}\), beam size \(k=2\), max length \(T'=3\)</p>
                        <img src="../shared/images/beam-search.svg" alt="Beam search visualization" style="width: 50%; max-width: 800px; margin: 20px auto; display: block;">
                        <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 15px; margin-top: 20px; font-size: 0.5em;">
                            <div class="emphasis-box" style="background: #F5F5FF;">
                                <h5 style="color: #10099F; margin-top: 0;">Time Step 1</h5>
                                <p style="margin: 0;">Select top 2 tokens: <strong>A</strong> and <strong>C</strong></p>
                                <p style="margin: 5px 0 0 0; font-size: 0.85em;">Based on \(P(y_1 \mid \mathbf{c})\)</p>
                            </div>
                            <div class="emphasis-box" style="background: #F0FFF9;">
                                <h5 style="color: #2DD2C0; margin-top: 0;">Time Step 2</h5>
                                <p style="margin: 0;">Expand 2 candidates ‚Üí 10 possibilities</p>
                                <p style="margin: 5px 0 0 0;">Keep top 2: <strong>AB</strong> and <strong>CE</strong></p>
                            </div>
                            <div class="emphasis-box" style="background: #FFFBF0;">
                                <h5 style="color: #FAC55B; margin-top: 0;">Time Step 3</h5>
                                <p style="margin: 0;">Expand 2 candidates ‚Üí 10 possibilities</p>
                                <p style="margin: 5px 0 0 0;">Keep top 2: <strong>ABD</strong> and <strong>CED</strong></p>
                            </div>
                        </div>
                        <div class="emphasis-box" style="margin-top: 20px; background: #F5F5F5; font-size: 0.5em;">
                            <p style="margin: 0;"><strong>Final candidates:</strong> A, C, AB, CE, ABD, CED (sequences ending at different steps)</p>
                        </div>
                    </div>
                </section>

                <!-- Beam Search Equations -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.8.3", "url": "https://d2l.ai/chapter_recurrent-modern/beam-search.html#beam-search"}]'>
                    <h2 class="truncate-title">Beam Search: The Mathematics</h2>
                    <div style="font-size: 0.5em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">At Each Time Step</h4>
                            <p><strong>Time step 2:</strong> For each of the \(k\) candidates from step 1, compute joint probabilities:</p>
                            <div style="background: #F5F5FF; padding: 15px; border-radius: 8px; margin: 12px 0;">
                                $$\begin{aligned}
                                P(A, y_2 \mid \mathbf{c}) &= P(A \mid \mathbf{c})P(y_2 \mid A, \mathbf{c})\\
                                P(C, y_2 \mid \mathbf{c}) &= P(C \mid \mathbf{c})P(y_2 \mid C, \mathbf{c})
                                \end{aligned}$$
                            </div>
                            <p style="font-size: 0.9em;">Pick the largest 2 among these \(2 \times 5 = 10\) values</p>
                        </div>
                        <div class="fragment" style="margin-top: 20px;">
                            <p><strong>Time step 3:</strong> Continue the process:</p>
                            <div style="background: #F0FFF9; padding: 15px; border-radius: 8px; margin: 12px 0;">
                                $$\begin{aligned}
                                P(A, B, y_3 \mid \mathbf{c}) &= P(A, B \mid \mathbf{c})P(y_3 \mid A, B, \mathbf{c})\\
                                P(C, E, y_3 \mid \mathbf{c}) &= P(C, E \mid \mathbf{c})P(y_3 \mid C, E, \mathbf{c})
                                \end{aligned}$$
                            </div>
                            <p style="font-size: 0.9em;">Again, pick the largest 2 among these 10 values</p>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 20px; background: #FFFBF0;">
                            <p style="margin: 0;"><strong>Pattern:</strong> At each step, we evaluate \(k|\mathcal{Y}|\) candidates and keep the top \(k\)</p>
                        </div>
                    </div>
                </section>

                <!-- MCQ: Beam Search -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "In beam search with beam size k=3 and vocabulary size |Y|=5000, how many candidate sequences are evaluated at each time step?",
                        "type": "single",
                        "options": [
                            {
                                "text": "3",
                                "correct": false,
                                "explanation": "This is only the number of sequences we keep, not the number we evaluate. We need to expand each of these."
                            },
                            {
                                "text": "5000",
                                "correct": false,
                                "explanation": "This is the vocabulary size, but we evaluate more candidates because we expand each of the k sequences."
                            },
                            {
                                "text": "15,000",
                                "correct": true,
                                "explanation": "Correct! We have k=3 sequences from the previous step, and we expand each with all |Y|=5000 vocabulary tokens, giving us k√ó|Y| = 3√ó5000 = 15,000 candidates to evaluate."
                            },
                            {
                                "text": "15,000,000",
                                "correct": false,
                                "explanation": "This would be k√ó|Y|¬≤, which is incorrect. We evaluate k√ó|Y| candidates at each step."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Beam Search Scoring -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.8.3", "url": "https://d2l.ai/chapter_recurrent-modern/beam-search.html#beam-search"}]'>
                    <h2 class="truncate-title">Scoring and Selecting the Final Output</h2>
                    <div style="font-size: 0.5em;">
                        <div class="fragment">
                            <h4 style="color: #10099F;">The Problem with Direct Probabilities</h4>
                            <p>Longer sequences have more probability terms multiplied together, naturally resulting in smaller probabilities. This biases the search toward shorter sequences!</p>
                        </div>
                        <div class="fragment" style="margin-top: 20px;">
                            <h4 style="color: #10099F;">The Solution: Length-Normalized Scoring</h4>
                            <div style="background: #F5F5FF; padding: 20px; border-radius: 8px; margin: 15px 0; border: 2px solid #10099F;">
                                <p style="margin: 0 0 12px 0; text-align: center;"><strong>Beam Search Score:</strong></p>
                                $$\frac{1}{L^\alpha} \log P(y_1, \ldots, y_{L}\mid \mathbf{c}) = \frac{1}{L^\alpha} \sum_{t'=1}^L \log P(y_{t'} \mid y_1, \ldots, y_{t'-1}, \mathbf{c})$$
                                <div style="margin-top: 15px; font-size: 0.95em;">
                                    <p style="margin: 5px 0;"><span style="color: #10099F;">‚ñ†</span> \(L\) = length of the candidate sequence</p>
                                    <p style="margin: 5px 0;"><span style="color: #2DD2C0;">‚ñ†</span> \(\alpha\) = length penalty parameter (typically 0.75)</p>
                                    <p style="margin: 5px 0;"><span style="color: #FAC55B;">‚ñ†</span> \(\log\) converts products to sums (numerical stability)</p>
                                </div>
                            </div>
                        </div>
                        <div class="fragment emphasis-box" style="background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <p style="margin: 0;"><strong>Why \(L^\alpha\)?</strong> The denominator <span class="tooltip">penalizes long sequences<span class="tooltiptext">Without length normalization, longer sequences would have unfairly lower probabilities due to multiplying more terms. The penalty balances this bias.</span></span>, preventing bias toward shorter outputs</p>
                        </div>
                    </div>
                </section>

                <!-- Computational Cost -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.8.3", "url": "https://d2l.ai/chapter_recurrent-modern/beam-search.html#beam-search"}]'>
                    <h2 class="truncate-title">Computational Cost: The Full Picture</h2>
                    <div style="font-size: 0.65em;">
                        <div style="margin-top: 20px;">
                            <table style="width: 100%; border-collapse: collapse; font-size: 0.9em;">
                                <thead>
                                    <tr style="background: #10099F; color: white;">
                                        <th style="padding: 12px; border: 1px solid #EEEEEE;">Method</th>
                                        <th style="padding: 12px; border: 1px solid #EEEEEE;">Complexity</th>
                                        <th style="padding: 12px; border: 1px solid #EEEEEE;">Example (\(|\mathcal{Y}|=10^4\), \(T'=10\))</th>
                                        <th style="padding: 12px; border: 1px solid #EEEEEE;">Quality</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr style="background: #F0FFF9;">
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;"><strong>Greedy</strong></td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">\(\mathcal{O}(|\mathcal{Y}|T')\)</td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">\(10^5\)</td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">Suboptimal ‚ö†Ô∏è</td>
                                    </tr>
                                    <tr style="background: #FFFBF0;">
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;"><strong>Beam (\(k=5\))</strong></td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">\(\mathcal{O}(k|\mathcal{Y}|T')\)</td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">\(5 \times 10^5\)</td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">Good ‚úì</td>
                                    </tr>
                                    <tr style="background: #F5F5FF;">
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;"><strong>Beam (\(k=10\))</strong></td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">\(\mathcal{O}(k|\mathcal{Y}|T')\)</td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">\(10^6\)</td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">Better ‚úì‚úì</td>
                                    </tr>
                                    <tr style="background: #FFF5F5;">
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;"><strong>Exhaustive</strong></td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">\(\mathcal{O}(|\mathcal{Y}|^{T'})\)</td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">\(10^{40}\)</td>
                                        <td style="padding: 12px; border: 1px solid #EEEEEE;">Optimal (but impossible) ‚úó</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 25px; background: #F5F5FF; border-left: 4px solid #10099F;">
                            <p style="margin: 0;"><strong>Key Insight:</strong> Beam search provides a flexible trade-off through the beam size \(k\). Larger \(k\) ‚Üí better quality but higher cost</p>
                        </div>
                        <div class="fragment emphasis-box" style="margin-top: 15px; background: #F0FFF9;">
                            <p style="margin: 0;"><strong>In Practice:</strong> Typical beam sizes range from \(k=5\) to \(k=50\), depending on the application and computational budget</p>
                        </div>
                    </div>
                </section>

                <!-- MCQ: Computational Cost -->
                <section>
                    <h2 class="truncate-title">Test Your Understanding</h2>
                    <div data-mcq='{
                        "question": "Which statement about beam search is correct?",
                        "type": "single",
                        "options": [
                            {
                                "text": "Beam search always finds the globally optimal sequence",
                                "correct": false,
                                "explanation": "Beam search is a heuristic that does not guarantee finding the globally optimal sequence. Only exhaustive search guarantees optimality."
                            },
                            {
                                "text": "Increasing the beam size k always improves the quality of the output",
                                "correct": false,
                                "explanation": "While larger k tends to improve quality, it does not always do so. The model might have learned patterns that do not align perfectly with the true optimal sequence."
                            },
                            {
                                "text": "Beam search with k=1 is equivalent to greedy search",
                                "correct": true,
                                "explanation": "Correct! When the beam size is 1, we only keep one candidate at each step, selecting the highest probability token‚Äîexactly what greedy search does."
                            },
                            {
                                "text": "The length penalty parameter Œ± should always be set to 1.0",
                                "correct": false,
                                "explanation": "The typical value for Œ± is 0.75, not 1.0. The optimal value depends on the specific task and dataset."
                            }
                        ]
                    }'></div>
                </section>

                <!-- Summary -->
                <section data-sources='[{"text": "Dive into Deep Learning - Section 10.8.4", "url": "https://d2l.ai/chapter_recurrent-modern/beam-search.html#summary"}]'>
                    <h2 class="truncate-title">Summary: Sequence Search Strategies</h2>
                    <div style="font-size: 0.5em;">
                        <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px; margin-top: 25px;">
                            <div class="emphasis-box" style="background: #F0FFF9; border-left: 4px solid #2DD2C0; min-height: 200px;">
                                <h4 style="color: #2DD2C0; margin-top: 0;">Greedy Search</h4>
                                <p style="font-size: 0.9em;"><strong>Strategy:</strong> Pick max at each step</p>
                                <p style="font-size: 0.9em;"><strong>Cost:</strong> \(\mathcal{O}(|\mathcal{Y}|T')\)</p>
                                <p style="font-size: 0.9em;"><strong>Quality:</strong> Suboptimal</p>
                                <p style="font-size: 0.85em; margin-top: 10px;">‚úì Fast and simple<br>‚úó Can miss better sequences</p>
                            </div>
                            <div class="emphasis-box" style="background: #F5F5FF; border-left: 4px solid #10099F; min-height: 200px;">
                                <h4 style="color: #10099F; margin-top: 0;">Beam Search</h4>
                                <p style="font-size: 0.9em;"><strong>Strategy:</strong> Maintain \(k\) candidates</p>
                                <p style="font-size: 0.9em;"><strong>Cost:</strong> \(\mathcal{O}(k|\mathcal{Y}|T')\)</p>
                                <p style="font-size: 0.9em;"><strong>Quality:</strong> Good compromise</p>
                                <p style="font-size: 0.85em; margin-top: 10px;">‚úì Flexible trade-off via \(k\)<br>‚úì Practical and effective<br>‚úì Used in production</p>
                            </div>
                            <div class="emphasis-box" style="background: #FFF5F5; border-left: 4px solid #FC8484; min-height: 200px;">
                                <h4 style="color: #FC8484; margin-top: 0;">Exhaustive Search</h4>
                                <p style="font-size: 0.9em;"><strong>Strategy:</strong> Try all sequences</p>
                                <p style="font-size: 0.9em;"><strong>Cost:</strong> \(\mathcal{O}(|\mathcal{Y}|^{T'})\)</p>
                                <p style="font-size: 0.9em;"><strong>Quality:</strong> Optimal</p>
                                <p style="font-size: 0.85em; margin-top: 10px;">‚úì Finds best sequence<br>‚úó Computationally infeasible</p>
                            </div>
                        </div>
                        <div class="emphasis-box" style="margin-top: 30px; background: #FFFBF0; border-left: 4px solid #FAC55B;">
                            <h4 style="color: #FAC55B; margin-top: 0;">üí° Key Takeaways</h4>
                            <ul style="margin: 10px 0 0 20px; line-height: 1.7;">
                                <li>Beam search is the <strong>standard method in practice</strong> for sequence generation</li>
                                <li>The beam size \(k\) provides a <strong>flexible trade-off</strong> between accuracy and computational cost</li>
                                <li><strong>Length normalization</strong> is essential to avoid bias toward shorter sequences</li>
                                <li>Typical beam sizes: \(k=5\) to \(k=50\) depending on application</li>
                            </ul>
                        </div>
                    </div>
                </section>

            </section>

        </div>
    </div>

    <!-- Reveal.js and plugins -->
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/reveal.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/notes/notes.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/highlight/highlight.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/math/math.js"></script>

    <!-- Shared utilities -->
    <script src="../shared/js/title-handler.js"></script>
    <script src="../shared/js/tooltip-modal.js"></script>
    <script src="../shared/js/source-modal-v2.js"></script>
    <script src="../shared/js/multiple-choice.js"></script>

    <script>
        Reveal.initialize({
            hash: true,
            controls: true,
            progress: true,
            center: true,
            transition: 'slide',
            math: {
                mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js',
                config: 'TeX-AMS_SVG-full'
            },
            plugins: [ RevealMath, RevealHighlight, RevealNotes ]
        });
    </script>

    <!-- D3.js for Interactive Visualization -->
    <script src="https://d3js.org/d3.v7.min.js"></script>

    <!-- Interactive LSTM Visualization -->
    <script>
        Reveal.on('slidechanged', function(event) {
            // Check if we're on the interactive LSTM slide
            const vizContainer = document.getElementById('lstm-interactive-viz');
            if (vizContainer && event.currentSlide.contains(vizContainer)) {
                createInteractiveLSTM();
            }
        });

        // Helper function to format formulas with proper HTML subscripts and superscripts
        function formatFormula(formula) {
            return formula
                // Handle tilde C with subscript FIRST (before general subscript patterns)
                .replace(/CÃÉ_\{([^}]+)\}/g, 'C&#771;<sub>$1</sub>')
                .replace(/CÃÉ_([a-z0-9t-]+)/g, 'C&#771;<sub>$1</sub>')
                // Handle complex subscripts like W_{xf}
                .replace(/([A-Z])_\{([^}]+)\}/g, '$1<sub>$2</sub>')
                // Handle simple subscripts like F_t, C_t
                .replace(/([A-Za-z])_([a-z0-9t-]+)/g, '$1<sub>$2</sub>')
                // Handle superscripts like ^{n√óh}
                .replace(/\^\{([^}]+)\}/g, '<sup>$1</sup>')
                // Handle tilde C without subscript (fallback)
                .replace(/CÃÉ/g, 'C&#771;')
                .replace(/~C/g, 'C&#771;');
        }

        function createInteractiveLSTM() {
            const container = d3.select('#lstm-interactive-viz');
            container.selectAll('*').remove(); // Clear previous content

            const width = 900;
            const height = 500;
            const svg = container.append('svg')
                .attr('width', '100%')
                .attr('height', '100%')
                .attr('viewBox', `0 0 ${width} ${height}`)
                .attr('preserveAspectRatio', 'xMidYMid meet');

            // Define colors
            const colors = {
                input: '#FC8484',
                forget: '#FFA05F',
                output: '#2DD2C0',
                candidate: '#FAC55B',
                memory: '#10099F',
                state: '#EEEEEE'
            };

            // Define tooltip
            const tooltip = container.append('div')
                .style('position', 'absolute')
                .style('background', 'rgba(255, 255, 255, 0.98)')
                .style('border', '2px solid #10099F')
                .style('border-radius', '8px')
                .style('padding', '15px')
                .style('display', 'none')
                .style('pointer-events', 'none')
                .style('font-size', '14px')
                .style('max-width', '400px')
                .style('box-shadow', '0 4px 12px rgba(0,0,0,0.15)')
                .style('z-index', '1000');

            // Add section labels
            svg.append('text')
                .attr('x', 120).attr('y', 25)
                .attr('text-anchor', 'middle')
                .attr('font-size', '12px')
                .attr('fill', '#666')
                .attr('font-weight', 'bold')
                .text('INPUTS');

            svg.append('text')
                .attr('x', 400).attr('y', 25)
                .attr('text-anchor', 'middle')
                .attr('font-size', '12px')
                .attr('fill', '#666')
                .attr('font-weight', 'bold')
                .text('GATES & OPERATIONS');

            svg.append('text')
                .attr('x', 780).attr('y', 25)
                .attr('text-anchor', 'middle')
                .attr('font-size', '12px')
                .attr('fill', '#666')
                .attr('font-weight', 'bold')
                .text('OUTPUTS');

            // SIMPLIFIED Node structure - operations removed
            const nodes = {
                // LEFT: Previous state
                c_prev: { x: 100, y: 80, label: 'C', subscript: 't-1', type: 'memory' },
                h_prev: { x: 100, y: 200, label: 'H', subscript: 't-1', type: 'state' },

                // LEFT: Current input
                x_t: { x: 100, y: 350, label: 'X', subscript: 't', type: 'input' },

                // MIDDLE: Gates and intermediate values
                forget_gate: { x: 380, y: 120, label: 'F', subscript: 't', symbol: '(œÉ)', type: 'forget' },
                input_gate: { x: 480, y: 170, label: 'I', subscript: 't', symbol: '(œÉ)', type: 'input' },
                candidate: { x: 480, y: 320, label: 'CÃÉ', subscript: 't', symbol: '(tanh)', type: 'candidate' },
                output_gate: { x: 680, y: 230, label: 'O', subscript: 't', symbol: '(œÉ)', type: 'output' },

                // RIGHT: Outputs
                c_t: { x: 800, y: 80, label: 'C', subscript: 't', type: 'memory' },
                h_t: { x: 800, y: 200, label: 'H', subscript: 't', type: 'state' }
            };

            // Draw memory cell flow (horizontal line) - THICKER
            svg.append('line')
                .attr('x1', 150).attr('y1', 80)
                .attr('x2', 750).attr('y2', 80)
                .attr('stroke', colors.memory)
                .attr('stroke-width', 5)
                .attr('opacity', 0.4);

            // Add "Memory Cell State" label
            svg.append('text')
                .attr('x', 450).attr('y', 60)
                .attr('text-anchor', 'middle')
                .attr('font-size', '11px')
                .attr('fill', colors.memory)
                .attr('font-weight', 'bold')
                .text('Memory Cell State Flow');

            // SIMPLIFIED connections - no operation nodes
            const connections = [
                // X_t and H_{t-1} feed into all gates
                { from: 'x_t', to: 'forget_gate' },
                { from: 'h_prev', to: 'forget_gate' },
                { from: 'x_t', to: 'input_gate' },
                { from: 'h_prev', to: 'input_gate' },
                { from: 'x_t', to: 'candidate' },
                { from: 'h_prev', to: 'candidate' },
                { from: 'x_t', to: 'output_gate' },
                { from: 'h_prev', to: 'output_gate' },

                // Memory cell state flow (shown by thick line, formula in C_t tooltip)
                { from: 'c_prev', to: 'c_t', type: 'memory' },

                // Gates influence memory (shown by formula in C_t tooltip)
                { from: 'forget_gate', to: 'c_t', type: 'gate', dashed: true },
                { from: 'input_gate', to: 'c_t', type: 'gate', dashed: true },
                { from: 'candidate', to: 'c_t', type: 'gate', dashed: true },

                // Output computation
                { from: 'c_t', to: 'h_t', type: 'state' },
                { from: 'output_gate', to: 'h_t', type: 'gate', dashed: true }
            ];

            // Define arrow markers BEFORE drawing connections
            const defs = svg.append('defs');

            // Memory flow arrow (purple)
            defs.append('marker')
                .attr('id', 'arrowhead-memory')
                .attr('markerWidth', 12)
                .attr('markerHeight', 12)
                .attr('refX', 10)
                .attr('refY', 6)
                .attr('orient', 'auto')
                .append('polygon')
                .attr('points', '0,2 10,6 0,10')
                .attr('fill', colors.memory);

            // Gate arrow (gray)
            defs.append('marker')
                .attr('id', 'arrowhead-gate')
                .attr('markerWidth', 10)
                .attr('markerHeight', 10)
                .attr('refX', 8)
                .attr('refY', 5)
                .attr('orient', 'auto')
                .append('polygon')
                .attr('points', '0,1 8,5 0,9')
                .attr('fill', '#666666');

            // State arrow (darker gray)
            defs.append('marker')
                .attr('id', 'arrowhead-state')
                .attr('markerWidth', 11)
                .attr('markerHeight', 11)
                .attr('refX', 9)
                .attr('refY', 5.5)
                .attr('orient', 'auto')
                .append('polygon')
                .attr('points', '0,1.5 9,5.5 0,9.5')
                .attr('fill', '#444444');

            // Default arrow
            defs.append('marker')
                .attr('id', 'arrowhead-default')
                .attr('markerWidth', 10)
                .attr('markerHeight', 10)
                .attr('refX', 8)
                .attr('refY', 5)
                .attr('orient', 'auto')
                .append('polygon')
                .attr('points', '0,1 8,5 0,9')
                .attr('fill', '#888888');

            connections.forEach(conn => {
                const from = nodes[conn.from];
                const to = nodes[conn.to];

                // Determine line style and color based on type
                let strokeColor = '#AAAAAA';
                let strokeWidth = 2;
                let dashArray = 'none';
                let markerEnd = 'url(#arrowhead-default)';

                if (conn.type === 'memory') {
                    strokeColor = colors.memory;
                    strokeWidth = 4;
                    markerEnd = 'url(#arrowhead-memory)';
                } else if (conn.type === 'gate') {
                    strokeColor = '#888888';
                    strokeWidth = 2;
                    markerEnd = 'url(#arrowhead-gate)';
                    if (conn.dashed) dashArray = '5,5';
                } else if (conn.type === 'state') {
                    strokeColor = '#666666';
                    strokeWidth = 3;
                    markerEnd = 'url(#arrowhead-state)';
                }

                // Calculate adjusted endpoint to stop before node circle (radius = 40)
                const dx = to.x - from.x;
                const dy = to.y - from.y;
                const distance = Math.sqrt(dx * dx + dy * dy);
                const nodeRadius = 40;
                const adjustedDistance = distance - nodeRadius - 5; // Stop 5px before node edge
                const ratio = adjustedDistance / distance;

                const x2Adjusted = from.x + dx * ratio;
                const y2Adjusted = from.y + dy * ratio;

                svg.append('line')
                    .attr('x1', from.x)
                    .attr('y1', from.y)
                    .attr('x2', x2Adjusted)
                    .attr('y2', y2Adjusted)
                    .attr('stroke', strokeColor)
                    .attr('stroke-width', strokeWidth)
                    .attr('stroke-dasharray', dashArray)
                    .attr('opacity', 0.6)
                    .attr('marker-end', markerEnd);
            });

            // Hover information with HTML-formatted math
            const hoverInfo = {
                x_t: {
                    title: formatFormula('Input X_t'),
                    formula: 'Current input at time step t',
                    dims: formatFormula('Dimensions: ‚Ñù^{n√ód}'),
                    description: 'Batch of n samples with d input features'
                },
                h_prev: {
                    title: formatFormula('Previous Hidden State H_{t-1}'),
                    formula: 'Hidden state from previous time step',
                    dims: formatFormula('Dimensions: ‚Ñù^{n√óh}'),
                    description: 'Contains h hidden units per sample'
                },
                c_prev: {
                    title: formatFormula('Previous Memory Cell C_{t-1}'),
                    formula: 'Memory cell state from previous time step',
                    dims: formatFormula('Dimensions: ‚Ñù^{n√óh}'),
                    description: 'Internal memory maintained across time'
                },
                forget_gate: {
                    title: formatFormula('Forget Gate F_t'),
                    formula: formatFormula('F_t = œÉ(X_t W_{xf} + H_{t-1} W_{hf} + b_f)'),
                    dims: 'Output: (0, 1) via sigmoid',
                    description: 'Controls what information to discard from memory. Values close to 0 mean forget, close to 1 means keep.',
                    intuition: '<strong>Why needed?</strong> Think of this like a <em>smart notebook</em> that automatically crosses out old notes when they\'re no longer relevant. <br><br><strong>Real example:</strong> When reading "The cat was hungry. The dog ran fast," after seeing "dog," you want to forget that you were tracking "cat" as the subject. Without this ability to forget, your memory would fill up with every detail you\'ve ever seen, making it impossible to focus on what matters now.',
                    params: formatFormula('Parameters: W_{xf} ‚àà ‚Ñù^{d√óh}, W_{hf} ‚àà ‚Ñù^{h√óh}, b_f ‚àà ‚Ñù^{1√óh}')
                },
                input_gate: {
                    title: formatFormula('Input Gate I_t'),
                    formula: formatFormula('I_t = œÉ(X_t W_{xi} + H_{t-1} W_{hi} + b_i)'),
                    dims: 'Output: (0, 1) via sigmoid',
                    description: 'Controls what new information to add to memory. Values close to 1 means use the new candidate information.',
                    intuition: '<strong>Why needed?</strong> This acts like an <em>information filter</em> or spam detector for your memory. Not everything you see deserves to be remembered! <br><br><strong>Real example:</strong> In the sentence "The fluffy little adorable cat meowed," the words "fluffy," "little," and "adorable" might be ignored (filtered out), while "cat" and "meowed" are stored. This prevents cluttering memory with less important details.',
                    params: formatFormula('Parameters: W_{xi} ‚àà ‚Ñù^{d√óh}, W_{hi} ‚àà ‚Ñù^{h√óh}, b_i ‚àà ‚Ñù^{1√óh}')
                },
                candidate: {
                    title: formatFormula('Candidate Memory Cell CÃÉ_t'),
                    formula: formatFormula('CÃÉ_t = tanh(X_t W_{xc} + H_{t-1} W_{hc} + b_c)'),
                    dims: 'Output: (-1, 1) via tanh',
                    description: 'New candidate values that could be added to memory. The input gate decides how much to use.',
                    intuition: '<strong>Why needed?</strong> Like a <em>suggestion box</em> - proposes information to remember, but doesn\'t decide whether to store it (that\'s the input gate\'s job). <br><br><strong>Example:</strong> Seeing "delicious chocolate cake" generates a candidate about it being delicious, but the input gate decides if it\'s important (yes for party planning, no for random reading). Separating "what could be remembered" from "should we remember it" provides flexibility.',
                    params: formatFormula('Parameters: W_{xc} ‚àà ‚Ñù^{d√óh}, W_{hc} ‚àà ‚Ñù^{h√óh}, b_c ‚àà ‚Ñù^{1√óh}')
                },
                output_gate: {
                    title: formatFormula('Output Gate O_t'),
                    formula: formatFormula('O_t = œÉ(X_t W_{xo} + H_{t-1} W_{ho} + b_o)'),
                    dims: 'Output: (0, 1) via sigmoid',
                    description: 'Controls what information from memory cell is exposed in the hidden state output.',
                    intuition: '<strong>Why needed?</strong> Like a <em>privacy filter</em> - you know more than you say! Memory stores many details, but you only share what\'s relevant. <br><br><strong>Example:</strong> Memory contains "Meeting at 3pm in room 401 with Sarah and John about budget planning," but after "The meeting is," you only output time info ("3pm"). Keeps comprehensive internal knowledge while exposing just what\'s needed.',
                    params: formatFormula('Parameters: W_{xo} ‚àà ‚Ñù^{d√óh}, W_{ho} ‚àà ‚Ñù^{h√óh}, b_o ‚àà ‚Ñù^{1√óh}')
                },
                c_t: {
                    title: formatFormula('Memory Cell State C_t'),
                    formula: formatFormula('C_t = F_t ‚äô C_{t-1} + I_t ‚äô CÃÉ_t'),
                    dims: formatFormula('Dimensions: ‚Ñù^{n√óh}'),
                    description: 'Updated internal memory state. Flows forward to next time step but is NOT passed to output layer.',
                    intuition: '<strong>Why needed?</strong> This is like a <em>conveyor belt</em> in a factory - information flows smoothly forward with items being added or removed, but the belt itself keeps moving steadily. <br><br><strong>Key insight:</strong> Regular RNNs struggle with "information fading" - by the time you read the 100th word, you\'ve forgotten the 1st word. The memory cell fixes this by using <em>addition</em> (C<sub>t-1</sub> + new stuff) instead of <em>multiplication</em>. Adding things preserves information better than multiplying over many steps, allowing the network to remember dependencies from hundreds of steps ago.',
                },
                h_t: {
                    title: formatFormula('Hidden State H_t'),
                    formula: formatFormula('H_t = O_t ‚äô tanh(C_t)'),
                    dims: formatFormula('Dimensions: ‚Ñù^{n√óh}'),
                    description: 'Output hidden state. Passed to next time step AND to the output layer.',
                    intuition: '<strong>Why needed?</strong> Like a <em>summary report</em> - detailed internal records (memory cell) ‚Üí clean, bounded summary for others. <br><br><strong>Example:</strong> Memory cell contains raw, unbounded stock trend numbers (-500, +2000, -150). Hidden state processes via tanh (squashes to -1 to +1) and output gate (filters relevant info) to produce clean summary: "upward trend, moderate confidence." Keeps outputs stable and interpretable.'
                }
            };

            // Draw nodes
            Object.entries(nodes).forEach(([key, node]) => {
                const g = svg.append('g')
                    .attr('transform', `translate(${node.x}, ${node.y})`)
                    .style('cursor', 'pointer');

                let color = colors.state;
                let radius = 40;

                if (node.type === 'input') color = colors.input;
                else if (node.type === 'forget') color = colors.forget;
                else if (node.type === 'candidate') color = colors.candidate;
                else if (node.type === 'output') color = colors.output;
                else if (node.type === 'memory') color = colors.memory;
                else if (node.type === 'operation') { color = '#EEEEEE'; radius = 28; }

                // Circle
                const circle = g.append('circle')
                    .attr('r', radius)
                    .attr('fill', color)
                    .attr('stroke', '#262626')
                    .attr('stroke-width', 2.5)
                    .attr('opacity', 0.85);

                // Render node content
                if (node.subscript) {
                    // Labels with subscripts (X_t, H_t, C_t, F_t, I_t, O_t, etc.)
                    const text = g.append('text')
                        .attr('text-anchor', 'middle')
                        .attr('dy', node.symbol ? '-0.2em' : '0.35em'); // Shift up if there's a symbol below

                    text.append('tspan')
                        .attr('font-size', '18px')
                        .attr('font-weight', 'bold')
                        .attr('fill', '#262626')
                        .text(node.label);

                    text.append('tspan')
                        .attr('font-size', '12px')
                        .attr('font-weight', 'bold')
                        .attr('fill', '#262626')
                        .attr('baseline-shift', '-30%')
                        .text(node.subscript);

                    // Add symbol annotation below if present (for gates)
                    if (node.symbol) {
                        g.append('text')
                            .attr('text-anchor', 'middle')
                            .attr('y', 16)
                            .attr('font-size', '11px')
                            .attr('fill', '#555')
                            .attr('font-weight', 'normal')
                            .text(node.symbol);
                    }
                } else {
                    // Regular text label (fallback, shouldn't happen with current structure)
                    g.append('text')
                        .attr('text-anchor', 'middle')
                        .attr('dy', '0.35em')
                        .attr('font-size', '13px')
                        .attr('font-weight', 'bold')
                        .attr('fill', '#262626')
                        .text(node.label);
                }

                // Hover effects with FIXED tooltip positioning
                g.on('mouseenter', function(event) {
                    circle.transition().duration(200)
                        .attr('opacity', 1)
                        .attr('r', radius * 1.15);

                    const info = hoverInfo[key];
                    if (info) {
                        let content = `<div style="color: #10099F; font-weight: bold; margin-bottom: 8px; font-size: 16px;">${info.title}</div>`;
                        content += `<div style="margin-bottom: 8px; font-family: 'Source Code Pro', monospace; background: #F5F5F5; padding: 8px; border-radius: 4px; font-size: 13px;">${info.formula}</div>`;
                        if (info.dims) content += `<div style="margin-bottom: 6px; color: #666; font-size: 12px;"><strong>Dimensions:</strong> ${info.dims}</div>`;
                        if (info.description) content += `<div style="margin-bottom: 6px; font-size: 13px;">${info.description}</div>`;
                        if (info.intuition) content += `<div style="margin-top: 8px; padding: 8px; background: #FFF9E6; border-left: 3px solid #FAC55B; border-radius: 4px; font-size: 12px; line-height: 1.5;"><span style="font-size: 14px;">üí°</span> ${info.intuition}</div>`;
                        if (info.params) content += `<div style="margin-top: 8px; font-size: 12px; color: #666; border-top: 1px solid #EEEEEE; padding-top: 6px;">${info.params}</div>`;

                        // Get container position for proper tooltip placement
                        const containerRect = container.node().getBoundingClientRect();
                        const tooltipWidth = 480;
                        const tooltipHeight = 250; // estimated

                        // Calculate position relative to container
                        let tooltipX = event.clientX - containerRect.left + 15;
                        let tooltipY = event.clientY - containerRect.top - 15;

                        // Keep tooltip within bounds
                        if (tooltipX + tooltipWidth > width) {
                            tooltipX = event.clientX - containerRect.left - tooltipWidth - 15;
                        }
                        if (tooltipY < 0) tooltipY = 10;
                        if (tooltipY + tooltipHeight > height) {
                            tooltipY = height - tooltipHeight - 10;
                        }

                        tooltip.html(content)
                            .style('display', 'block')
                            .style('left', tooltipX + 'px')
                            .style('top', tooltipY + 'px');
                    }
                })
                .on('mouseleave', function() {
                    circle.transition().duration(200)
                        .attr('opacity', 0.85)
                        .attr('r', radius);
                    tooltip.style('display', 'none');
                })
                .on('mousemove', function(event) {
                    const containerRect = container.node().getBoundingClientRect();
                    const tooltipWidth = 400;
                    const tooltipHeight = 250;

                    let tooltipX = event.clientX - containerRect.left + 15;
                    let tooltipY = event.clientY - containerRect.top - 15;

                    if (tooltipX + tooltipWidth > width) {
                        tooltipX = event.clientX - containerRect.left - tooltipWidth - 15;
                    }
                    if (tooltipY < 0) tooltipY = 10;
                    if (tooltipY + tooltipHeight > height) {
                        tooltipY = height - tooltipHeight - 10;
                    }

                    tooltip
                        .style('left', tooltipX + 'px')
                        .style('top', tooltipY + 'px');
                });
            });
        }

        // Interactive Deep RNN Visualization
        Reveal.on('slidechanged', function(event) {
            const deepRnnVizContainer = document.getElementById('deep-rnn-interactive-viz');
            if (deepRnnVizContainer && event.currentSlide.contains(deepRnnVizContainer)) {
                createInteractiveDeepRNN();
            }
        });

        function createInteractiveDeepRNN() {
            const container = d3.select('#deep-rnn-interactive-viz');
            container.selectAll('*').remove();

            const width = 900;
            const height = 550;
            const svg = container.append('svg')
                .attr('width', '100%')
                .attr('height', '100%')
                .attr('viewBox', `0 0 ${width} ${height}`)
                .attr('preserveAspectRatio', 'xMidYMid meet')
                .style('background', 'white')
                .style('border-radius', '8px');

            // Colors
            const layerColors = ['#FC8484', '#2DD2C0', '#10099F', '#FAC55B'];
            const inputColor = '#EEEEEE';
            const outputColor = '#FFA05F';

            // Configuration
            let numLayers = 2;
            let numTimeSteps = 4;
            let isAnimating = false;
            let animationInterval = null;

            // Layout parameters
            const cellSize = 60;
            const hSpacing = 120;
            const vSpacing = 100;

            function drawNetwork() {
                svg.selectAll('*').remove();

                // Add title
                svg.append('text')
                    .attr('x', width / 2)
                    .attr('y', 30)
                    .attr('text-anchor', 'middle')
                    .style('font-size', '18px')
                    .style('font-weight', 'bold')
                    .style('fill', '#10099F')
                    .text(`${numLayers}-Layer Deep RNN over ${numTimeSteps} Time Steps`);

                // Calculate starting positions
                const startX = (width - (numTimeSteps - 1) * hSpacing - cellSize) / 2;
                const startY = 80;

                // Draw input layer
                for (let t = 0; t < numTimeSteps; t++) {
                    const x = startX + t * hSpacing;
                    const y = startY;

                    svg.append('rect')
                        .attr('x', x)
                        .attr('y', y)
                        .attr('width', cellSize)
                        .attr('height', cellSize * 0.6)
                        .attr('rx', 5)
                        .attr('fill', inputColor)
                        .attr('stroke', '#262626')
                        .attr('stroke-width', 2);

                    svg.append('text')
                        .attr('x', x + cellSize / 2)
                        .attr('y', y + cellSize * 0.4)
                        .attr('text-anchor', 'middle')
                        .style('font-size', '14px')
                        .style('fill', '#262626')
                        .text(`X_${t}`);
                }

                // Draw RNN layers
                for (let l = 0; l < numLayers; l++) {
                    const layerY = startY + vSpacing * (l + 1);

                    for (let t = 0; t < numTimeSteps; t++) {
                        const x = startX + t * hSpacing;
                        const y = layerY;

                        // Draw cell
                        const cell = svg.append('rect')
                            .attr('x', x)
                            .attr('y', y)
                            .attr('width', cellSize)
                            .attr('height', cellSize)
                            .attr('rx', 8)
                            .attr('fill', layerColors[l % layerColors.length])
                            .attr('fill-opacity', 0.3)
                            .attr('stroke', layerColors[l % layerColors.length])
                            .attr('stroke-width', 3)
                            .attr('class', `cell-${l}-${t}`);

                        // Add label
                        svg.append('text')
                            .attr('x', x + cellSize / 2)
                            .attr('y', y + cellSize / 2 + 5)
                            .attr('text-anchor', 'middle')
                            .style('font-size', '12px')
                            .style('font-weight', 'bold')
                            .style('fill', '#262626')
                            .text(`H_${t}^(${l + 1})`);

                        // Draw connection from input or previous layer
                        const prevY = l === 0 ? startY + cellSize * 0.6 : layerY - vSpacing + cellSize;
                        svg.append('line')
                            .attr('x1', x + cellSize / 2)
                            .attr('y1', prevY)
                            .attr('x2', x + cellSize / 2)
                            .attr('y2', y)
                            .attr('stroke', '#10099F')
                            .attr('stroke-width', 2)
                            .attr('marker-end', 'url(#arrowhead-vertical)')
                            .attr('class', `conn-vertical-${l}-${t}`)
                            .attr('opacity', 0.3);

                        // Draw recurrent connections (horizontal)
                        if (t > 0) {
                            const prevX = x - hSpacing;
                            svg.append('path')
                                .attr('d', `M ${prevX + cellSize} ${y + cellSize / 2} L ${x} ${y + cellSize / 2}`)
                                .attr('stroke', layerColors[l % layerColors.length])
                                .attr('stroke-width', 2)
                                .attr('marker-end', 'url(#arrowhead-horizontal)')
                                .attr('class', `conn-horizontal-${l}-${t}`)
                                .attr('opacity', 0.3);
                        }
                    }

                    // Layer label
                    svg.append('text')
                        .attr('x', startX - 60)
                        .attr('y', layerY + cellSize / 2 + 5)
                        .attr('text-anchor', 'end')
                        .style('font-size', '14px')
                        .style('font-weight', 'bold')
                        .style('fill', layerColors[l % layerColors.length])
                        .text(`Layer ${l + 1}`);
                }

                // Draw output layer
                const outputY = startY + vSpacing * (numLayers + 1);
                for (let t = 0; t < numTimeSteps; t++) {
                    const x = startX + t * hSpacing;

                    // Connection from top RNN layer to output
                    svg.append('line')
                        .attr('x1', x + cellSize / 2)
                        .attr('y1', startY + vSpacing * numLayers + cellSize)
                        .attr('x2', x + cellSize / 2)
                        .attr('y2', outputY)
                        .attr('stroke', '#FFA05F')
                        .attr('stroke-width', 2)
                        .attr('marker-end', 'url(#arrowhead-vertical)')
                        .attr('class', `conn-output-${t}`)
                        .attr('opacity', 0.3);

                    svg.append('rect')
                        .attr('x', x)
                        .attr('y', outputY)
                        .attr('width', cellSize)
                        .attr('height', cellSize * 0.6)
                        .attr('rx', 5)
                        .attr('fill', outputColor)
                        .attr('stroke', '#262626')
                        .attr('stroke-width', 2)
                        .attr('class', `output-${t}`);

                    svg.append('text')
                        .attr('x', x + cellSize / 2)
                        .attr('y', outputY + cellSize * 0.4)
                        .attr('text-anchor', 'middle')
                        .style('font-size', '14px')
                        .style('fill', '#262626')
                        .text(`O_${t}`);
                }

                // Define arrow markers
                svg.append('defs').selectAll('marker')
                    .data(['arrowhead-vertical', 'arrowhead-horizontal'])
                    .enter().append('marker')
                    .attr('id', d => d)
                    .attr('markerWidth', 10)
                    .attr('markerHeight', 10)
                    .attr('refX', 9)
                    .attr('refY', 3)
                    .attr('orient', 'auto')
                    .append('polygon')
                    .attr('points', '0 0, 10 3, 0 6')
                    .attr('fill', '#10099F');
            }

            function animateForward() {
                let step = 0;
                const totalSteps = numTimeSteps * numLayers + numTimeSteps;

                animationInterval = setInterval(() => {
                    if (step < numTimeSteps * numLayers) {
                        const t = step % numTimeSteps;
                        const l = Math.floor(step / numTimeSteps);

                        // Highlight cell
                        svg.select(`.cell-${l}-${t}`)
                            .transition()
                            .duration(300)
                            .attr('fill-opacity', 0.8)
                            .transition()
                            .duration(300)
                            .attr('fill-opacity', 0.3);

                        // Highlight connections
                        svg.select(`.conn-vertical-${l}-${t}`)
                            .transition()
                            .duration(400)
                            .attr('opacity', 1)
                            .transition()
                            .duration(400)
                            .attr('opacity', 0.3);

                        if (t > 0) {
                            svg.select(`.conn-horizontal-${l}-${t}`)
                                .transition()
                                .duration(400)
                                .attr('opacity', 1)
                                .transition()
                                .duration(400)
                                .attr('opacity', 0.3);
                        }
                    } else {
                        // Animate output
                        const t = step - numTimeSteps * numLayers;
                        svg.select(`.conn-output-${t}`)
                            .transition()
                            .duration(400)
                            .attr('opacity', 1)
                            .transition()
                            .duration(400)
                            .attr('opacity', 0.3);

                        svg.select(`.output-${t}`)
                            .transition()
                            .duration(300)
                            .attr('fill', '#FF8C00')
                            .transition()
                            .duration(300)
                            .attr('fill', outputColor);
                    }

                    step++;
                    if (step >= totalSteps) {
                        step = 0;
                    }
                }, 600);
            }

            function stopAnimation() {
                if (animationInterval) {
                    clearInterval(animationInterval);
                    animationInterval = null;
                }
            }

            // Initial draw
            drawNetwork();

            // Add controls
            const controlsContainer = container.append('div')
                .style('position', 'absolute')
                .style('top', '10px')
                .style('right', '10px')
                .style('background', 'rgba(255, 255, 255, 0.95)')
                .style('padding', '15px')
                .style('border-radius', '8px')
                .style('border', '2px solid #10099F')
                .style('z-index', '100');

            // Number of layers control
            const layerControl = controlsContainer.append('div')
                .style('margin-bottom', '10px');

            layerControl.append('label')
                .style('font-size', '13px')
                .style('font-weight', 'bold')
                .style('margin-right', '10px')
                .text('Layers: ');

            layerControl.append('input')
                .attr('type', 'range')
                .attr('min', 1)
                .attr('max', 4)
                .attr('value', numLayers)
                .style('width', '100px')
                .style('vertical-align', 'middle')
                .on('input', function() {
                    numLayers = +this.value;
                    layerValue.text(numLayers);
                    stopAnimation();
                    isAnimating = false;
                    playBtn.text('‚ñ∂ Play');
                    drawNetwork();
                });

            const layerValue = layerControl.append('span')
                .style('margin-left', '10px')
                .style('font-family', 'monospace')
                .style('font-weight', 'bold')
                .text(numLayers);

            // Time steps control
            const timeControl = controlsContainer.append('div')
                .style('margin-bottom', '10px');

            timeControl.append('label')
                .style('font-size', '13px')
                .style('font-weight', 'bold')
                .style('margin-right', '10px')
                .text('Time Steps: ');

            timeControl.append('input')
                .attr('type', 'range')
                .attr('min', 2)
                .attr('max', 6)
                .attr('value', numTimeSteps)
                .style('width', '100px')
                .style('vertical-align', 'middle')
                .on('input', function() {
                    numTimeSteps = +this.value;
                    timeValue.text(numTimeSteps);
                    stopAnimation();
                    isAnimating = false;
                    playBtn.text('‚ñ∂ Play');
                    drawNetwork();
                });

            const timeValue = timeControl.append('span')
                .style('margin-left', '10px')
                .style('font-family', 'monospace')
                .style('font-weight', 'bold')
                .text(numTimeSteps);

            // Play/Pause button
            const playBtn = controlsContainer.append('button')
                .style('background', '#10099F')
                .style('color', 'white')
                .style('border', 'none')
                .style('padding', '8px 16px')
                .style('border-radius', '5px')
                .style('cursor', 'pointer')
                .style('font-size', '13px')
                .style('font-weight', 'bold')
                .style('width', '100%')
                .text('‚ñ∂ Play')
                .on('click', function() {
                    if (isAnimating) {
                        stopAnimation();
                        isAnimating = false;
                        playBtn.text('‚ñ∂ Play');
                    } else {
                        animateForward();
                        isAnimating = true;
                        playBtn.text('‚è∏ Pause');
                    }
                });
        }

        // Machine Translation Interactive Visualizations
        Reveal.on('slidechanged', function(event) {
            // Preprocessing Demo
            const preprocessContainer = document.getElementById('preprocess-demo');
            if (preprocessContainer && event.currentSlide.contains(preprocessContainer)) {
                createPreprocessDemo();
            }

            // Histogram Demo
            const histogramContainer = document.getElementById('histogram-demo');
            if (histogramContainer && event.currentSlide.contains(histogramContainer)) {
                createHistogramDemo();
            }

            // Decoder Shift Demo
            const decoderContainer = document.getElementById('decoder-shift-demo');
            if (decoderContainer && event.currentSlide.contains(decoderContainer)) {
                createDecoderShiftDemo();
            }

            // Minibatch Demo
            const minibatchContainer = document.getElementById('minibatch-demo');
            if (minibatchContainer && event.currentSlide.contains(minibatchContainer)) {
                createMinibatchDemo();
            }

            // Data Flow Visualization
            const dataflowContainer = document.getElementById('dataflow-viz');
            if (dataflowContainer && event.currentSlide.contains(dataflowContainer)) {
                createDataFlowViz();
            }
        });

        function createPreprocessDemo() {
            const container = d3.select('#preprocess-demo');
            container.selectAll('*').remove();

            const examples = [
                { raw: 'Go.\tVa !', processed: 'go .\tva !' },
                { raw: 'Hi.\tSalut !', processed: 'hi .\tsalut !' },
                { raw: 'WHO?\tQui ?', processed: 'who ?\tqui ?' }
            ];

            let currentIndex = 0;

            const demoContainer = container.append('div')
                .style('text-align', 'center');

            const beforeBox = demoContainer.append('div')
                .style('display', 'inline-block')
                .style('width', '45%')
                .style('vertical-align', 'top')
                .style('margin', '10px');

            beforeBox.append('h4')
                .style('color', '#FC8484')
                .text('Before Preprocessing');

            const beforeContent = beforeBox.append('div')
                .style('background', '#FFF5F5')
                .style('border', '2px solid #FC8484')
                .style('padding', '20px')
                .style('border-radius', '8px')
                .style('font-family', "'Source Code Pro', monospace")
                .style('font-size', '1.1em')
                .style('min-height', '60px')
                .style('display', 'flex')
                .style('align-items', 'center')
                .style('justify-content', 'center')
                .text(examples[0].raw);

            const afterBox = demoContainer.append('div')
                .style('display', 'inline-block')
                .style('width', '45%')
                .style('vertical-align', 'top')
                .style('margin', '10px');

            afterBox.append('h4')
                .style('color', '#2DD2C0')
                .text('After Preprocessing');

            const afterContent = afterBox.append('div')
                .style('background', '#F0FFF9')
                .style('border', '2px solid #2DD2C0')
                .style('padding', '20px')
                .style('border-radius', '8px')
                .style('font-family', "'Source Code Pro', monospace")
                .style('font-size', '1.1em')
                .style('min-height', '60px')
                .style('display', 'flex')
                .style('align-items', 'center')
                .style('justify-content', 'center')
                .text(examples[0].processed);

            const btnContainer = demoContainer.append('div')
                .style('margin-top', '20px');

            btnContainer.append('button')
                .style('background', '#10099F')
                .style('color', 'white')
                .style('border', 'none')
                .style('padding', '10px 20px')
                .style('border-radius', '5px')
                .style('cursor', 'pointer')
                .style('font-size', '14px')
                .text('Next Example')
                .on('click', function() {
                    currentIndex = (currentIndex + 1) % examples.length;
                    beforeContent.text(examples[currentIndex].raw);
                    afterContent.text(examples[currentIndex].processed);
                });
        }

        function createHistogramDemo() {
            const container = d3.select('#histogram-demo');
            container.selectAll('*').remove();

            const width = 700;
            const height = 400;
            const margin = { top: 20, right: 30, bottom: 50, left: 60 };

            const svg = container.append('svg')
                .attr('width', '100%')
                .attr('height', '100%')
                .attr('viewBox', `0 0 ${width} ${height}`)
                .attr('preserveAspectRatio', 'xMidYMid meet');

            // Simulated data (token lengths)
            const sourceData = [3, 4, 5, 6, 7, 8, 9, 10, 4, 5, 6, 7, 8, 9, 3, 4, 5, 6, 7, 8, 12, 14, 16, 18, 5, 6, 7, 8, 9, 10];
            const targetData = [3, 4, 5, 6, 7, 8, 9, 10, 11, 4, 5, 6, 7, 8, 3, 4, 5, 6, 7, 8, 13, 15, 17, 19, 5, 6, 7, 8, 9, 11];

            const bins = d3.bin().thresholds(20);
            const sourceBins = bins(sourceData);
            const targetBins = bins(targetData);

            const x = d3.scaleLinear()
                .domain([0, 25])
                .range([margin.left, width - margin.right]);

            const y = d3.scaleLinear()
                .domain([0, d3.max([...sourceBins, ...targetBins], d => d.length)])
                .range([height - margin.bottom, margin.top]);

            // Draw source histogram
            svg.selectAll('.bar-source')
                .data(sourceBins)
                .join('rect')
                .attr('class', 'bar-source')
                .attr('x', d => x(d.x0))
                .attr('y', d => y(d.length))
                .attr('width', d => x(d.x1) - x(d.x0) - 1)
                .attr('height', d => height - margin.bottom - y(d.length))
                .attr('fill', '#10099F')
                .attr('opacity', 0.7);

            // Draw target histogram
            svg.selectAll('.bar-target')
                .data(targetBins)
                .join('rect')
                .attr('class', 'bar-target')
                .attr('x', d => x(d.x0))
                .attr('y', d => y(d.length))
                .attr('width', d => x(d.x1) - x(d.x0) - 1)
                .attr('height', d => height - margin.bottom - y(d.length))
                .attr('fill', '#2DD2C0')
                .attr('opacity', 0.7);

            // X axis
            svg.append('g')
                .attr('transform', `translate(0,${height - margin.bottom})`)
                .call(d3.axisBottom(x))
                .append('text')
                .attr('x', width / 2)
                .attr('y', 35)
                .attr('fill', '#262626')
                .attr('font-size', '14px')
                .attr('font-weight', 'bold')
                .text('# tokens per sequence');

            // Y axis
            svg.append('g')
                .attr('transform', `translate(${margin.left},0)`)
                .call(d3.axisLeft(y))
                .append('text')
                .attr('transform', 'rotate(-90)')
                .attr('x', -height / 2)
                .attr('y', -40)
                .attr('fill', '#262626')
                .attr('font-size', '14px')
                .attr('font-weight', 'bold')
                .attr('text-anchor', 'middle')
                .text('count');

            // Legend
            const legend = svg.append('g')
                .attr('transform', `translate(${width - 150}, ${margin.top})`);

            legend.append('rect')
                .attr('width', 20)
                .attr('height', 20)
                .attr('fill', '#10099F')
                .attr('opacity', 0.7);

            legend.append('text')
                .attr('x', 25)
                .attr('y', 15)
                .attr('font-size', '12px')
                .text('Source');

            legend.append('rect')
                .attr('y', 25)
                .attr('width', 20)
                .attr('height', 20)
                .attr('fill', '#2DD2C0')
                .attr('opacity', 0.7);

            legend.append('text')
                .attr('x', 25)
                .attr('y', 40)
                .attr('font-size', '12px')
                .text('Target');
        }

        function createDecoderShiftDemo() {
            const container = d3.select('#decoder-shift-demo');
            container.selectAll('*').remove();

            const sequence = ['<bos>', 'salut', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'];

            const demoDiv = container.append('div')
                .style('text-align', 'center');

            // Decoder Input
            const inputDiv = demoDiv.append('div')
                .style('margin-bottom', '30px');

            inputDiv.append('h4')
                .style('color', '#10099F')
                .style('margin-bottom', '15px')
                .text('Decoder Input (tgt_array[:,:-1])');

            const inputRow = inputDiv.append('div')
                .style('display', 'flex')
                .style('justify-content', 'center')
                .style('gap', '5px');

            sequence.slice(0, -1).forEach((token, i) => {
                inputRow.append('div')
                    .style('background', i === 0 ? '#FAC55B' : (token === '<pad>' ? '#EEEEEE' : '#10099F'))
                    .style('color', token === '<pad>' ? '#666' : 'white')
                    .style('padding', '10px 15px')
                    .style('border-radius', '5px')
                    .style('font-family', "'Source Code Pro', monospace")
                    .style('font-size', '13px')
                    .style('border', '2px solid #10099F')
                    .text(token);
            });

            // Arrow
            demoDiv.append('div')
                .style('font-size', '2em')
                .style('color', '#666')
                .style('margin', '20px 0')
                .text('‚Üì Shifted by one token');

            // Labels
            const labelDiv = demoDiv.append('div');

            labelDiv.append('h4')
                .style('color', '#FC8484')
                .style('margin-bottom', '15px')
                .text('Labels (tgt_array[:,1:])');

            const labelRow = labelDiv.append('div')
                .style('display', 'flex')
                .style('justify-content', 'center')
                .style('gap', '5px');

            sequence.slice(1).forEach((token, i) => {
                labelRow.append('div')
                    .style('background', token === '<pad>' ? '#EEEEEE' : '#FC8484')
                    .style('color', token === '<pad>' ? '#666' : 'white')
                    .style('padding', '10px 15px')
                    .style('border-radius', '5px')
                    .style('font-family', "'Source Code Pro', monospace")
                    .style('font-size', '13px')
                    .style('border', '2px solid #FC8484')
                    .text(token);
            });
        }

        function createMinibatchDemo() {
            const container = d3.select('#minibatch-demo');
            container.selectAll('*').remove();

            const data = {
                source: [[117, 182, 0, 3, 4, 4, 4, 4, 4],
                         [62, 72, 2, 3, 4, 4, 4, 4, 4],
                         [57, 124, 0, 3, 4, 4, 4, 4, 4]],
                decoder_input: [[3, 37, 100, 58, 160, 0, 4, 5, 5],
                                [3, 6, 2, 4, 5, 5, 5, 5, 5],
                                [3, 180, 0, 4, 5, 5, 5, 5, 5]],
                src_valid_len: [4, 4, 4],
                label: [[37, 100, 58, 160, 0, 4, 5, 5, 5],
                        [6, 2, 4, 5, 5, 5, 5, 5, 5],
                        [180, 0, 4, 5, 5, 5, 5, 5, 5]]
            };

            const vocab = {
                0: '<eos>', 2: '!', 3: '<bos>', 4: '<pad>', 5: '<pad>',
                6: 'salut', 37: 'va', 57: 'who', 58: '!', 62: 'hi',
                72: '.', 100: '!', 117: 'go', 124: '?', 160: 'alors',
                180: 'qui', 182: '.'
            };

            const demoDiv = container.append('div')
                .style('font-size', '0.85em');

            function renderArray(title, arr, color, vocabMap) {
                const section = demoDiv.append('div')
                    .style('margin-bottom', '25px');

                section.append('h4')
                    .style('color', color)
                    .style('margin-bottom', '10px')
                    .text(title);

                arr.forEach((row, rowIdx) => {
                    const rowDiv = section.append('div')
                        .style('display', 'flex')
                        .style('gap', '3px')
                        .style('margin-bottom', '5px')
                        .style('justify-content', 'center');

                    row.forEach((val, colIdx) => {
                        const cell = rowDiv.append('div')
                            .style('background', val === 4 || val === 5 ? '#EEEEEE' : color)
                            .style('color', val === 4 || val === 5 ? '#999' : 'white')
                            .style('padding', '8px 12px')
                            .style('border-radius', '4px')
                            .style('font-family', "'Source Code Pro', monospace")
                            .style('font-size', '12px')
                            .style('min-width', '35px')
                            .style('text-align', 'center')
                            .style('cursor', 'pointer')
                            .style('position', 'relative')
                            .text(val);

                        if (vocabMap && vocabMap[val]) {
                            cell.on('mouseenter', function() {
                                const tooltip = d3.select('body').append('div')
                                    .attr('class', 'minibatch-tooltip')
                                    .style('position', 'absolute')
                                    .style('background', 'rgba(0,0,0,0.9)')
                                    .style('color', 'white')
                                    .style('padding', '8px 12px')
                                    .style('border-radius', '5px')
                                    .style('font-size', '12px')
                                    .style('pointer-events', 'none')
                                    .style('z-index', '1000')
                                    .text(vocabMap[val]);

                                const rect = this.getBoundingClientRect();
                                tooltip
                                    .style('left', (rect.left + window.scrollX + rect.width / 2) + 'px')
                                    .style('top', (rect.top + window.scrollY - 35) + 'px')
                                    .style('transform', 'translateX(-50%)');
                            }).on('mouseleave', function() {
                                d3.selectAll('.minibatch-tooltip').remove();
                            });
                        }
                    });
                });
            }

            renderArray('Source:', data.source, '#10099F', vocab);
            renderArray('Decoder Input:', data.decoder_input, '#FAC55B', vocab);

            const lenSection = demoDiv.append('div')
                .style('margin-bottom', '25px');
            lenSection.append('h4')
                .style('color', '#2DD2C0')
                .style('margin-bottom', '10px')
                .text('Source Valid Lengths:');
            lenSection.append('div')
                .style('font-family', "'Source Code Pro', monospace")
                .style('font-size', '14px')
                .text('[' + data.src_valid_len.join(', ') + ']');

            renderArray('Labels:', data.label, '#FC8484', vocab);

            demoDiv.append('p')
                .style('margin-top', '20px')
                .style('font-style', 'italic')
                .style('color', '#666')
                .style('text-align', 'center')
                .text('üí° Hover over indices to see their token mappings');
        }

        function createDataFlowViz() {
            const container = d3.select('#dataflow-viz');
            container.selectAll('*').remove();

            const steps = [
                { name: 'Raw Text Download', icon: 'üì•', color: '#FC8484' },
                { name: 'Preprocessing', icon: 'üîß', color: '#FFA05F' },
                { name: 'Tokenization', icon: '‚úÇÔ∏è', color: '#FAC55B' },
                { name: 'Vocabulary Building', icon: 'üìö', color: '#2DD2C0' },
                { name: 'Padding/Truncation', icon: 'üìè', color: '#10099F' },
                { name: 'DataLoader', icon: 'üîÑ', color: '#00FFBA' }
            ];

            const flowDiv = container.append('div')
                .style('display', 'flex')
                .style('flex-direction', 'column')
                .style('align-items', 'center')
                .style('gap', '15px')
                .style('padding', '20px');

            steps.forEach((step, i) => {
                const stepDiv = flowDiv.append('div')
                    .style('width', '80%')
                    .style('text-align', 'center');

                stepDiv.append('div')
                    .style('background', `linear-gradient(135deg, ${step.color} 0%, ${step.color}AA 100%)`)
                    .style('color', 'white')
                    .style('padding', '20px')
                    .style('border-radius', '10px')
                    .style('font-size', '1.1em')
                    .style('font-weight', 'bold')
                    .style('box-shadow', '0 4px 6px rgba(0,0,0,0.1)')
                    .html(`${step.icon} ${step.name}`);

                if (i < steps.length - 1) {
                    stepDiv.append('div')
                        .style('font-size', '2em')
                        .style('color', '#CCCCCC')
                        .style('margin', '5px 0')
                        .text('‚Üì');
                }
            });
        }

        // Encoder-Decoder Interactive Visualization
        Reveal.on('slidechanged', function(event) {
            const encDecViz = document.getElementById('encoder-decoder-viz');
            if (encDecViz && event.currentSlide.contains(encDecViz)) {
                createEncoderDecoderViz();
            }
        });

        function createEncoderDecoderViz() {
            const container = d3.select('#encoder-decoder-viz');
            container.selectAll('*').remove();

            const width = container.node().getBoundingClientRect().width;
            const height = 450;

            const svg = container.append('svg')
                .attr('width', width)
                .attr('height', height);

            // Example sequence: "They are watching ." -> "Ils regardent ."
            const sourceTokens = ['They', 'are', 'watching', '.'];
            const targetTokens = ['<bos>', 'Ils', 'regardent', '.'];
            const outputTokens = ['Ils', 'regardent', '.', '<eos>'];

            // Layout parameters
            const tokenWidth = 80;
            const tokenHeight = 40;
            const stateSize = 100;
            const spacing = 30;

            // Calculate positions
            const encoderX = 80;
            const encoderY = 50;
            const stateX = width / 2 - stateSize / 2;
            const stateY = height / 2 - stateSize / 2;
            const decoderX = width - encoderX - tokenWidth * 4 - spacing * 3;
            const decoderY = height - 100;

            // Animation state
            let animationStep = 0;
            let animationSpeed = 1;
            let animationInterval = null;

            // Draw input tokens (encoder input)
            const inputGroup = svg.append('g').attr('class', 'input-tokens');
            sourceTokens.forEach((token, i) => {
                const g = inputGroup.append('g')
                    .attr('transform', `translate(${encoderX + i * (tokenWidth + spacing)}, ${encoderY})`);

                g.append('rect')
                    .attr('width', tokenWidth)
                    .attr('height', tokenHeight)
                    .attr('fill', '#10099F')
                    .attr('stroke', '#10099F')
                    .attr('stroke-width', 2)
                    .attr('rx', 5)
                    .attr('opacity', 0);

                g.append('text')
                    .attr('x', tokenWidth / 2)
                    .attr('y', tokenHeight / 2)
                    .attr('text-anchor', 'middle')
                    .attr('dominant-baseline', 'middle')
                    .attr('fill', 'white')
                    .attr('font-size', '14px')
                    .attr('font-family', "'Source Code Pro', monospace")
                    .text(token)
                    .attr('opacity', 0);
            });

            // Draw encoder box
            const encoderBox = svg.append('g').attr('class', 'encoder-box');
            encoderBox.append('rect')
                .attr('x', encoderX - 20)
                .attr('y', encoderY + tokenHeight + 30)
                .attr('width', tokenWidth * 4 + spacing * 3 + 40)
                .attr('height', 80)
                .attr('fill', '#10099F')
                .attr('stroke', '#10099F')
                .attr('stroke-width', 2)
                .attr('rx', 10)
                .attr('opacity', 0);

            encoderBox.append('text')
                .attr('x', encoderX + (tokenWidth * 4 + spacing * 3) / 2)
                .attr('y', encoderY + tokenHeight + 70)
                .attr('text-anchor', 'middle')
                .attr('fill', 'white')
                .attr('font-size', '18px')
                .attr('font-weight', 'bold')
                .text('Encoder')
                .attr('opacity', 0);

            // Draw state representation
            const stateGroup = svg.append('g').attr('class', 'state-group');
            stateGroup.append('rect')
                .attr('x', stateX)
                .attr('y', stateY)
                .attr('width', stateSize)
                .attr('height', stateSize)
                .attr('fill', '#FAC55B')
                .attr('stroke', '#FAC55B')
                .attr('stroke-width', 3)
                .attr('rx', 10)
                .attr('opacity', 0);

            stateGroup.append('text')
                .attr('x', stateX + stateSize / 2)
                .attr('y', stateY + stateSize / 2 - 10)
                .attr('text-anchor', 'middle')
                .attr('fill', '#262626')
                .attr('font-size', '16px')
                .attr('font-weight', 'bold')
                .text('Encoded')
                .attr('opacity', 0);

            stateGroup.append('text')
                .attr('x', stateX + stateSize / 2)
                .attr('y', stateY + stateSize / 2 + 10)
                .attr('text-anchor', 'middle')
                .attr('fill', '#262626')
                .attr('font-size', '16px')
                .attr('font-weight', 'bold')
                .text('State')
                .attr('opacity', 0);

            // Draw decoder box
            const decoderBox = svg.append('g').attr('class', 'decoder-box');
            decoderBox.append('rect')
                .attr('x', decoderX - 20)
                .attr('y', decoderY - 100)
                .attr('width', tokenWidth * 4 + spacing * 3 + 40)
                .attr('height', 80)
                .attr('fill', '#2DD2C0')
                .attr('stroke', '#2DD2C0')
                .attr('stroke-width', 2)
                .attr('rx', 10)
                .attr('opacity', 0);

            decoderBox.append('text')
                .attr('x', decoderX + (tokenWidth * 4 + spacing * 3) / 2)
                .attr('y', decoderY - 60)
                .attr('text-anchor', 'middle')
                .attr('fill', 'white')
                .attr('font-size', '18px')
                .attr('font-weight', 'bold')
                .text('Decoder')
                .attr('opacity', 0);

            // Draw output tokens
            const outputGroup = svg.append('g').attr('class', 'output-tokens');
            outputTokens.forEach((token, i) => {
                const g = outputGroup.append('g')
                    .attr('transform', `translate(${decoderX + i * (tokenWidth + spacing)}, ${decoderY})`);

                g.append('rect')
                    .attr('width', tokenWidth)
                    .attr('height', tokenHeight)
                    .attr('fill', '#FC8484')
                    .attr('stroke', '#FC8484')
                    .attr('stroke-width', 2)
                    .attr('rx', 5)
                    .attr('opacity', 0);

                g.append('text')
                    .attr('x', tokenWidth / 2)
                    .attr('y', tokenHeight / 2)
                    .attr('text-anchor', 'middle')
                    .attr('dominant-baseline', 'middle')
                    .attr('fill', 'white')
                    .attr('font-size', '14px')
                    .attr('font-family', "'Source Code Pro', monospace")
                    .text(token)
                    .attr('opacity', 0);
            });

            // Define arrowheads
            svg.append('defs').append('marker')
                .attr('id', 'arrowhead')
                .attr('markerWidth', 10)
                .attr('markerHeight', 10)
                .attr('refX', 9)
                .attr('refY', 3)
                .attr('orient', 'auto')
                .append('polygon')
                .attr('points', '0 0, 10 3, 0 6')
                .attr('fill', '#10099F');

            svg.append('defs').append('marker')
                .attr('id', 'arrowhead2')
                .attr('markerWidth', 10)
                .attr('markerHeight', 10)
                .attr('refX', 9)
                .attr('refY', 3)
                .attr('orient', 'auto')
                .append('polygon')
                .attr('points', '0 0, 10 3, 0 6')
                .attr('fill', '#2DD2C0');

            // Animation steps
            function animate() {
                switch(animationStep) {
                    case 0:
                        // Show input tokens
                        inputGroup.selectAll('rect, text')
                            .transition()
                            .duration(500 / animationSpeed)
                            .attr('opacity', 1);
                        break;
                    case 1:
                        // Show encoder box
                        encoderBox.selectAll('rect, text')
                            .transition()
                            .duration(500 / animationSpeed)
                            .attr('opacity', 1);
                        break;
                    case 2:
                        // Animate tokens flowing into encoder
                        sourceTokens.forEach((token, i) => {
                            const startX = encoderX + i * (tokenWidth + spacing) + tokenWidth / 2;
                            const startY = encoderY + tokenHeight;
                            const endY = encoderY + tokenHeight + 70;

                            svg.append('circle')
                                .attr('cx', startX)
                                .attr('cy', startY)
                                .attr('r', 5)
                                .attr('fill', '#00FFBA')
                                .transition()
                                .duration(800 / animationSpeed)
                                .delay(i * 200 / animationSpeed)
                                .attr('cy', endY)
                                .remove();
                        });
                        break;
                    case 3:
                        // Show encoded state
                        stateGroup.selectAll('rect, text')
                            .transition()
                            .duration(500 / animationSpeed)
                            .attr('opacity', 1);

                        // Arrow from encoder to state
                        const arrowEnc = svg.append('g').attr('class', 'arrow-enc');
                        arrowEnc.append('line')
                            .attr('x1', encoderX + (tokenWidth * 4 + spacing * 3) / 2)
                            .attr('y1', encoderY + tokenHeight + 110)
                            .attr('x2', stateX + stateSize / 2)
                            .attr('y2', stateY)
                            .attr('stroke', '#10099F')
                            .attr('stroke-width', 3)
                            .attr('marker-end', 'url(#arrowhead)')
                            .attr('opacity', 0)
                            .transition()
                            .duration(500 / animationSpeed)
                            .attr('opacity', 1);
                        break;
                    case 4:
                        // Show decoder box
                        decoderBox.selectAll('rect, text')
                            .transition()
                            .duration(500 / animationSpeed)
                            .attr('opacity', 1);

                        // Arrow from state to decoder
                        const arrowDec = svg.append('g').attr('class', 'arrow-dec');
                        arrowDec.append('line')
                            .attr('x1', stateX + stateSize / 2)
                            .attr('y1', stateY + stateSize)
                            .attr('x2', decoderX + (tokenWidth * 4 + spacing * 3) / 2)
                            .attr('y2', decoderY - 100)
                            .attr('stroke', '#2DD2C0')
                            .attr('stroke-width', 3)
                            .attr('marker-end', 'url(#arrowhead2)')
                            .attr('opacity', 0)
                            .transition()
                            .duration(500 / animationSpeed)
                            .attr('opacity', 1);
                        break;
                    case 5:
                        // Generate output tokens one by one
                        outputTokens.forEach((token, i) => {
                            outputGroup.selectAll('g')
                                .filter((d, idx) => idx === i)
                                .selectAll('rect, text')
                                .transition()
                                .duration(400 / animationSpeed)
                                .delay(i * 500 / animationSpeed)
                                .attr('opacity', 1);
                        });
                        break;
                }

                animationStep++;
                if (animationStep > 5) {
                    clearInterval(animationInterval);
                }
            }

            // Control handlers
            document.getElementById('animate-btn').onclick = function() {
                if (animationInterval) {
                    clearInterval(animationInterval);
                }
                animationStep = 0;
                animationInterval = setInterval(() => {
                    animate();
                }, 1000 / animationSpeed);
            };

            document.getElementById('reset-btn').onclick = function() {
                if (animationInterval) {
                    clearInterval(animationInterval);
                }
                animationStep = 0;
                container.selectAll('*').remove();
                createEncoderDecoderViz();
            };

            document.getElementById('speed-slider').oninput = function() {
                animationSpeed = parseFloat(this.value);
                document.getElementById('speed-value').textContent = animationSpeed.toFixed(1) + 'x';
            };
        }
    </script>
</body>
</html>